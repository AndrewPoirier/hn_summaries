<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>HN Summaries</title><link>http://andrewpoirier.github.io/hn_summarizer</link><description>The top HN articles everyday - summarized</description><lastBuildDate>Sat, 09 Nov 2024 06:53:20 -0000</lastBuildDate><item><title>1. Scientists glue two proteins together, driving cancer cells to self-destruct</title><link>https://news.ycombinator.com/item?id=42037386</link><description>
&lt;![CDATA[
&lt;p&gt;625 points points by Jerry2 on 2024-11-04T00:42:58 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;There's a decent amount of cynicism in the comments, which I understand. I think this is a really cool and novel study, though.Historically, cancer was treated with therapies that are toxic to all cells, relying on the fact that cancer cells divide quickly and are unable to handle stress as well as normal cells (chemotherapy, radiation).The last couple of decades we've seen many targeted cancer therapies. These drugs generally inhibit the activity of a specific protein that lets the cancer cells grow (e.g. EGFR inhibitors) or prevents the immune system from killing the cancer cells (e.g. PDL1 inhibitors).This mechanism is way more interesting. The gene BCL6 is usually turned on in immune cells when they are mutating to recognize foreign invaders. This process involves lots of DNA damage and stress, but BCL6 stops the cells from dying and is therefore important for normal immune function. Unfortunately, this makes BCL6 a gene that is often co-opted in cancer cells to help them survive.The method cleverly exploits the oncogenic function of BCL6 not by inhibiting it, but by turning it into a guide, enabling the delivery of activating machinery to the targets of BCL6 and reversing the inhibitory effects on cell death.The whole field of targeted degraders, molecular glues, and heterobifunctional molecules is a growing area of interest in cancer research.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;All of this stuff is promising, and I hope the diagnostic side catches up as well.Just went to a funeral this weekend for a 40 year old who died of breast cancer 4 weeks after diagnosis at her first annual mammogram.A lot of skeptical people under 30 here haven't lived through regularly various cancer diagnoses in their friends &amp; family group that your late 30s/early 40s starts to bring.I don't have the data on it, but anecdotally I notice that women's cancers seem to strike 5-10 years earlier than mens even if they can be caught early &amp; treated well.. Though apparently men have overall worse cancer survival rates.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Same as mountainriver's comment. I really find strange how I've been reading news lines over the past years about great advancements in many incurable and chronic diseases (like Alzheimer's, diabetes, and cancers) yet after all that time people's treatment is not going any better. I'm not sure whether scientific journalism somehow delivered some unintended messages to me, or we're just supposed to experience these great advancements after couple of decades from the announcement.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:46:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42037386</guid></item><item><title>2. New York Times Tech Guild goes on strike</title><link>https://news.ycombinator.com/item?id=42040795</link><description>
&lt;![CDATA[
&lt;p&gt;683 points points by ChrisArchitect on 2024-11-04T12:08:30 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Here is context on the strike, how long it's been brewing, and more that I happened to read yesterday:https://www.thenation.com/article/archive/the-new-york-times...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; The two sides negotiated until late Sunday. The sticking points in recent days were over whether they could get a “just cause” provision in their contract, which means workers can be terminated only for misconduct or another such reason; pay increases and pay equity; and return-to-office policies.This seems like a LOT of issues that still need to be hammered out. It would be one thing if they were disagreeing about a number, but it sounds like the terms keep changing and nobody agrees on the nature of the work itself. It's not even clear that there's a preliminary contract ready for the NYTimes to sign.Striking during election week is kind of a crappy move to pull. But if this is just attention seeking without a serious contract, it seems egregiously risky on behalf of the union members too: there's not a clear button the Times can push on behalf of the union to end the strike immediately. The Times would either have to sign a blank check to the union now, or the union would have to agree to an IOU in exchange for a bunch of temporary concessions.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Gift link: https://www.nytimes.com/2024/11/04/business/media/new-york-t...https://archive.ph/f9gP0&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42040795</guid></item><item><title>3. A change of heart regarding employee metrics</title><link>https://news.ycombinator.com/item?id=42038653</link><description>
&lt;![CDATA[
&lt;p&gt;570 points points by zdw on 2024-11-04T05:06:42 &lt;/p&gt;
&lt;p&gt;This week's prompt is a change of heart on employee metrics. Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com. Today's prompt: Share your thoughts on a story you saw in CNN. com's newsquiz.  The weekly News Quiz will be held on November 3, 2024 at 11:30 a.m. ET (13:30 p.m., November 4, 2014 at 9:30 A.M. ET)&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&gt;&gt; [Why not build programmer performance measurement tooling?] It's the job of a manager to know what their reports are up to, and whether they're doing a good job of it, and are generally effective. If they can't do that, then they themselves are ineffective, and that is the sort of thing that is the responsibility of THEIR manager, and so on up the line.Agreed wholeheartedly, but for slightly different reasons. To wit, laziness and Goodhart's law. [0]In the absence of infinite time, automation will excuse a lack of manager curiosity, as other competing tasks absorb the freed time.Consequently, most managers with automated dashboards showing performance metrics won't use those dashboards... plus all the person-to-person work they were previously doing. They'll only use those dashboards.Which then slowly but inexorably turns your employees into dashboard-optimization drones via operant conditioning.Helping a colleague doesn't show up on the dashboards? Fuck that. Digging into what looks like a security vulnerability isn't on the sprint board? Fuck that.Which is incredibly corrosive to quality, creative system design.And then, because this is the work reality you've created, the creative folks you really want working there bail for greener pastures, and you're left with bottom of the barrel talent and retention problems.[0] https://en.m.wikipedia.org/wiki/Goodhart's_law&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I worked on an internal platform for a large engineering org and was responsible for choosing what features we put in.We had the technical means to track everything from commits to reviews, jiras, deploys, etc. Some of our most celebrated and impactful features were reporting on Accelerate metrics and related. E.g. deploy frequency, size of changes, duration of stages in the dev cycle and such.I set a very inflexible red line: we don’t expose data more granular than at team level. Ever. No excuse.Quite a few line managers would come to me asking for “personal metrics”, and even engineers in the team were super interested in building that (“with all this data we could…”).My argument was that these metrics are toxic and invite misuse. A second factor was that this misuse would generate mistrust from engs against the platform and damage adoption.Instrumenting an organization thought of as a system is fine. You want to see where are bottlenecks, you want to have measurable targets for how technical work is done and how it correlates to business goals/KPIs.You want to offer teams metrics of their delivery my process so they can take the info and implement improvements whenever they see fit, and have a data driven conversation with the business (e.g. about the right setting for the carefulness knob)But teams are the minimum unit of ownership, we stop the instrumentation there. Sure, a team’s performance ultimately links to individuals, but that is the manager’s job to figure out.Interestingly:* only line managers asked for this info, nobody in a director/vp/cxo role
* the most annoyed by me saying no were engineers in the team who wanted to do these features&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;there's a scene from the tv show "suits" that has always stuck with me:the show is set in a law firm, and in this particular episode they needed to lay off some of their associates. a young, newly-promoted lawyer was tasked with drawing up a list of the associates and marking the ones who she felt should get the axe, based on their performance. so she comes up with some metrics, goes through the associates' work, and ranks them based on the resultant numbers, saying that the bottom few could be let go.there is one employee, brian, who ends up near the bottom of the list. a more senior person takes her aside and asks why she recommended brian be laid off, so she brings out the metrics and rankings and points to him near the bottom. the senior person asks "okay, so who are the top associates in your list? can you point them out on the seating chart?". turns out, the top five associates were all brian's neighbours, and the reason was that he was really good at helping people when they were stuck with something. but of course that affected his own individual contributor numbers, and there were no metrics for "helped someone else out but didn't get credit for it".&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42038653</guid></item><item><title>4. Hertz-dev, the first open-source base model for conversational audio</title><link>https://news.ycombinator.com/item?id=42036995</link><description>
&lt;![CDATA[
&lt;p&gt;280 points points by mnk47 on 2024-11-03T23:30:48 &lt;/p&gt;
&lt;p&gt;Introducing hertz-dev, the first open-source base model for conversational audio generation. A convolutional audio autoencoder that takes mono, 16kHz speech and transforms it into a 8 Hz latent representation at about 1kbps bitrate. The model has a context of 8192 sampled latent representations (17 minutes) and predicts the next encoded audio frame. We're excited to announce that we're open-sourcing current checkpoints of our full-duplex, audio-only transformer base model.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This is really cool. FWIW, existing open-source TTS engines are really bad in comparison to what you have here: I know this is voice-to-voice, but I think there'd be a lot of appetite to get this to also be multimodal and accept text (essentially making it a really good TTS model, in addition to a great voice-to-voice model).I suppose someone could hack their way around the problem by finetuning it to essentially replay Piper (or whatever) output, only with more natural prosody and intonation. And then have the text LLM pipe to Piper, and Piper pipe to Hertz-dev. But it would be pretty useful to have it accept text natively!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;They say Hertz is first of its kind but Moshi is another duplex audio model from earlier this year that seems to perform similarly (and it runs on a MacBook):
https://github.com/kyutai-labs/moshi&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Tesla’s approach to pure vision-based autonomous driving—temporarily setting aside lidar and other sensors—seems designed to make this technology more accessible and scalable. By focusing on a vision-only model, they can accelerate adoption and gather large datasets for quicker iterations. Once the vision-based system reaches a mature stage, I imagine Tesla might reintegrate additional sensor data, like lidar or radar, to refine their autonomous driving suite, making it even more robust and closer to perfection.Additionally, I’ve been exploring an idea about voice interaction systems. Currently, most voice interactions are processed by converting voice input into text, generating a text-based response, and then turning this text back into audio. But what if we could train the system to respond directly in voice, without involving text at all? If developed to maturity, this model could produce responses that feel more natural and spontaneous, possibly diverging from traditional text-to-speech outputs. Natural speech has unique syntax and rhythm, not to mention dialect and tone variations, which could make a purely voice-trained system fascinating and more human-like.Could you let me know if your current voice interaction model follows the standard speech-to-text-to-speech process, or if there is exploration in voice-to-voice processing?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42036995</guid></item><item><title>5. Alonzo Church: Architect of computer intelligence</title><link>https://news.ycombinator.com/item?id=42042025</link><description>
&lt;![CDATA[
&lt;p&gt;274 points points by drcwpl on 2024-11-04T14:51:10 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;A historical tidbit which I loved in Paradigms of Artificial Intelligence Programming (available in PDF and EPUB here - https://github.com/norvig/paip-lisp):&gt; The name lambda comes from the mathematician Alonzo Church's notation for functions (Church 1941). Lisp usually prefers expressive names over terse Greek letters, but lambda is an exception. A better name would be make-function. Lambda derives from the notation in Russell and Whitehead's Principia Mathematica, which used a caret over bound variables: x̂(x + x). Church wanted a one-dimensional string, so he moved the caret in front: ^x(x + x). The caret looked funny with nothing below it, so Church switched to the closest thing, an uppercase lambda, Λx(x + x) . The Λ was easily confused with other symbols, so eventually the lowercase lambda was substituted: λx(x + x). John McCarthy was a student of Church's at Princeton, so when McCarthy invented Lisp in 1958, he adopted the lambda notation. There were no Greek letters on the keypunches of that era, so McCarthy used (lambda (x) (+ x x)), and it has survived to this day.So, yes, on the topic of this post - Church pops up in loads of Lisp retrospectives. Maybe he's "forgotten" by people with very little engagement in the history of computing.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;"Church’s lambda calculus and the Turing machine are equally powerful but differ in the fact that Turing machines use mutable state. To this day, there is a rift between functional and imperative programming languages, because of the separation of Church and state."[I have known the above quote forever, but I can't find an original source]edit: might be from Guy Steele: "And some people prefer not to commingle the functional, lambda-calculus part of a
language with the parts that do side effects. It seems they believe in the separation of Church and state"&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;If you want to read something incredible about Church, read Rota's reminiscence. It's the first section of https://www34.homepage.villanova.edu/robert.jantzen/princeto....Related:Alonzo Church, 92, Theorist of the Limits of Mathematics(1995) - https://news.ycombinator.com/item?id=12240815 - Aug 2016 (1 comment)Gian-Carlo Rota on Alonzo Church (2008) - https://news.ycombinator.com/item?id=9073466 - Feb 2015 (2 comments)&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042025</guid></item><item><title>6. What should a logo for NeXT look like? (1986)</title><link>https://news.ycombinator.com/item?id=42042382</link><description>
&lt;![CDATA[
&lt;p&gt;222 points points by themantra514 on 2024-11-04T15:26:32 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The logo got a second lease of life after NeXT was acquired by Apple. A bit of British political trivia: Dominic Cummings, the campaign director of the Vote Leave organisation in the 2016 Brexit referendum, nicked the NeXT logo and made a few tweaks for Vote Leave:&gt; The logo was stolen from Steve Jobs. We couldn’t afford to hire a top agency and they wouldn’t have worked with us anyway. So I thought about Jobs’ advice on simplicity and ‘the best artists steal’ (see above!) and did some google searches. Surely there’s something he did with manic determination I could steal? After he left Apple in the 1980s, for his new company he got one of the top designers in the world to do a logo. I looked at it and thought, ‘good enough for Steve good enough for us, we can put a hole in the top so it looks like a ballot box’. Total cost: almost nothing. I made a lot of decisions like this because the savings in time and money were far greater than the marginal improvements of spending more time and money on them (if this would even bring an improvement).https://dominiccummings.substack.com/i/117842715/where-did-t...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I always go back to the Saul Bass presentation to AT&amp;T over their 1970 logo redesign. He takes 30 minutes to explain the thought process and sell this design hard. By the end you're convinced it's the natural thing to do. I'm sure every executive in the room felt the same way.https://www.youtube.com/watch?v=xKu2de0yCJI(Bass would return a mere 13 years later to do the AT&amp;T "Death Star" logo after the breakup)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; Set in all capitals, the word NEXT is sometimes confused with EXIT possibly because the EXT grouping is so dominant. A combination of capitals and lower case letters alleviates this problem.Huh. Never knew why the 'e' was lowercased until now. I thought it was just "style".&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042382</guid></item><item><title>7. An embarrassingly simple approach to recover unlearned knowledge for LLMs</title><link>https://news.ycombinator.com/item?id=42037982</link><description>
&lt;![CDATA[
&lt;p&gt;248 points points by PaulHoule on 2024-11-04T02:52:14 &lt;/p&gt;
&lt;p&gt;Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21\% of the intended forgotten knowledge in full precision, which significantly increases to 83\% after 4-bit quantization.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;In short: their finding is that quantizing a model undoes various “unlearning” methods. An unlearning method is a specific update to model weights that make it forget specific facts. These are often meant to satisfy copyright claims, although I don’t know if these are ever used in practice.I feel that this needs a good threat model analysis. Like, you possess an fp32 model, which someone has fine-tuned to forget some facts, which you can then quantize to recover those facts. When would this lead to a dangerous situation?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think quantization is a red herring. If there's any way to undo the unlearning, this means that the knowledge is still in the weights -- that's basic information theory. I'm sure there are a million other ways to recover the lost knowledge that don't involve quantization.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It's like asking baby to unlearn something "bad" it learned. Pretty much guaranteed the knowledge will be reinforced rather than forgotten.Whenever I hear about AI craze, I remind myself of the 3D printers craze from 10-15 years ago. "Death blow to factories", "We will print our own cars", "We will print our own food". I imagine LLM AI will follow the same fate - yes, but not really.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42037982</guid></item><item><title>8. Show HN: Tinder, but to decide what to eat</title><link>https://news.ycombinator.com/item?id=42036041</link><description>
&lt;![CDATA[
&lt;p&gt;242 points points by kiru_io on 2024-11-03T20:56:05 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I work for a startup that provides meal plans. This and competing apps let you set requirements (kcal, intolerances, etc), also includes breakfast, etc. These apps are aimed at people that want to eat healthy and are looking for some inspiration.You seem to go with user generated content, so the inspiration part is out, the health part is out, but you focus very much on the problem of forming a choice just for diner.I do think this way your audience is huge, but the added value is a bit limited.So you can decide to slowly move towards those other apps. Or, perhaps move away from it somehow. Maybe it's a generic tool to help you grow and maitain your relationship with your partner by providing tools that deal with each other preferences and choices within that relationship. Both practical and more emotional. But I guess I'm now more brainstorming :).You can also just keep it small and have fun tinkering in a way that works for you. I read a comment:&gt; There are servers needed for the app to work, right? So I guess subscription makes sense?Perhaps you don't really need servers. Keep the data just local on the app. Let people use regular chat for getting to a compromise. That way you could ask a one time fee of $5. It could be a (very) small passive income that doesn't require you much work, no moderation, no security risks.Either way, good luck!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I like the idea and face the same challenge. I’ve just installed it and, from my first impressions, it seemed a bit basic. Here’s what I expected:Hundreds of recipes that I could swipe left and right through, allowing me to build up a typical selection of what I would usually eat. Instead, I was presented with only three choices, none of which I would generally consider.A simple way to send the code to my wife — via imessage, Telegram, etc. Instead, I had to tell her in person! :)This presents the perfect opportunity to delve into shopping lists where the wife wants something healthy, and the I crave a burger. I can think of quite a few features you could add if the app develops further.Also, like the comment below about having a stranger over for dinner (not for dating purposes), it could involve a couple or someone visiting a new country who would appreciate a local showing them around and perhaps covering the dinner cost. Once the app learns your food preferences and interests, that could be quite exciting! There might already be an app that does this; I’m not sure.  Swiping left and right on both food likes / dislikes and also general interests.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Why not both? See what others around you want to eat, swipe together, meet up with a stranger in a restaurant and eat together. Maybe get to know them, maybe not.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42036041</guid></item><item><title>9. Writing secure Go code</title><link>https://news.ycombinator.com/item?id=42043939</link><description>
&lt;![CDATA[
&lt;p&gt;274 points points by gus_leonel on 2024-11-04T17:34:28 &lt;/p&gt;
&lt;p&gt;Security in Go code can be achieved by following a few specific practices. These practices will lead to writing robust, secure and performant code. The best way to stay informed about Go security announcements is to subscribe to the [email protected] list. The go vet command without arguments runs the tool with all options allowed by default. The tool scans the source code and reports potential issues. It also enforces Go language styling and suggests corrections with running staticcheck in the CI pipeline, we can install the code locally as a standalone binary.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;As the article also mentions: instead of checking if your program has a dependency on something that contains vulnerabilities, govulncheck checks if vulnerable code is actually reached. I find that so awesome. (And I know, someone is going to point out that hipster language foo does this too and better — it’s not the norm).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Don’t forget about capslock: https://github.com/google/capslockAssess your 3P modules for dangerous capabilities&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Great tips in here - I was not aware of `go vet` nor `go test -race`.FWIW, while go is not memory safe, I do find that it's much easier to be safe in go than it is in other languages. Its verboseness lends to a very clear understanding of what's happening in any given function. I absolutely hated this at the start, but now ~3 years into maintaining a go codebase, I find it quite nice both for debugging as well as editing old code. I know exactly what each function does, and what the structure of data is in any given context.Another interesting side effect is that AI tools seem to work amazingly well with golang, given how context is often local to the function.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043939</guid></item><item><title>10. Quincy Jones has died</title><link>https://news.ycombinator.com/item?id=42039569</link><description>
&lt;![CDATA[
&lt;p&gt;362 points points by gfortaine on 2024-11-04T08:13:45 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;As a jazz aficionado, I am very familiar with Quincy Jones’ immense contributions to music.  I am a very big fan of the albums he produced, such as “The Dude” and “Back on the Block.”What is less well known is Quincy Jones’ involvement with computing.  At one point he was on the advisory committee for the ACM Computers in Entertainment Magazine (https://dl.acm.org/doi/10.1145/973801.973803), and if I remember correctly, he was on the board of former Xerox PARC researcher Alan Kay’s Viewpoints Research Institute.  I’ve been wanting to know more about Quincy Jones’ involvement with computing since I first learned about this a few years ago.Rest in peace.  Quincy Jones is a legendary figure.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;When I was four, I got a record player for Christmas. This one:https://djcj.website/wp-content/uploads/2019/12/denim_turnta...My mom had a copy of Ray Charles' greatest hits. My favorite song was One Mint Julep. Quincy Jones did the arrangement. You can see by the wear on this record how much I listened to that song, as well as "Unchain My Heart" and "Hit the Road Jack."https://djcj.website/wp-content/uploads/2020/05/one-mint-jul...So much great music. And when you watch interviews with other musicians with whom he crossed paths, they all talk about what an uplifting and positive influence he had on their lives.Here's a interview with his longtime collaborator Tom Bähler. He has some really beautiful stories about his experiences with Quincy.https://youtu.be/yIkP_XuIDeY?t=5197And when he got together with Rod Temperton, the magic was next-level.https://www.facebook.com/QuincyJones/posts/ill-never-forget-...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;*From a strictly musical perspective, what have you done that you’re most proud of?*That anything I can feel, I can notate musically. Not many people can do that. I can make a band play like a singer sings. That’s what arranging is, and it’s a great gift. I wouldn’t trade it for shit.https://www.vulture.com/article/quincy-jones-in-conversation...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039569</guid></item><item><title>11. Diagram as Code</title><link>https://news.ycombinator.com/item?id=42044771</link><description>
&lt;![CDATA[
&lt;p&gt;339 points points by ulrischa on 2024-11-04T18:46:42 &lt;/p&gt;
&lt;p&gt;Diagrams lets you draw the cloud system architecture in Python code. It was born for prototyping a new system architecture without any design tools. Diagram as Code allows you to track the architecture diagram changes in any version control system. It currently supports main major providers including: AWS, Azure, GCP, Kubernetes, Alibaba Cloud, Oracle Cloud etc... It also supports On-Premise nodes, SaaS and major Programming frameworks and languages.NOTE: It does not control any actual cloud resources nor does it generate cloud formation or terraform code.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I quite like PlantUML, even for add a simple diagram to an email discussion which has become to long.My colleagues however like the idea but don't want to learn the syntax.So I build a simple add-on to our internal mail system that, when invoked, scrapes the email and runs it against a fine tuned Llama 3.1 8b model which then generates a PlantUML diagram from natural language.If the input isn't of an appropriate nature to be converted to a diagram or vague it will not do this.What I have found is that now at least 50% of the team have used this feature once since go-live.In many cases not all though, the immediately returned image is not 100% correct but there is a nice integrated way to edit and render which is now causing many to get familiar with the syntax whereas before they couldn't be bothered.Overall it's been a nice, relatively cheap way to get GenAI to actually help us at work.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This project (and others like it) are graphviz wrappers - they do some really cool stuff to emit styled .dot files that look better than writing and rendering raw gv.#Allowing specification in Python offers very little advantage - in theory you think, hey, I've got hi-lighting, autocompletion, and so on from an IDE. It'll play nice in VCS. Maybe I can interrogate orchestration layers and so on to produce dynamic views.In practice diagrams are produced by folks who might not want to use or learn python [or golang, their other implementation]. Instead a lean purpose-build DSL, maybe even an extension of graphviz dot, is easier and more portable for some audiences to pick up.
Secondly, we can't JUST graft a DSL front-end onto these tools because the styled components are baked into the project.My personal experience with layout engines is that they work OK for very small architecture diagrams, but become ugly or inelegant at useful scales.I (and the teams I've worked with) settle on draw.io, either the desktop app, or committed as part of confluence, as the best way to describe intent/design - and rendering graphviz with a style up top for anything dynamic.Would welcome seeing a true extension to the dot language that can unlock reasoning engines (like to do threat modeling) and render-time styling.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I personally have been using mermaid for sequence diagrams and flow charts: https://mermaid.js.org/DaC seems nicer for infra&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42044771</guid></item><item><title>12. DB48X: High Performance Scientific Calculator, Reinvented</title><link>https://news.ycombinator.com/item?id=42043747</link><description>
&lt;![CDATA[
&lt;p&gt;153 points points by qwezxcrty on 2024-11-04T17:19:34 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The 48G was a really good calculator, but only after loading additional software. The HP50g that came much later is better in every respect, except possibly for the smaller "ENTER" key (and people used to 48G will have to change some habits and possibly redefine some keys…).Incidentally, many young people (yes, I know how that sounds) do not know how useful a good engineering calculator can be and do not want to learn how to use one. They are missing out. Yes, there is a steep learning curve, but the rewards are significant if you do any amount of calculation in your hobby or work. No, this is not replaced by typing "python" (or "bc", or anything else, really) at your command prompt.Also incidentally, the development of good engineering calculators pretty much died. HP Prime is largely a school-pleasing toy, HP would down their calculator division a long time ago, and nobody else produces anything good. It's kind of like with gyms: what you get is what the market wants, and since the market doesn't know much, you get gyms full of useless exercise machines, because that's what people think a good gym should have. Similarly with calculators: you get stupid "modern" graphing calculators which are useless for actual work (it takes forever to use them to calculate useful things, and graphing is much better done on a computer), but they look great and sell well.I admire the project, although I would probably have taken a different path (emulation) to get the biggest effect with the smallest possible effort :-)I wish there was a good HP50G emulator for iOS — there used to be one, but it was abandoned (contact me if you want to develop it and would like to get the source code, it was under the GPL and I got it from the author).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I am a fan of the HP Primehttps://hpcalcs.com/product/hp-prime-graphing-calculator/But I use it in algebraic instead of RPN mode.  I’ve got a 49g and a 50-something too.People say it is pricey but I managed to get one discounted that was intended for the Latin American market.  So is the thing that software is supposed to run on.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I still have a HP48GX in perfect condition and love it. One of my first programs was to calculate how much „slower“ my time is running when I drive a car or fly in a plane compared to someone standing still on the sidewalk.I still find it much more comfortable having a real calculator… call me old fashioned.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043747</guid></item><item><title>13. A Hamiltonian Circuit for Rubik's Cube</title><link>https://news.ycombinator.com/item?id=42011976</link><description>
&lt;![CDATA[
&lt;p&gt;101 points points by jcalx on 2024-10-31T21:56:35 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;You can solve a (legally scrambled) Rubik's Cube with no knowledge of its initial state, as long as someone stops you when you've done it.You also need several billion years to do this, so it's not recommended for beginner solvers.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is neat, though it's from 2012 or maybe earlier.I wonder if there is a single not-too-long rotation sequence that generates the whole cube group.  That is, a sequence XYZ that you can perform repeatedly and have that bring you through every cube state.  If not, maybe there is some other very simple algorithm that traverses all the states, instead of a zip file that uncompresses to 200MB.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Bit of a meta note: grown adult here who never got into cubing earlier in life. Recently picked one up as some non-screen entertainment for some long haul flights and train travel. Highly recommend.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42011976</guid></item><item><title>14. Is the Q source the origin of the Gospels?</title><link>https://news.ycombinator.com/item?id=42040706</link><description>
&lt;![CDATA[
&lt;p&gt;155 points points by Tomte on 2024-11-04T11:55:30 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The Q hypothesis has issues. For such an important document or source, nothing is known about it. Its existence is not mentioned or hinted at in external sources. No trace of it has been found.In addition, the synoptic puzzle can be laid in a self-consistent and "path-of-least-resistance way" by looking at e.g. author motives: Matthew writing for the Jewish community in Jerusalem; Mark describing Peter's preaching in Rome; Luke writing as a Greek doctor for a gentile audience (and John writing much later, clarifying and responding to the first heresies that had popped up).So the Q hypothesis, aside from being a purely theoretical construction based on internal evidence, is not necessary either.See e.g. "Case Against Q: Studies in Markan Priority and the Synoptic Problem" by Goodacre.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Kind of odd to see this turning up here:  this theory isn't new and in fact is one of the couple most accepted theories about the origin of the gospels.  It was proposed more than a century ago, and this article doesn't say anything particularly new or interesting about it.  Honestly, the Wikipedia page is probably better:https://en.wikipedia.org/wiki/Q_source&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; The Farrer hypothesis proposes that Matthew used Mark as a source, but Luke used both Mark and Matthew as a source. This approach is simple and negates the need for a Q source altogether.&gt; A weakness of the Q source hypothesis is the absence of any textual evidence despite extensive scholarly efforts to find it. The entire hypothesis is based on statistical and literary analysis and inference. It adds complexity to the synoptic problem by introducing an additional layer of tradition, transmission, and composition, which may not be warranted given the available evidence (or rather lack thereof).Wouldn't Occam's Razor suggest that the Farrer hypothesis is most likely true?Edit: Or, maybe I should just continue reading to the end first:&gt; On the other hand, it would also make for a more complex explanation than other scholars have proposed, violating the principle of Occam’s Razor. Alternatively, Mark could have been the source for Matthew, and Matthew for Luke, which is a much simpler explanation than the Q hypothesis.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42040706</guid></item><item><title>15. PacCam: Pac-Man controlled with your face</title><link>https://news.ycombinator.com/item?id=42018740</link><description>
&lt;![CDATA[
&lt;p&gt;59 points points by bblcla on 2024-11-01T16:37:16 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Hello again Nolen, fun game! Tried the single player mode on mobile, works well and fast :)1. Why is there no "map"? I was confused as I expected a fixed grid for pacman to be able to navigate in2. Why are the bots so much faster? It is difficult enough to track my own character to ensure its moving in the right direction, so the fast bots really sneak up on me and there's no way to avoid them&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Love it! I think we'd get along - https://github.com/everythingishacked/CheekyKeys&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I wish there was some way to calibrate this.My webcam sits low on my desk (it's built into a laptop screen that is one of many) so it was almost impossible to look up without it saying "too far" and I had to curl around myself and hunch to get it to maybe register as looking down.I tried moving the display between monitors and that didn't help much.If I could calibrate what "straight ahead" is then I could maybe play the game.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42018740</guid></item><item><title>16. USFS Decision to Halt Prescribed Burns in California is History Repeating</title><link>https://news.ycombinator.com/item?id=42046596</link><description>
&lt;![CDATA[
&lt;p&gt;274 points points by danboarder on 2024-11-04T22:19:49 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&gt; This week, the U.S. Forest Service directed its employees in California to stop prescribed burning “for the foreseeable future,” a directive that officials said is meant to preserve staff and equipment to fight wildfires if needed.It sounds like it's a resourcing issue, not a change in philosophy.  It doesn't change the fact that it won't be happening though.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;California is in the middle of a huge fire insurance crisis. It started with the intentional housing supply restrictions that drove up property prices and rents. In suburban areas, rebuilding costs were mostly increased indirectly through higher wages (as tradespeople and laborers have to make rent.) This sent insurance rates through the roof and caused a wave of policy cancellations. Many insurance companies exited the market altogether [1].Climate change is also to blame. The firestorms of 2017, 2018 and 2020 broke all records, and were insanely expensive to rebuild after. The typical trigger is a katabatic wind event [2] after a long dry spell. This massively reduces relative humidity (often to 5-10%,) making ignition much easier. Once a fire starts, the wind spreads it extremely quickly. Sustained wind speeds of 50-60mph are not uncommon near mountain peaks.In 2017/2018/2020, the precipitating events were so intense that the initial responses focused exclusively on helping the residents out. By the time the actual firefighting began, the fires were already enormous.It's surprising to me that we haven't seriously looked into large-scale sprinkler systems, such as this one deployed in Spain [3]. These could take a major bite out of the initial uncontrolled stage. They could either be deployed in the wild along naturally defensible lines, or at the perimeters of inhabited areas.They're expensive upfront, but not as expensive as the alternative. They might also reduce the need for prescribed burns.[1] https://www.theguardian.com/us-news/article/2024/aug/10/home...[2] https://en.wikipedia.org/wiki/Katabatic_wind[3] https://www.wired.com/story/spanish-wildfire-defenses/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Slight tangent, USFS has been using outdated models for their prescribed burns, and burned as late as July in my area, right at the beginning of fire season and months away from any expected precipitation. This turned into a big wildfire in my area and they spent ~$100m putting it out. You may have been able to get away with burning during the summer in the 90's here, but not anymore.I'm not opposed to prescribed burns, either, I think they are totally necessary. But do them in the fall, when you've got nothing but rain and cool temperatures for the next 6 months, instead of weeks before the hottest and driest stretch of the year.As to why they burn in early summer, they said at a community meeting it's because it requires fewer people to manage the fire.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42046596</guid></item><item><title>17. Top discoveries about ancient people from DNA in 2023</title><link>https://news.ycombinator.com/item?id=42033913</link><description>
&lt;![CDATA[
&lt;p&gt;89 points points by softwaredoug on 2024-11-03T16:21:03 &lt;/p&gt;
&lt;p&gt;This year saw a lot of research consolidation, with continued progress along well-established lines. New techniques have opened up avenues of understanding kinship from ancient populations and the links between people and artifacts. Balancing selection can be a result of overdominance, where the relative fitness of an allele declines when the allele becomes very common, or balancing selection can happen when an allele has varied fitnesses in different times and places. Many fascinating questions about ancient people involve their social dynamics and their interaction with other ancient groups.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&gt; [On a sense of smell:] Denisovan missense variants had a stronger response than their human orthologs, which de March and coworkers narrowed down to “odors contemporary humans perceive as spicy, balsamic, and unpleasant”. Neandertals, on the other hand, had a much lower response for the missense variants which were found in these genes.I struggle to interpret this (not least because of the mis- prefix: does this mean incorrectly sensing? Does spicy in scent mean something that would map to food spices?) But does it mean that Denisovans would have disliked things we think of as smelling bad, far more than Neanderthals would? Would a Denisovan have bathed more for personal hygiene, or have avoided spicy food, or...? Would a Denisovan today have a strong aversion to some perfumes or colognes (the ones with woody, tobacco, musk scents)?There is this vague sense of wonder that there were human populations with preferences that were _different_ to our own.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It’s impressive how ancient DNA maps our origins though it feels like piecing together a story with missing chapters&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42033913</guid></item><item><title>18. We're Leaving Kubernetes</title><link>https://news.ycombinator.com/item?id=42041917</link><description>
&lt;![CDATA[
&lt;p&gt;384 points points by filiptronicek on 2024-11-04T14:41:28 &lt;/p&gt;
&lt;p&gt;Kubernetes seems like the obvious choice for building out remote, standardized and automated development environments. But Gitpod has found that Kubernetes is not the right choice. This is the story of how (not) to build development environments in the cloud. The many gigabytes of source code, build caches, Docker container and test data are subject to a high change rate and costly to migrate. Unlike many production services, there’s a 1-to-1 interaction between the developer and their environment. We found that many teams underestimate the complexity of operating a CDE.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Personally - just let the developer own the machine they use for development.If you really need consistency for the environment - Let them own the machine, and then give them a stable base VM image, and pay for decent virtualization tooling that they run... on their own machine.I have seen several attempts to move dev environments to a remote host.  They invariably suck.Yes - that means you need to pay for decent hardware for your devs, it's usually cheaper than remote resources (for a lot of reasons).Yes - that means you need to support running your stack locally.  This is a good constraint (and a place where containers are your friend for consistency).Yes - that means you need data generation tooling to populate a local env.  This can be automated relatively well, and it's something you need with a remote env anyways.---The only real downside is data control (ie - the company has less control over how a developer manages assets like source code).  I'm my experience, the vast majority of companies should worry less about this - your value as a company isn't your source code in 99.5% of cases, it's the team that executes that source code in production.If you're in the 0.5% of other cases... you know it and you should be in an air-gapped closed room anyways (and I've worked in those too...)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; This is not a story of whether or not to use Kubernetes for production workloads that’s a whole separate conversation. As is the topic of how to build a comprehensive soup-to-nuts developer experience for shipping applications on Kubernetes.&gt; This is the story of how (not) to build development environments in the cloud.I'd like to request that the comment thread not turn into a bunch of generic k8s complaints. This is a legitimately interesting article about complicated engineering trade-offs faced by an organization with a very unique workload. Let's talk about that instead of talking about the title!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;  &gt;Kubernetes seems like the obvious choice for building out remote, standardized and automated development environments

- Is it really Obvious Choice™ though Fred?- Hmm, let's consult the graphs.  &gt;Kubernetes is a container orchestration system for automating software deployment.

- It's about automating deployment Carl, not development environments!  &gt;Kubernetes is not the right choice for building development environments, as we’ve found.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42041917</guid></item><item><title>19. Unfortunate things about performance reviews (2021)</title><link>https://news.ycombinator.com/item?id=42039053</link><description>
&lt;![CDATA[
&lt;p&gt;205 points points by zargon on 2024-11-04T06:30:00 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I learned this in my very first corporate job at Factset and it made me sick of them; it's the main reason why I've worked at a bunch of startups.If the manager likes you, they will see the things you do in a positive light.If the manager doesn't like you, they will see the things you do in a negative light.So obviously, the solution is to optimize for always keeping the manager happy... except that that is a little dehumanizing.It's basically like any relationship coupled with confirmation bias. Basically, if you get onto the shit-list of your partner or friend or manager, it is difficult to get off it. People seem to automatically polarize their opinions about other people (probably due to confirmation bias) and then just apply post-hoc justification.If nothing else, I have gotten very good at noticing the change of tone when the point-of-no-return is reached (perhaps because I feel like I am terrible at avoiding it). You'll feel some queasiness/nausea after a conversation that went from friendly to critical based on something you perhaps flubbed... you'll start blaming yourself (even though you probably didn't actually have a ton of control over the outcome). Something will feel "off." Things won't feel as harmonious anymore. Details will be off- you didn't get invited to an important meeting that you are pretty sure you would have been invited to months prior. A new hire will get approved, but without anyone checking in with you first. You will feel like you are on the defensive and are working "defensively"- you're struggling to complete work or put presentations together or whatever- you're not sleeping well- those are all the feel of the ring ropes against your back, because you're actually on them, and you're in denial. It's hard not to take personally; has anyone actually ever been put on a PIP that made it back to "stellar performer", or are PIPs purely just lip-service to a CYA for the inevitable layoff?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt;&gt; If you take nothing else away from this post, take this: a sufficiently skilled manager can take the same body of work and make it work for you OR against you.This is pretty much the only thing that matters (unless you are really at one of the far extremes of the ability bell curve).&gt;&gt;About a year ago, I finally came to the conclusion that I would not put anything on a performance review writeup for a coworker that could ever be used against them.When I was a contractor, I was occasionally asked for feedback from permanent employee managers. As if I would say anything bad, even if I hated them.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Perf reviews are a terrible abstraction. The ranking and self-scoring and meetings and goal setting and stomach aching could be boiled down to a 5 item list:1. We want this person to leave. They probably should have been let go already.2. We wouldn't mind if this person left, but we aren't going to go out of our way until there are layoffs.3. This person provides adequate value, loyalty, and flexibility for their salary.4. This person is a key contributor and should be advanced if possible.5. We don't know why this person is still here, and we are terrified they might leave us when they realize how undercompensated they are.That's it. That's all perf reviews are for. No one needs to be stack ranked or anything silly like that. HR is an abomination.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039053</guid></item><item><title>20. Designing a Home Radio Telescope for 21 Cm Emission</title><link>https://news.ycombinator.com/item?id=42044494</link><description>
&lt;![CDATA[
&lt;p&gt;89 points points by antognini on 2024-11-04T18:21:59 &lt;/p&gt;
&lt;p&gt;This study presents the methodology for creating a cost-efficient radio astronomy telescope that can be used to detect 21 cm emissions. By measuring the Doppler shifts of the 21 cm emission, the velocities of hydrogen clouds relative to Earth can be determined. This enables the identification of these clouds' movements, their positions within the galaxy's spiral arms, and their roles in the overall rotational dynamics of the Milky Way. The setup is designed to be accessible to amateurs, enabling others to conduct similar projects.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I had a dish set up in London, 20 years ago (before I came out to the USA). Looked like #1. The dish splits into segments, and I recall driving down the M1 from Birmingham in my battered old Ford Escort, with the (razor-sharp) mesh segments squeezed in and wobbling right next to my jugular... Those dishes were getting vanishingly hard to find in the UK, so it was worth the trip, and I kept my neck intact with only minimal damage...I had it all packed up when moving out to the US (because my imagination told me that houses in the US were far larger than in the UK). The house I ended up buying (despite having a much larger back garden) didn't have the space to set it up again and remain married, so two decades later, it's still in that wooden case... I do, however, have an optical telescope set up (#2)Back then, we didn't have easy access to SDR's, so there's a feed horn, a down-converter, and I had an external (standalone) WinRadio receiver to  actually listen to the feed. That went into an audio card on a linux box, and the waterfall display was beautiful :)#1: https://imgur.com/a/CDrEeII#2: https://imgur.com/a/askar-130phq-scope-sb-myt-mount-26mp-cam...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Some pics of the OG detector from the 50s https://www.radio-astronomy.org/node/368The Purcell mentioned is the same one of NMR Nobel and E&amp;M textbook fame.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Page three of the paper shows an enviable rooftop antenna farm. Drool.I have an ignorant question ... can home/amateur radio astronomy ever produce layperson-appreciated "imagery"? Something easily understood like optical astronomy can produce? e.g. stitching together a sky scan for a particular emission or something?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42044494</guid></item><item><title>21. Limitations of frame pointer unwinding</title><link>https://news.ycombinator.com/item?id=42040549</link><description>
&lt;![CDATA[
&lt;p&gt;117 points points by rwmj on 2024-11-04T11:25:25 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Didn’t really get the point of the post as it just presents something without a conclusion.9X% of users do not care about a &lt;1% drop in performance. I suspect we get the same variability just by going from one kernel version to another. The impact from all the Intel mitigations that are now enabled by default is much worse.However I do care about nice  profiles and stack traces without having to jump through hoops.Asking people to recompile an _entire_ distribution just to get sane defaults is wrong. Those who care about the last drop should build their custom systems as they see fit, and they probably already do.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I added support to Sysprof this weekend for unwinding using libdwfl and DWARF/CFI/eh_frame/etc techniques that Serhei did in eu-stacktrace.The overhead is about 10% of samples. But at least you can unwind on systems without frame-pointers. Personally I'll take the statistical anomalies of frame-pointers which still allow you to know what PID/TID are your cost center even if you don't get perfect unwinds. Everyone seems motivated towards SFrame going forward, which is good.https://blogs.gnome.org/chergert/2024/11/03/profiling-w-o-fr...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I broadly agree with the thesis of the post, which if I understand correctly is that frame pointers are a temporary compromise until the whole ecosystem gets its act together and manages to agree on some form of out-of-band tracking of frame pointers, and it seems that we'll eventually get there.Some of the statements in the post seem odd to me though.- 5% of system-wide cycles spent in function prologues/epilogues? That is wild, it can't be right.- Is using the whole 8 bytes right for the estimate? Pushing the stack pointer is the first instruction in the prologue and it's literally 1 byte. Epilogue is symmetrical.- Even if we're in the prologue, we know that we're in a leaf call, we can still resolve the instruction pointer to the function, and we can read the return address to find the parent, so what information is lost?When it comes to future alternatives, while frame pointers have their own problems, I think that there are still a few open questions:- Shadow stacks are cool but aren't they limited to a fixed number of entries? What if you have a deeper stack?- Is the memory overhead of lookup tables for very large programs acceptable?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42040549</guid></item><item><title>22. Cheap Thrills, an album cover by Robert Crumb (2020)</title><link>https://news.ycombinator.com/item?id=42039935</link><description>
&lt;![CDATA[
&lt;p&gt;172 points points by stareatgoats on 2024-11-04T09:35:19 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Robert Crumb was interviewed for a BBC Radio 3 program where he played some records from his collection and talked about them.One song was particularly fascinating: a primitive attempt at the new fangled sound called 'jazz' by a French country musette band from the early 20th C.Crumb explained that when early American jazz bands went to Paris in the 1910s, the new sounds caused a sensation when they performed in the up-market venues. So the country bands were aware of the new style of jazz but most people had never actually heard any and had to play what they imagined jazz to be, mostly based off verbal descriptions. I remember this record as a crazy sound, but brilliantly entertaining.Unfortunately I can't point you to the song or the interview, but if anyone else can please reply :-0&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Crumb has been living in a small village in the south of France since the 90's.In the "Crumb" doc he says something along "They're all wearing baseball hats. I'm getting out of here.", speaking about the US.He also laments having taken too much LSD.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The intro about him not liking the music reminded me of the Letter of Note entry when Crumb is sent an experimental jazz album and replies to the musician:https://lettersofnote.com/2015/12/17/torturing-the-saxophone...&gt; I gotta tell you, on the cover of the CD of your sax playing, which is black and has no text on it, I wrote in large block letters, in silver ink, “Torturing The saxophone—Mats Gustafsson.” I just totally fail to find anything enjoyable about this, or to see what this has to do with music as I understand it, or what in God´s name is going on in your head that you want to make such noises on a musical instrument. Quite frankly, I was kind of shocked at what a negative, unpleasant experience it was, listening to it.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039935</guid></item><item><title>23. The history of Unix's ioctl and signal about window sizes</title><link>https://news.ycombinator.com/item?id=42039401</link><description>
&lt;![CDATA[
&lt;p&gt;109 points points by ingve on 2024-11-04T07:39:27 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I submitted the proposal for `tcgetwinsize` to POSIX a few years ago.  I originally wrote it because I was sick of having to turn off _POSIX_C_SOURCE for just a single file to get glibc to expose TIOCGWINSZ.SIGWINCH and the TIOCGWINSZ ioctl() were originally omitted from POSIX as they were considered relevant for windowing systems only and GUI-stuff was considered out of scope for POSIX.  Furthermore, POSIX only specifies ioctl() for STREAMS; other interfaces that traditionally use ioctl() calls are specified in POSIX using wrapper functions (which is what the new interface is; it is specified such that you can implement it just by wrapping the traditional TIOCGWINSZ/TIOCSWINSZ ioctl calls).My original proposal had functions tcgetsize() and tcsetsize(), but it turns out that QNX already uses these identifiers with an incompatible signature, so a last minute change was made to name these tcgetwinsize() and tcsetwinsize().Furthermore, the winsize structure traditionally also has ws_xpixel and ws_ypixel members indicating the resolution of the terminal.  This existed primarily becaus on some historical virtual terminals, a client could change the video mode by calling the TIOCSWINSZ ioctl, providing resolution and row/column count for the desired video mode.  While no current virtual terminal known to me supports this, the POSIX spec mandates that if a slave PTY calls tcsetwinsize(), the window size update is propagated to the master, allowing terminal emulators to implement this feature if desired.  Another objection raised was that the traditional unsigned short type may be insufficient for future high-definition screens and a resolution may not be well defined for some types of terminals like hardcopy or braille terminals.I maintain that submitting a feature to POSIX and waiting for a new version of the standard to be released is probably the easiest way to get glibc to implement a feature you want.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;For anybody wondering "why couldn't they just...", there is a lot of complexity in TTYs and PTYs. The kernel is even involved in line discipline and job control. Those Ctrl+Z or Ctrl+C keys you press? The kernel gets involved.It may seem strange that there's a process signal for window-size changes, but that's what was needed back in 1985. There's a similar dance with the Amiga's console.device, but both Unix and Amiga TTYs are better than Windows' terminals where there was no such thing as a PTY until Windows 10, you had to make direct API calls, and even now it's still pretty slow: https://devblogs.microsoft.com/commandline/windows-command-l...This page is a great overview pf the Unix TTY/PTY subsystem: https://www.linusakesson.net/programming/tty/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Terminals, ttys, etc. have some of the most arcane and outdated APIs I am aware of. It's like a window back into the 1970s&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039401</guid></item><item><title>24. Show HN: Convert any website into a React component</title><link>https://news.ycombinator.com/item?id=42043552</link><description>
&lt;![CDATA[
&lt;p&gt;214 points points by alexdanilowicz on 2024-11-04T17:03:00 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Your actual product is really slick.  Even just with some basic tests I can see that it produces designs with a much higher degree of polish than regular LLM models, and with much more of a design bent.  I'll definitely use this for some prototyping this week!I wonder what changes you've made from standard LLMS to get here?  I could imagine trying to put things on guard rails, giving it some components to build off, or just fine tuning based on a really nice corpus of good websites (maybe generated with this tool).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is a very useful browser extension. Really love the fact that you are even able to convert the styles to TailwindCSS. Very clever.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I am going to be that person, but how is the copyright for the output of tools like this? Since not all websites include license on their site, yet their looks are replicated, this might be even less clear than with LLMs in general.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043552</guid></item><item><title>25. DataChain: DBT for Unstructured Data</title><link>https://news.ycombinator.com/item?id=42043948</link><description>
&lt;![CDATA[
&lt;p&gt;121 points points by shcheklein on 2024-11-04T17:34:57 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Yay! Excited to see DataChain on the front page :)Maintainer and author here. Happy to answer any questions.We built DataChain because our DVC couldn't fully handle data transformations and versioning directly in S3/GCS/Azure without data copying.Analogy with "DBT for unstractured data" applies very well to DataChain since it transforms data (using Python, not SQL) inside in storages (S3, not DB). Happy to talk more!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Cool!  Does this assume the unstructured data already has a corresponding metadata file?My most common use cases involve getting PDFs or HTML files and I have to parse the metadata to store along with the embedding.Would I have to run a process to extract file metadata into JSONs for every embedding/chunk? Would keys created based off document be title+chunk_no?Very interested in this because documents from clients are subject to random changes and I don’t have very robust systems in place.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It took me a minute to grok what this was for, but I think I like itIt doesn't really replace any of the tooling we use to wrangle data at scale (like prefect or dagster or temporal) but as a local library it seems to be excellent, I think what confused me most was the comparison to dbt.I like the from_* utils and the magic of the Column class operator overloading and how chains can be used as datasets. Love how easy checkpointing is too. Will give it a go&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043948</guid></item><item><title>26. Interview gone wrong</title><link>https://news.ycombinator.com/item?id=42020103</link><description>
&lt;![CDATA[
&lt;p&gt;135 points points by ashu1461 on 2024-11-01T18:32:28 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;If you know nothing about Python or coding, and you see a=b=c, you'd think that's true when all three a,b,c are the same. Python does that beautifully here, and that's the intent. It's not Python that's confusing, it's your previous experience with other languages that's confusing you.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I know the point of the piece is the python syntax here, but I got stuck on: "judge things like code quality / speed / conciseness etc."Do people generally write concise code on right off the bat when confronted with a new problem? I've always taken the same approach I would with writing: get something that works; refactor for concision. Maybe everyone else is playing 3D chess and I'm still on Chutes and Ladders?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I'm confused about this blog post. Python is mostly C inspired but actually more pseudocode inspired (which helps its popularity) which is why chained expressions exist.Also, why would you conduct an interview in a language where even if you don't know the syntax (and this is obscure) you could have looked it up or disallowed the interview to be done in Python? I think the due diligence with this issue is more to the interviewer than Python.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42020103</guid></item><item><title>27. Back to the future: Writing 6502 assembler with Amazon Q Developer</title><link>https://news.ycombinator.com/item?id=42043549</link><description>
&lt;![CDATA[
&lt;p&gt;69 points points by ingve on 2024-11-04T17:02:38 &lt;/p&gt;
&lt;p&gt;In this short post I have some fun with Amazon Q Developer and get it to write code that runs on my virtual Commodore 64. Here is the code it produced. It runs.....well almost. I see a square sprite move smoothly across the screen and when it gets to the end it crashes with the following error:Illegal quantity error in 200I turn to Amazon Q to help me fix this issue, asking it to resolve this error. It quickly provides me with updated code and an explanation of why I got the error. This correction ensures that the high bit of the sprite's X coordinate is set correctly when the sprite moves beyond the 255th pixel, allowing it to move across the entire width of the screen. After looking at some Redit groups, it is clear that the way to use the 6502 assembler tool is the way forward.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This raises the question: what information did Amazon Q ingest to be able to write C64 Basic, and from where – OCR'd books and magazine off Google Books? Online tutorials? That would explain whether it would be possible to adapt this workflow to supporting other relatively obscure platforms, with a limited documentation set that's certainly not available online on the internet in easily parsable HTML: e.g. PDP-11 assembly, Turbo Pascal, classic Macintosh/Macintosh Toolbox, etc.Who knows, it might be a shot in the arm for retrocomputing enthusiasts.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;  // Zero page variables
  .const zp_x = $FB
  .const zp_y = $FE
  .const zp_dx = $101
  .const zp_dy = $104

AI extended zero page, I see… (zp_dx and zp_dy are in 6502 hardcoded stack range, not in zero page at all).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Author of the post here. Just reading the comments so apologies for getting some of the terminology wrong. The intention was never to mislead folk , just wanted to share my enthusiasm for emulation and the fact that you could get working code.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043549</guid></item><item><title>28. Data Commons</title><link>https://news.ycombinator.com/item?id=42005646</link><description>
&lt;![CDATA[
&lt;p&gt;49 points points by zerojames on 2024-10-31T11:18:49 &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Used as grounding by Google's DataGemma model https://blog.google/technology/ai/google-datagemma-ai-llm/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;How is this built? What'd be the approach if I'd like to achieve similar results against proprietary data.References article speak of RAG and RIG - but I wonder if they factor into fine-tuning the models. AFAIK, RAG doesn't play nicely with structured data.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42005646</guid></item><item><title>29. It's called a dance floor</title><link>https://news.ycombinator.com/item?id=42042810</link><description>
&lt;![CDATA[
&lt;p&gt;131 points points by wmeredith on 2024-11-04T16:04:07 &lt;/p&gt;
&lt;p&gt;Vogue is an RIAA-certified triple-platinum hit, selling over six million copies since its 1991 release on the "I'm Breathless" album by pop mega-star Madonna. Vogue topped charts in Australia, Canada, Japan, the United Kingdom, and the United States. It has been sampled by Kylie Minogue, Beyoncé, and Ariana Grande. The track starts with a startling, sweeping vocal line, "What are you looking at?" that pans around our heads like Michael Bay's camera.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;QSound was magic at the time. We had a DSP class in my EE degree where we implemented a very minor transform that would shift position of audio and it was wild.It's impossible to get 3D audio to be absolutely as flawless as the real world because human ears all vary slightly and your 3D spacial perception of sound is literally tuned on your own ears, but QSound's transfer functions come as close as you can get.The algorithm also falls apart a bit outside of the sweet spot, and is really only useful in headphones and specific cases where a human is known to be placed in a certain location relative to speakers.The original model was developed using a simulated human head and lots of hand-tuning. I am curious if we've advanced far enough with tech that a more modern set of transfer function parameters could be developed.Nothing beats N speakers for positional audio, but this is a pretty decent replacement if the conditions are ideal.OpenAL was designed as an open-source library to bring 3D audio to the masses in the same way that OpenGL did (basically exposing QSound/equivalent hardware on sound cards to an API), but I'm not sure what happened to it [1].[1] https://www.openal.org/documentation/openal-1.1-specificatio...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;If you like this kind of stereophonic sound, I recommend Art of Noise. Here are some songs from them:Moments in Love: https://www.youtube.com/watch?v=uNkcZ8QoNuIParanoimia: https://www.youtube.com/watch?v=5F8BD6gNOagDragnet '88: https://www.youtube.com/watch?v=f6JQO0KnUZYI recommend to set the videos to the highest quality and to listen using headphones&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I remember being shown Virtual Barbershop on 2000s YouTube as a teenager. I was absolutely blown away by the experience, it did for my ears like what 2024 VR does for my eyes. Total magic.https://www.qsound.com/demos/virtualbarbershop_long.htmVery cool to see it’s from the same company!&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042810</guid></item><item><title>30. HardenedBSD Feature Comparison with OpenBSD, FreeBSD, NetBSD</title><link>https://news.ycombinator.com/item?id=42036652</link><description>
&lt;![CDATA[
&lt;p&gt;97 points points by transpute on 2024-11-03T22:35:16 &lt;/p&gt;
&lt;p&gt;This page includes a summary of HardenedBSD's features. Use this summary to help you with reading comprehension and vocabulary. At the bottom of the page, please share your feedback about the features you have seen on this page and the other Hardened FreeBSD features. The Hardened BSD Wiki is a free, open-source, community-driven software project that aims to improve the performance of BSD systems. For a more detailed and up-to-date guide to Hardened. BSD features, please visit our wiki.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;It's easy to invent a chart that only you can get a nearly perfect score on.This does nothing to explain what any of these features are, what are "Boot hardening" and "sysctl hardening"?At least OpenBSD's innovations page makes an attempt to explain new concepts and features that have been developed over the years, and people can make any comparisons for themselves.https://www.openbsd.org/innovations.html&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Read these claims with a pretty big asterisk.  Implementation quality of HBSD features is often poor or very poor.  https://www.fabiankeil.de/gehacktes/hardenedbsd/ is just one example.  Specifically some of the changes made to "harden" the system are pretty dubious and introduce new bugs, possibly security relevant, that did not previously exist.  No one runs or pen tests HBSD.  It's even more niche than OpenBSD.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; Executable file integrity enforcementI assume but don't know for sure that this refers to Veriexec in NetBSD, and I'm not sure what in HardenedBSD. Anyone know?https://man.netbsd.org/veriexec.8My understanding is that Veriexec isn't enabled by default - the manpage says only that "[s]ome kernels already enable Veriexec by default." If you have this enabled, how do you upgrade binaries? The manpage says that in strict mode 1, write access to monitored binaries is allowed but then access is denied. So I assume that after file modification, root then runs veriexecgen and veriexecctl load as mentioned in the manual to update the signatures list. So it seems that strict level 1 isn't functionally different from a read-only /usr or even just root-owned binaries. In either case, you just need root to update targeted binaries. Surely I'm missing something and would appreciate some insight.At a glance as an outsider, stricter modes appear somewhat functionally similar to "chflags schg" on BSD systems, where more work is needed to get around restrictions. In the case of schg, you have to reboot into single user mode, remove the schg flag, then modify the binary, and continue booting into multi-user mode. You could do this as a remote attacker (as in not having console access) depending on what boot files are or aren't protected with schg, but modifying all the necessary files can be a source of new problems.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42036652</guid></item><item><title>1. Hacking 700M Electronic Arts accounts</title><link>https://news.ycombinator.com/item?id=42052143</link><description>
&lt;![CDATA[
&lt;p&gt;856 points points by mooreds on 2024-11-05T15:18:34 &lt;/p&gt;
&lt;p&gt;The website article discusses the issue of EA (Electronic Arts) account takeover and provides tips on how users can protect their accounts from being compromised. It explains the methods used by cybercriminals to gain unauthorized access to accounts and suggests security measures such as enabling two-factor authentication, using unique and strong passwords, and staying vigilant against phishing attempts. The article aims to educate and raise awareness about account security to help users safeguard their accounts from potential breaches.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Ea loves using generic systems across all their games. When poking around at Madden I found they have a common backend called blaze that has generic web and tcp endpoints. We built out a tool to call these endpoints (having to upload xml) and only later found out that every time we made the call it was crashing their servers but since we were grabbing a new server each request we were crashing all of their madden servers one by one. They ended up building an API to discourage people poking around&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;    So, like any sane person would, I overnighted an Xbox, installed Battlefield 2042, and waited for the moment of truth...
     
    I was in!

I love hackers &lt;3&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I enjoyed the detailed explanation of how he moved from point to point. I imagine it wasn't as straightforward as is laid out in a blog postIt would be interesting to see what I imagine to be the reams of notes from one of these to show how much time and effort it takes to perform this kind of attack.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:46:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42052143</guid></item><item><title>2. Hacker Fab</title><link>https://news.ycombinator.com/item?id=42051968</link><description>
&lt;![CDATA[
&lt;p&gt;426 points points by ipnon on 2024-11-05T14:59:15 &lt;/p&gt;
&lt;p&gt;The website provides information about Hacker-Fab Space, a collaborative workspace aimed at fostering creativity, learning, and innovation within the hacker community. It offers tools, resources, and opportunities for individuals to experiment, share knowledge, and engage in hands-on projects. The space encourages networking and skill development through workshops, events, and open project nights, creating a supportive environment for makers and hackers to collaborate and grow.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;When we saw a rise in 3d printing, I was very hopeful that a hobbyist movement towards fabricating large-feature ICs would soon arise. Nobody's doing 4nm fabrication in their garage, I reasoned, but surely we could get to ~10um.As I read more about the dark art of IC fabrication, though, I realized that even this was a faint dream. I had imagined a world of lasers carving troughs, and print heads carefully placing down the lines and doping the silicon, an elegant symphony of modern technology.But the real world is much messier -- every stage involves dangerous and toxic chemicals, processes that are spoiled by a spec of dust in the wrong place, either causing a cascade of reagent failures or a physical impediment to correctness; distressingly analog and oh so messy and built by trial and error and refined by domain experts in ways that are intensely hard to replicate because all the same lessons need to be learned again each time.I'm glad to see the work being done here for hobbyist fabrication, but barring huge leaps and bounds, the gap between the neat lines in Magic and the shiny silicon discs is a vast chasm owned by the material scientists, not the electrical engineers or the software engineers.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Nobody seems to have mentioned electron beam lithography. Hobbyists have done that.[1]E-beam lithography has been used since the 1970s. It's slow; it might take a day to make a CPU. That's why it's not used as a production process. But as a prototype process, it works fine. There are a few hobbyists doing this.[1]E-beam systems are basically scanning electron microscopes with more power. There's a vacuum chamber, means for focusing and steering an electron beam similar to what's inside a CRT, and control equipment. It's all computer-controlled, of course.This has many advantages. Software can correct for nonlinearities in the scanning. The machine can inspect what it's written by scanning at low power.You still have to coat and etch; it's not a dry process. The beam just exposes photoresist.The equipment is the size of a desk. Here's a machine at CMU.[2] Many universities have such machines.[1] https://hackaday.com/2024/08/06/creating-1%c2%b5m-features-t...[2] https://nanofab.ece.cmu.edu/facilities-equipment/fei-sirion....&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;While I'm sympathetic to democratizing access to simple fabrication technology, I have serious misgivings about hobbyists getting involved.There's the obvious stuff: you can't avoid HF, and it's nasty stuff. You can die. But that's not what I'm the most worried about; people can make smart decisions to reduce risk, and ultimately people can make their own decisions about their risk tolerance.What I'm worried about is the SF6 for the RIE. Kg for kg, that stuff has a global warming potential of more than 24,000 TIMES the warming potential of CO2. If it's all broken down in the plasma chamber, or there's exhaust scrubbers involved like you'd have at an industrial fab, then it's no issue.But hobbyists are going to be spilling and purging a bunch of unmodified SF6. It's kind of an ecological catastrophe. Some things are better not done at home.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051968</guid></item><item><title>3. Failure analysis of the Arecibo 305 meter telescope collapse</title><link>https://news.ycombinator.com/item?id=42051368</link><description>
&lt;![CDATA[
&lt;p&gt;227 points points by mhb on 2024-11-05T13:37:42 &lt;/p&gt;
&lt;p&gt;The website discusses the health effects of cannabis and cannabinoids, examining the potential therapeutic benefits and risks associated with their use. It explores the role of cannabis-derived compounds in addressing medical conditions such as chronic pain, cancer-related symptoms, and multiple sclerosis. The report addresses various delivery methods and formulations of cannabinoids, highlighting the need for continued research to better understand their effects on health and to inform medical practice and policy decisions.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;In the summary they state:All the reported experimental zinc electroplasticity (EP) data were developed at current densities orders of magnitude higher than those possibly present in the Arecibo Telescope but measured in laboratory experimental periods that were orders of magnitude shorter than the telescope's socket zinc service.There are no reported experimental data concerning low-current, long-term EP, which the committee has lumped together under the term "LEP", affecting zinc's creep mechanisms over decades.The timing and patterns of the Arecibo Telescope's socket failures make the LEP hypothesis the only one that the committee could find that could potentially explain the failure patterns observed.Accelerated aging is, as far as I know, pretty much standard in the industry. Nobody can wait 20 years to find out if a certain material is good enough or not.However, the real failure seems to be the lack of urgency when they signs started to show up:Upon reflection, the unusually large and progressive cable pullouts of key structural cables that could be seen during visual inspection several months and years before the M4N failure should have raised the highest alarm level, requiring urgent action. The lack of documented concern from the contracted engineers about the inconsequentiality of the cable pullouts or the safety factors between Hurricane Maria in 2017 and the failure is alarming.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Even if I am not a radio astronomer, this instrument was unique in nature and still in use for very specific observations and until the very end of its operation was able to deliver data. It is disheartening to learn that it was indeed due to gross maintenance negligence (as assumed originally by many) that the final fatal failure occurred, when potentially the structure could have been salvaged.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Practical Engineering on YouTube has an episode covering the collapse of this structure[1]. It's very good and worth a watch.[1] https://youtu.be/3oBCtTv6yOw&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051368</guid></item><item><title>4. AMD outsells Intel in the datacenter space</title><link>https://news.ycombinator.com/item?id=42054449</link><description>
&lt;![CDATA[
&lt;p&gt;458 points points by baal80spam on 2024-11-05T19:27:15 &lt;/p&gt;
&lt;p&gt;The article discusses how AMD has outsold Intel in the data center space for the first time ever, marking a significant milestone in the competitive CPU market. The shift in market share is attributed to AMD's recent success and growing popularity in delivering high-performance processors designed for data center use, challenging Intel's long-standing dominance in the industry.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Oh my, allow me to reminisce.When the Intel 80386-33 came out we thought it was the pinnacle of CPUs, running our Novell servers!   We now had a justification to switch from arcnet to token ring.  Our servers could push things way faster!Then, in the middle 1991, the AMD 80386-40 CPU came out.  Mind completely blown!  We ordered some (I think) Twinhead motherboards. They were so fast we could only use Hercules mono cards in them; all other video cards were fried.  16Mb token ring was out, so some of my clients moved to it with the fantastic CPU.I have seen some closet-servers running Novell NetWare 3.14 (?) with that AMD CPU in the late '90s.  There was a QUIC tape &amp; tape drive in the machine that was never changed for maybe a decade?  The machine never went down (or properly backed up).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Damn, first Intel missed out on Mobile, then it fumbled AI, and now it's being seriously challenged on its home turf. Pat has his work cut out for him.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Surprising it took so long given how dominant the EPYC CPUs were for years.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054449</guid></item><item><title>5. Machines of Loving Grace</title><link>https://news.ycombinator.com/item?id=42045509</link><description>
&lt;![CDATA[
&lt;p&gt;230 points points by greenie_beans on 2024-11-04T20:05:19 &lt;/p&gt;
&lt;p&gt;The website discusses the rise of artificial intelligence and its impact on the future of work, exploring the concept of 'machines of loving grace' - a term that refers to the possibility of advanced technology enhancing human potential and well-being. It delves into the potential benefits and challenges that AI and automation may bring to society, offering thought-provoking insights on how we can navigate this transformative technological landscape.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&gt; Yet, I am shocked when AI does not stop Outlook Messenger from bursting confetti across my desktop in response to the Congratulations reply I receive when HR misreads my email about both adding and removing our late son from my health insurance.Echoes of Facebook showing people “memories” (photos) of their deceased children on their bday. This is one of the saddest stories I’ve read in a bit.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Adam Curtis made a fantastic documentary on the darker side of our relationship with technology. I don't agree with all of his points, but it's still a great watch.From Wikipedia: Curtis argues that computers have failed to liberate humanity, and instead have "distorted and simplified our view of the world around us".https://en.wikipedia.org/wiki/All_Watched_Over_by_Machines_o...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;brutal story. for those who were equally confused this post seems to have the same title as but is unrelated to Dario Amodei's recent https://darioamodei.com/machines-of-loving-grace - is perhaps a nice/bittersweet reality check on how our designs often fall short of our ambitions.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42045509</guid></item><item><title>6. Show HN: rallyup – Lightweight Wake-on-LAN Scheduler</title><link>https://news.ycombinator.com/item?id=42050862</link><description>
&lt;![CDATA[
&lt;p&gt;136 points points by darwindarak on 2024-11-05T12:04:14 &lt;/p&gt;
&lt;p&gt;This page provides information about a tool called RallyUp developed by Darwin Darak, designed for performance measurement and data recording in the context of rally racing. It outlines the features of the tool, such as real-time speed and distance tracking, as well as elevation profiles and split times, to assist rally drivers in analyzing and improving their performance. Users can find the code, contributing guidelines, and project updates on this GitHub page.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Very nice, just FYI for home assistant fans: WoL is also supported in there :)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Isn't it bad design in the first place if you require "right order" of boot up? What if some, but not all, servers crash and reboot? How do you ensure the correct order in that case?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;One thing that might be useful is to allow a given server in the chain to fail. For example, if you had a Proxmox (or other hypervisor) cluster, in the event that a single node fails to come up, you'd probably want everything else to still boot. Or maybe it would be easier if there was a separate category for VM vs. hypervisor?Either way, neat project, and thank you for sharing.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42050862</guid></item><item><title>7. Facebook building subsea cable that will encompass the world</title><link>https://news.ycombinator.com/item?id=42041581</link><description>
&lt;![CDATA[
&lt;p&gt;269 points points by giuliomagnifico on 2024-11-04T14:00:59 &lt;/p&gt;
&lt;p&gt;The website discusses Facebook's plans to construct a new subsea cable project called "Bifrost" that will connect the United States, Europe, Africa, and the Middle East, enhancing global internet connectivity. The construction of this cable aims to address the increasing demand for data transmission capacity and speed, with Facebook collaborating with various partners to ensure successful deployment and operation of the infrastructure.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;FYI, this is NOT the cable Facebook is planning to build, this is the dream cable of a submarine cable… enthusiast? From LinkedIn: “To be clear, this is not Meta's plan or map. This is Ver "T" and T stands for Tagare. It's what I think is going to happen to this cable if I was designing it. This is my wish list.”https://www.linkedin.com/pulse/map-metas-w-cable-sunil-tagar...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Highly recommend an article by The Verge on how these things are repaired and maintained.https://www.theverge.com/c/24070570/internet-cables-undersea...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;So do we sometimes lay cables on top of other cables down there?What governments do you have to go to to get approval to do this? Could I just run a string across the Atlantic Ocean?If we do lay cables on top of other cables how high do they get stacked? Are there challenges to bring the lower cables back up? Does that happen? Or do we just keep them down there forever basically and upgrade the hardware at the terminal?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42041581</guid></item><item><title>8. Blog Writing for Developers (2023)</title><link>https://news.ycombinator.com/item?id=42045477</link><description>
&lt;![CDATA[
&lt;p&gt;243 points points by mooreds on 2024-11-04T20:01:57 &lt;/p&gt;
&lt;p&gt;The website article provides guidance and tips on blog writing specifically tailored for developers. It covers topics such as finding inspiration for blog content, structuring posts effectively, balancing technical details with engaging writing, and promoting blog posts to reach a wider audience. Overall, it aims to help developers enhance their writing skills and create compelling and useful content for their audience.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I’ve been writing a technical blog for over 20 years, and I believe that each blog post helps me think more deeply, examining every source and related code carefully. This process has been incredibly valuable to me, and even in the LLM era of 2024, I still enjoy blogging. Often, the primary user of my blog is myself; I go back to my past entries to help guide further research and exploration.I once heard a senior developer say, 'I’m not shy to admit that after I finish a blog post, I’m at ease to forget about it—because I know I can always look it up again.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The author suggests everyone should watch the Larry McEnerney lecture but he seems to have missed a pretty important point from that lecture.A really big point Larry tries to make during his lecture is that there are 2 types of writing. One you do for yourself (to help clear your ideas) and the other and the other one is designed to valuable to the reader.And he is pretty obsessed with the idea of writing valuable text. He even says that if your text isn't valuable there is no point in making it persuasive, organized or clear.For me this was a pretty interesting revelation. For most of my life I had this idea that the quality of the content and the quality of the writing were tightly related. And this idea made me believe that if you have good content, good writing should follow naturally.After watching this lecture I realized that content and writing are separated axis, and you can definitely have one without the other. LLMs are pretty good at writing without content, for example.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;My biggest challenge with writing blogs/newsletters is the fear of publishing, not getting it "perfect", or being horribly wrong about whatever I'm writing about.To get over this I just made simple personal blog/site using GH pages/jekyll/markup that doesn't have 1. A marketing version of a "publish" function and 2. the posts are perpetually in DRAFT.Basically there is no 'done' which leaves me more comfortable in putting my thoughts on the internet instead of leaving them in my head. I can keep going back to the ideas and refining them.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42045477</guid></item><item><title>9. Every boring problem found in eBPF (2022)</title><link>https://news.ycombinator.com/item?id=42018195</link><description>
&lt;![CDATA[
&lt;p&gt;158 points points by udev4096 on 2024-11-01T15:50:56 &lt;/p&gt;
&lt;p&gt;The website showcases a series of photographs with captions that humorously depict common workplace frustrations and scenarios, such as dealing with difficult colleagues, technology malfunctions, and mundane tasks. The images aim to provide a lighthearted perspective on office life and evoke solidarity among individuals who can relate to these humorous situations.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;BPF recently got published as an RFC[1], posted here[2] today and earlier here[3][4].[1]: https://datatracker.ietf.org/doc/html/rfc9669[2]: https://news.ycombinator.com/item?id=42051950[3]: https://news.ycombinator.com/item?id=42024377[4]: https://news.ycombinator.com/item?id=42038371&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;By the way, this article is published as part of the tmp.0ut zine, and the CFP for the next issue is currently open: https://tmpout.sh/blog/vol4-cfp.html&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I'm usually against separate "mobile versions" of websites but wow, this needs one.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42018195</guid></item><item><title>10. Show HN: I wrote an open-source browser alternative for Computer Use for any LLM</title><link>https://news.ycombinator.com/item?id=42052432</link><description>
&lt;![CDATA[
&lt;p&gt;169 points points by gregpr07 on 2024-11-05T15:51:43 &lt;/p&gt;
&lt;p&gt;The GitHub repository contains code for a web browser usage analysis project. It includes tools for collecting and analyzing data on browser usage, focusing on tracking the popularity of different web browsers over time. The project aims to provide insights into trends and patterns related to browser usage on the internet.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Is it decided then that screenshots are better input for LLMs than HTML, or is that still an active area of investigation? I see that y'all elected for a mostly screenshot-based approach here, wondering if that was based on evidence or just a working theory.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Awesome project, starred! Here are some other projects for agentic browser interactions:* Cerebellum (Typescript): https://github.com/theredsix/cerebellum* Skyvern: https://github.com/Skyvern-AI/skyvernDisclaimer: I am the author of Cerebellum&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It's impressive, but to me it seems like the saddest development experience...    agent = Agent(
        task='Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour.',
        llm=ChatOpenAI(model='gpt-4o'),
    )
    
    await agent.run()

Passing prompts to a LLM agent... waiting for the black box to run and do something...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42052432</guid></item><item><title>11. Show HN: Whirlwind – Async concurrent hashmap for Rust</title><link>https://news.ycombinator.com/item?id=42053747</link><description>
&lt;![CDATA[
&lt;p&gt;135 points points by willothy on 2024-11-05T18:02:18 &lt;/p&gt;
&lt;p&gt;The website contains a project called "Whirlwind," created by the Fortress Build team. It focuses on providing developers with a framework for building fast and scalable API-driven web applications using Python. The project includes features such as database integration, seamless API development, and performance optimization. Additionally, it offers documentation and guidance for developers interested in using Whirlwind for their projects.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I don't think I'd recommend using this in production. The benchmarks look good, but by immediately waking the waker[0], you've effectively created a spin-lock. They may work in some very specific circumstances, but they will most likely in practice be more costly to your scheduler (which likely uses locks btw) than just using locks[0]: https://github.com/fortress-build/whirlwind/blob/0e4ae5a2aba...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;One thing which wasn’t obvious to me from the benchmark: What’s the key distribution? A sharded map will probably have great performance on uniform keys, but in my experience it’s far more common to have power law distribution in real life scenarios.It would be good to see a benchmark where it only touches a _single_ key. If Whirlwind is still fast than the others I would be far more convinced to use it unconditionally.EDIT: I also see that you're benchmarking on a M3 Max. Note that this has 6 performance cores and 6 efficiency cores. This means that if you're running at &lt;6 cores it will most likely start out running it at the efficiency core. From my experience it's quite important to do warmup phases in order to get stable results at low thread count. And even then I find it hard to reason about the results since you're running in mixed set of cores…&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; Just as dashmap is a replacement for std::sync::RwLock&lt;HashMap&gt;, whirlwind aims to be a replacement for tokio::sync::RwLock&lt;HashMap&gt;.I'm curious about the practical benefits of handling a HashMap with an async interface. My long-standing understanding is that `tokio::sync::RwLock&lt;HashMap&gt;` is only useful when you'd want to hold the lock guard across another `await` operation; but when the lock guard is not held across an await, it is always preferable to use the synchronous version.This would lead me to assume that same applies for dashmap--it should be sufficient for async use cases and doesn't need an async API unless we expect to be blocked, but the benchmarks indicate that whirlwind outperforms dashmap in various situations. Do you have a sense of where this blocking occurs in dashmap?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42053747</guid></item><item><title>12. Pagination widows, or, why I'm embarrassed about my eBook (2023)</title><link>https://news.ycombinator.com/item?id=42047677</link><description>
&lt;![CDATA[
&lt;p&gt;217 points points by OuterVale on 2024-11-05T00:58:11 &lt;/p&gt;
&lt;p&gt;This blog discusses the concept of responsive web design, emphasizing the importance of designing websites that adapt to different screen sizes and devices. The author highlights the significance of creating flexible layouts and using media queries to enhance user experience across various platforms. The blog provides examples and practical tips for implementing responsive design in web development projects.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;While everyone here seems to talk about the epub angle to the story, there's also simply the deeper story here, that "the web's" handling of paged media and the CSS paged media specs (to which his epub problem is related) is a never ending shitshow. Not only for epubs, for everybody who actually wants to print to real paper, too, ideally with a working cross browser solution.Mistake is largely not in the specs, but in the lack of support for them. Page breaking controls, weirdly breaking tables, lack of access to area outside the page box to influence headers/footers without weird hacks etc. etc. For printing, the 1990ies never ended.This leads to the bizarre situation where basically everyone who has semi complex printing needs in web applications will create PDF and then print that - and for creating those PDFs, often HTML to PDF conversion is used, just with actually implemented CSS for paged media. Which again proves that the spec is at least 99% there, if somebody would just kindly implement it in a browser, too.Won't be more complex than having the latest WebGL whatever thing in your browser engine ;-)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Another frustrating thing with ebooks is that you can't get them in PDF format any more. So much time is spent making a nicely fomatted hardcopy edition, then the ebook is only available as a terribly auto-converted epub that throws away all the layout and style. Particularly cookbooks, as well as anything technical, I just can't stand how lazy, ugly, and difficult to read the epubs are. All the tooling already exists to produce PDFs identical to the print version, but no, we can't have those.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Not to mention the ugly/unusable rendering of mathematical formulate in ebooks on my Kindle, which is gatherig dust.Layouting is an art and a craft, and the fact that it's automated by people who
lack the specialized knowledge, or for whom it is not a priority (quarter century old bug reports, really?) suggests that in 2025, you should still avoid ebooks if you care about quality and aesthetics.This is a shame because e-ink is just becoming usable. Anyhow, long live the paper book!&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42047677</guid></item><item><title>13. What Every Developer Should Know About GPU Computing (2023)</title><link>https://news.ycombinator.com/item?id=42042016</link><description>
&lt;![CDATA[
&lt;p&gt;175 points points by mooreds on 2024-11-04T14:49:44 &lt;/p&gt;
&lt;p&gt;The website discusses how Graphical Processing Units (GPUs) play a crucial role in accelerating computations for various tasks like machine learning, simulations, and data processing. It explains the benefits of using GPUs, such as parallel processing power, over traditional Central Processing Units (CPUs). The article highlights how GPUs are optimized for handling multiple tasks simultaneously, making them efficient for handling complex computations and improving overall system performance in applications requiring high computational power.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Unrelated but I absolutely love this reply from the previous time this was posted and someone complained about the line "most programmmers ...":&gt; Try this on: "A non-trivial number of Computer Scientists, Computer Engineers, Electrical Engineers, and hobbyists have ..."&gt; Took some philosophy courses for fun in college. I developed a reading skill there that lets me forgive certain statements by improving them instead of dismissing them. My brain now automatically translates over-generalizations and even outright falsehoods into rationally-nearby true statements. As the argument unfolds, those ideas are reconfigured until the entire piece can be evaluated as logically coherent.&gt; The upshot is that any time I read a crappy article, I'm left with a new batch of true and false premises or claims about topics I'm interested in. And thus my mental world expands.https://news.ycombinator.com/item?id=37969305&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This video is a great explainer too:How do Graphics Cards Work? Exploring GPU Architecture (https://youtu.be/h9Z4oGN89MU?si=EPPO0kny-gN0zLeC)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Makes me consider writing a post on misconceptions of GPU computing, such as requiring the problem to be fully data-parallel.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042016</guid></item><item><title>14. The Roots of Fear: Understanding the Amygdala</title><link>https://news.ycombinator.com/item?id=42042417</link><description>
&lt;![CDATA[
&lt;p&gt;146 points points by birriel on 2024-11-04T15:29:07 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Dreams and fear have an odd and slightly unintuitive relationship. When we are anxious and awake the amygdala is active and norepinephrine (the “fight or flight” neurotransmitter) is high.During REM sleep, surprisingly the amygdala is inactive and norepinephrine is 85% lower than base waking levels (not high anxious levels). So the brain is in a super relaxed state!I wrote a paper on the implications for dream content and interpretation (I’m a psychotherapist in training).If you’re interested you can find the paper here:https://osf.io/preprints/psyarxiv/k6trzAnd it was discussed on HN here:https://news.ycombinator.com/item?id=19143590&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think there are two types of fear mostly, the innate survival animalistic fear and the self-perpetuating fear caused due to misunderstanding. The animalistic fear is present in all and it's not possible to get rid of. When you see a snake or a tiger in front of you, that fear is natural. The response is to jump or run and is so spontaneous, you can't really control it. It's necessary for survival. But I think we are interested in the other fear, the one that is bound to attachment. You see a tiger, you panic, turns out to be a cat, you laugh it off, go away, that fear is not an issue. But if you go about your day thinking, what if that was a tiger? What if I get jumped by tiger this time? Then, you are creating the fear. The fear has no basis, except for it was implanted to you awhile ago. And now you are attaching yourself to it. You are extending it which is the actual problem. Most of us have fears that go back to childhood. If you think back far enough(like the tiger example), question yourself why you are afraid, you know the answers.One more example, I used to be afraid of getting heart-attacks in the past. Even gas passing would make me panic. Have I ever had a heart-attack before? No. How am I so damn sure that I have a heart-attack if I don't even know what it's supposed to feel like? Heart-attack is a bad thing and it shouldn't be happening to me. How is every acid reflux a heart-attack to me now. I have created my own bubble of fear. When though? I sure as hell didn't know what heartattack is when I was born. So it happened when I was able to comprehend what a heart-attack is right? For me, it's due to people around me passing, it's due to reading on Internet about young celebrities dying to strokes, watching movies, etc. It got implanted in me. I don't know a heartattack I just have an idea of it which is not the same thing. Not even remotely related.Fear arises due to misunderstanding. If you trace it far back enough, fear was implanted mostly in the childhood.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;https://gwern.net/backstop#hui-nengs-flag -- Evolution as Backstop for Reinforcement Learning -- Hui Neng’s Flag -- the mathematics of positive and negative reinforcementhttps://gwern.net/fiction/batman -- The Gift of the Amygdali -- Sci-Fi, anxiety, pain&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042417</guid></item><item><title>15. Lisp Query Notation (LQN)</title><link>https://news.ycombinator.com/item?id=42007462</link><description>
&lt;![CDATA[
&lt;p&gt;132 points points by surprisetalk on 2024-10-31T14:46:59 &lt;/p&gt;
&lt;p&gt;The website discusses a new query notation inspired by Lisp for structuring and querying data, aiming to provide a clearer and more expressive alternative to standard query languages. By utilizing nested lists resembling Lisp code, the query notation enables a versatile approach to defining and querying data relationships, offering increased flexibility in data manipulation and retrieval.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I don't quite understand the images that are included here...Though they're interesting and eye-catching.I feel like they've got something related to the tool... but are they simply for decoration?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42007462</guid></item><item><title>16. State of Python 3.13 performance: Free-threading</title><link>https://news.ycombinator.com/item?id=42051197</link><description>
&lt;![CDATA[
&lt;p&gt;180 points points by art049 on 2024-11-05T13:06:57 &lt;/p&gt;
&lt;p&gt;The website discusses the performance improvements in Python 3.13 and focuses on the benefits of free threading in Python. It highlights how Python's GIL (Global Interpreter Lock) is being addressed in the latest version and how it affects multi-threading. The article explores how these improvements can enhance Python's performance and facilitate better concurrency in Python applications.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I don't really have a dog in this race as I don't use Python much, but this sort of thing always seemed to be of questionable utility to me.Python is never really going to be 'fast' no matter what is done to it because its semantics make most important optimizations impossible, so high performance "python" is actually going to always rely on restricted subsets of the language that don't actually match language's "real" semantics.On the other hand, a lot of these changes to try and speed up the base language are going to be highly disruptive. E.g. disabling the GIL will break tonnes of code, lots of compilation projects involve changes to the ABI, etc.I guess getting loops in Python to run 5-10x faster will still save some people time, but it's also never going to be a replacement for the zoo of specialized python-like compilers because it'll never get to actual high performance territory, and it's not clear that it's worth all the ecosystem churn it might cause.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I'm glad the Python community is focusing more on CPython's performance. Getting speed ups on existing code for free feels great. As much as I hate how slow Python is, I do think its popularity indicates it made the correct tradeoffs in regards to developer ease vs being fast enough.Learning it has only continued to be a huge benefit to my career, as it's used everywhere which underlies how important popularity of a language can be for developers when evaluating languages for career choices&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Performance for python3.14t alpha 1 is more like 3.11 in what I've tested. Not good enough if Python doesn't meet your needs, but this comes after 3.12 and 3.13 have both performed worse for me.3.13t doesn't seem to have been meant for any serious use. Bugs in gc and so on are reported, and not all fixes will be backported apparently. And 3.14t still has unavoidable crashes. Just too early.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051197</guid></item><item><title>17. Aldebaran 1959 Spacecraft Concept (2010)</title><link>https://news.ycombinator.com/item?id=42047243</link><description>
&lt;![CDATA[
&lt;p&gt;62 points points by LorenDB on 2024-11-04T23:39:15 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The long Discovery space craft depicted in the latter half of "2001: A Space Odyssey" was derived from the nuclear rocket. It was suggested that the radioactive part of an Orion-style space craft be put far away from the crew compartment.We can probably can thank Fred Ordway (Marshall Spaceflight Center engineer) who Kubrick brought on board as technical consultant back then. (And of course for the look of the ships that are still so iconic over 50 years later I shouldn't leave off Harry Lange.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Pictures of Orion concepts have been widely distributed for decades, but not this one. Going into space with an air-breathing nuclear bomb powered jet engine. That is truly weird. How fast was it supposed to be going in atmosphere, I wonder. Did it carry reaction mass for vacuum so it could keep going out of the atmosphere?The trouble with nuclear rockets is that although you have plenty of energy, you still need to carry reaction mass - air, or water, or something - and a lot of it. That becomes the limit on delta-V.(The great frustration of rockets: not only do rockets need something to push against, they have to carry it with them.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Seems small. The proposed Super Orion would lift 8 million tons to orbit. From wikipedia:&gt; The biggest design above is the "super" Orion design; at 8 million tons, it could easily be a city. [...] This extreme design could be built with materials and techniques that could be obtained in 1958 or were anticipated to be available shortly after.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42047243</guid></item><item><title>18. DeepMind debuts watermarks for AI-generated text</title><link>https://news.ycombinator.com/item?id=42051098</link><description>
&lt;![CDATA[
&lt;p&gt;117 points points by ambigious7777 on 2024-11-05T12:50:16 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;These watermarks are not robust to paraphrasing attacks: AUC ROC falls from 0.95 to 0.55 (barely better than guessing) for a 100 token passage.The existing impossibility results imply that these attacks are essentially unavoidable (https://arxiv.org/abs/2311.04378) and not very costly, so this line of inquiry into LLM watermarking seems like a dead end.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This article goes into it a little bit, but an interview with Scott Aaronson goes into some detail about how watermarking works[0].He's a theoretical computer scientist but he was recruited by OpenAI to work on AI safety. He has a very practical view on the matter and is focusing his efforts on leveraging the probabilistic nature of LLMs to provide a digital undetectable watermark. So it nudges certain words to be paired together slightly more than random and you can mathematically derive with some level of certainty whether an output or even a section of an output was generated by the LLM. It's really clever and apparently he has a working prototype in development.Some work arounds he hasn't figured out yet is asking for an output in language X and then translating it into language Y. But those may still be eventually figured out.I think watermarking would be a big step forward to practical AI safety and ideally this method would be adopted by all major LLMs.That part starts around 1 hour 25 min in.&gt; Scott Aaronson: Exactly. In fact, we have a pseudorandom function that maps the N-gram to, let’s say, a real number from zero to one. Let’s say we call that real number ri for each possible choice i of the next token. And then let’s say that GPT has told us that the ith token should be chosen with probability pi.https://axrp.net/episode/2023/04/11/episode-20-reform-ai-ali...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Some comments here point at impossibility results, but after screening hundreds of job applications at work, it's not hard to pick out the LLM writing, even without watermark. My internal LLM detector is now so sensitive that I can tell when my confirmed-human colleagues used an LLM to rephrase something when it's longer than just one sentence. The writing style is just so different.Maybe if you prompt it right, it can do a better job of masking itself, but people don't seem to do that.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051098</guid></item><item><title>19. Netflix Europe offices raided in tax fraud probe</title><link>https://news.ycombinator.com/item?id=42051643</link><description>
&lt;![CDATA[
&lt;p&gt;333 points points by user20180120 on 2024-11-05T14:20:49 &lt;/p&gt;
&lt;p&gt;The website discusses the global initiative by the United Nations to save biodiversity, aiming to halt the extinction crisis and restore ecosystems. The article emphasizes the urgency of action needed to protect the planet's biodiversity and highlights the importance of conserving nature to ensure a sustainable future for all life on Earth.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I wonder how these "office raids" would work for remote first companies that don't have much of an office presence and with little or no physical documents and everything being stored in the cloud somewhere.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Wel,But things are changing. It seems... These are the developments in The Netherlands. Most of it somewhere over the horizon. Interested to know if other countries with similar tax evasion rules change their rules?It's in dutch so use your popular translation tool for these links:- https://www.rijksoverheid.nl/documenten/brochures/2023/10/11...
- https://theses.ubn.ru.nl/server/api/core/bitstreams/a384a151...
- https://open.overheid.nl/documenten/44e45809-c66e-4378-9fc8-...
- https://www.nu.nl/economie/6286473/nederland-nummer-een-bij-...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Sounds like the tech companies won't be expanding outside of Ireland for a while ....&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051643</guid></item><item><title>20. Nvidia and its partners built a system to bypass U.S. export restrictions</title><link>https://news.ycombinator.com/item?id=42048065</link><description>
&lt;![CDATA[
&lt;p&gt;324 points points by mgh2 on 2024-11-05T02:20:46 &lt;/p&gt;
&lt;p&gt;The tweet posted by user @kakashiii111 discusses the importance of self-assessment and personal growth. It emphasizes the need to reflect on our actions, behaviors, and thoughts in order to become better individuals. The tweet encourages self-improvement and underscores the significance of learning from past experiences to evolve and make positive changes in our lives.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Nvidia is obviously a US company, but the chips themselves are manufactured in Taiwan.And of course China sees Taiwan as a rogue province, at at least treats invasion there as "on the table". While the US may decide to actively support Taiwan, at the very least a war over that will disrupt production.Should Taiwan fall, and China choose to ban exports from there to the US, then the fun and games would really start.As long as back-channels exist to supply the chips to China, then there's less incentive for China to control Taiwan. The ban exists as good politics (we don't ship to our adversaries) while the back-channels ensure they aren't forced into a position no-one wants them to be in.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Article: https://news.ycombinator.com/item?id=42048033&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;We will see what happens - but given nvidias growth and how heavy they are now weighted I’m skeptical there will be any enforcement until well after the elections.Neither party wants to look “bad for the economy”, even if the people harmed isn’t of significant size.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42048065</guid></item><item><title>21. Low-poly image generation using evolutionary algorithms in Ruby (2023)</title><link>https://news.ycombinator.com/item?id=42047320</link><description>
&lt;![CDATA[
&lt;p&gt;113 points points by thomascountz on 2024-11-04T23:50:49 &lt;/p&gt;
&lt;p&gt;The website discusses creating low-poly images using Delaunay triangulation and the Voronoi diagram algorithms. It provides an in-depth tutorial on generating these geometric artworks with Python, manipulating colors, and incorporating noise for a unique effect. The article offers step-by-step instructions and code examples to help readers understand and implement the process of low-poly image generation.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Great write-up, I like the fitness graphs a lot.I did something similar in Julia a while ago in an attempt to learn the language: https://www.basjacobs.com/post/2020-11-18-image-triangulatio...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Camme for the evolutionary stuff (wrote mh PhD on it).Left having leaned that you can switch Tail Call Optimisation on or off in Ruby code.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I made some image generation with CLIP and Evolutionary algorithms not so long ago[1] and the results had a bit more life than I was expecting. It is still a contested area of research and you have some cool stuff like CLIPDraw[2] where they use gradient decent to approximate a vector to the embeddings of CLIP.[1] https://snats.xyz/pages/articles/optimizing_images.html
[2] https://arxiv.org/pdf/2106.14843&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42047320</guid></item><item><title>22. World’s oldest tree? Genetic analysis traces evolution of iconic Pando forest</title><link>https://news.ycombinator.com/item?id=42046953</link><description>
&lt;![CDATA[
&lt;p&gt;116 points points by pseudolus on 2024-11-04T22:58:50 &lt;/p&gt;
&lt;p&gt;The website provides information on the challenges facing global aquaculture due to climate change, including impacts on fish health and production. It discusses how rising water temperatures can lead to disease outbreaks and stresses the need for innovative solutions to ensure sustainable aquaculture practices in the face of climate-related challenges.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;If you're ever in central Utah you should make the trip to see Pando, it grows beside Fish Lake which is teeming with life, and surrounded by beautiful hills and mountains that make for great campsite views. The lake is full of landlocked kokanee salmon that never see an ocean in their lifetime.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;TIL Pando is not just an especially large quaking aspen, but rather a triploid mutant that can reproduce only asexually.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The fact that Pando is a single organism is so confusing to me. I’m guessing there are more forests like Pando that are also a single organism? Is this something unique to this particular species?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42046953</guid></item><item><title>23. Netnews: The Origin Story [pdf]</title><link>https://news.ycombinator.com/item?id=42048021</link><description>
&lt;![CDATA[
&lt;p&gt;60 points points by tkhattra on 2024-11-05T02:09:16 &lt;/p&gt;
&lt;p&gt;The document provides a historical overview of Usenet, a popular early online discussion system that emerged in the 1980s. It discusses the growth of Usenet from a small community of users to a global network of servers exchanging messages and files. The paper highlights key milestones in Usenet's development and the challenges it faced as it grew in popularity, such as spam and scalability issues. Additionally, it delves into the social aspects of Usenet, including its impact on online culture and communication.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;There is a probably-'80s document that I would like to find again, written I think by some university as an ‘introduction to Usenet’ for students. It had a section I particularly remember about focusing discussions on the topic of a newsgroup rather than on the newsgroup. Anyone recognize this?(Today is Tuesday the 11389th of September 1993.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;the section "conclusion" is a good summary of the article, of major usenet design decisions and also of it's shortcomings.It seems it has ~~degenerated~~ evolved to a niche file sharing platform for obscure contents?I remember the days when comp.os.linux.announce was a good place to keep a pulse on what's cooking in terms of fun FOSS software.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;"Personally owned computers—microcomputers, in the terminology of the day—were rare and were the domain of a few
hobbyists. Most were very small and generally lacked hard drives;
bulk storage was via audio cassette tape or (for the lucky few) on
floppy disks with a capacity of about 1.5 megabytes."1.5 megabytes?  Um, no.  3.5" floppies weren't out yet in 1979, and they were 1.44MB.  5.25" double-sided high-density floppies were 1.2MB, and I'm not sure they were were out yet either.  I was using 8" floppies in 1979, and IIRC they were about 250KB&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42048021</guid></item><item><title>24. Why Companies Are Ditching the Cloud: The Rise of Cloud Repatriation</title><link>https://news.ycombinator.com/item?id=42054813</link><description>
&lt;![CDATA[
&lt;p&gt;203 points points by panrobo on 2024-11-05T20:19:13 &lt;/p&gt;
&lt;p&gt;The article explores the trend of companies moving away from the cloud and opting for cloud repatriation, where they bring data and applications back in-house due to cost savings, security concerns, and performance issues. It discusses the factors driving this shift and presents various scenarios where companies are reconsidering their cloud strategies to better align with their specific business needs.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I don't know that 37Signals counts as a "major enterprise". Their Cloud exodus can't have been more than a few dozen servers, right?Meanwhile AWS is growing at 20%/year, Azure at 33% and GCP at 35%. That doesn't seem compatible with any kind of major cloud repatriation trend.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;GEICO is moving away from the cloud because their IT is a joke. They had a horrible on-prem infrastructure, so they moved to the cloud not knowing how, and they made the same mistakes in the cloud as on-prem, plus the usual mistakes every cloud migration runs into. They are moving away from the cloud because their new VP's entire career is focused on running her own hardware. What we know about their new setup is absolutely bonkers (like, K8s-on-OpenStack-on-K8s bonkers). Look to them for what not to do.37signals is like the poster child for NIH syndrome. They keep touting cost savings as the reason for the move, but from what I have gathered, they basically did nothing to save cost in the cloud. It is trivial to save 75% off AWS's list price. They will even walk you through it, they literally want you to save money. That, plus using specific tech in specific ways, allows you to reap major benefits of modern designs while reducing cost more. 37signals didn't seem to want to go that route. But they do love to build their own things, so servers would be a natural thing for them to DIY.Almost every argument against the cloud - cost inefficiency, fear of vendor lock-in, etc - has easy solutions that make the whole thing extremely cost competitive, if not a way better value, than trying to become your own cloud hosting provider. It's very hard to estimate the real world costs, both known and unknown, of DIY hosting (specifically the expertise, or lack of it, and the impacts from doing it wrong, which is very likely to happen if cloud hosting isn't your core business). But it's a 100% guarantee that you will never do it better than AWS.AI is the only place I could reasonably imagine somebody having an on-prem advantage. At the moment, we still live in a world where that hardware isn't a commodity in the way every other server is. So you might just be faster to deploy, or cheaper to buy, with AI gear. Storage is similar but not nearly as tight a market. But that will change eventually once either the hype bubble bursts, or there's more gear for cheaper for the cloud providers to sell.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It's a short simple post that comes down to this:&gt; Weekly explains that “just running legacy applications in the cloud is prohibitively expensive,” highlighting how lift-and-shift approaches often fail to deliver expected benefits.Yes, if you have a mature business without active development at a scale where compute/storage costs is a substantial accounting line item, then it makes sense to run on hardware that doesn't have the flexibility and cost of the cloud.There is an in-between that makes much more sense for most though. Running on provisioned bare metal. Lots of providers offer this as a better performance/price option where you don't have to deal with provisioning hardware but do everything else from the OS+maintenance and up.At one company we used large bare-metal machine instances provisioned for stable parts of the application architecture (e.g. database and webapp instances) and the cloud for new development where it made sense to leverage capabilities, e.g. DynamoDB with cross-region replication.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054813</guid></item><item><title>25. Wooden satellite heads to space in Mars exploration test</title><link>https://news.ycombinator.com/item?id=42051687</link><description>
&lt;![CDATA[
&lt;p&gt;97 points points by austinallegro on 2024-11-05T14:26:42 &lt;/p&gt;
&lt;p&gt;The world's first wooden satellite designed to test the durability of wood in space is scheduled to be launched as part of a Mars exploration project. The satellite, named WISA Woodsat, aims to assess the potential for sustainable materials in space missions. This innovative approach could provide valuable data on how wood behaves in the harsh conditions of space and its viability for future space exploration missions.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I wasn’t sure what the article meant by “no screws or glue”, when the photograph appears to have visible screws. But closer images show that these are apparently some sort of rivet?I found a (Japanese-language-only) news piece that shows some of the crafting and assembly of the satellite, and the box body certainly holds together by itself, via some beautifully intricate joinery:https://www.youtube.com/watch?v=A_F-NzzC7RA&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I'm confused by this statement in the article:&lt;&lt; LignoSat is made of honoki, a kind of magnolia tree native to Japan, and has been made using a traditional Japanese technique without screws or glue. &gt;&gt;From photos I've seen while searching for more information, it does appear that there's a wooden core structure that is joined without fasteners. But it's then given a metal exoskeleton and what certainly appears to be metal fasteners.I'd like to understand whether the goal is to create satellites without metal, as the article seemed to imply.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I accidentally visited this from a browser with no adblocker and outbrain clickbait has become comically weird. I was shown what appears to be AI generated video clips of a bear walking through a children's hospital ward, presented as a story about something that happened in my area (Ireland has no bears). I refreshed and was shown the same story but this time it was a wolf. This was side by side with the usual midjourney images as dating site profiles, and weird fabricated medical stuff. They really have gone off the deep end.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051687</guid></item><item><title>26. The Eternal Mainframe (2013)</title><link>https://news.ycombinator.com/item?id=42055556</link><description>
&lt;![CDATA[
&lt;p&gt;72 points points by w3ll_w3ll_w3ll on 2024-11-05T22:00:05 &lt;/p&gt;
&lt;p&gt;The website explores the concept of a hypothetical eternal mainframe computer, discussing its potential implications on society and the limitations of current technology. It delves into the idea of a computer system continuously evolving and improving itself, leading to ethical considerations, philosophical questions, and speculations about the future of artificial intelligence and human-computer interaction.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;At least in my experience, when I've heard that the "mainframe is going to die", it's specifically referencing the IBM ecosystem - COBOL and friends.To me it looks like the author is grasping for straws when saying "well, a server rack is just like a mainframe, so the mainframe is not dying!".To me it's the opposite: yes, a server rack is just like a mainframe. That's why the mainframe is dying - a bunch of servers can do the same work much more cheaply.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Great article reflecting on who controls computational resources - the user or the company.I want to respond to one point mentioned:&gt; Those who continue to do significant work offline will become the exception; meaning they will be an electoral minority. With so much effort being put into web apps, they may even be seen as eccentrics; meaning there may not be much sympathy for their needs in the halls of power.What I find scary is that developers see web apps (and hence the open web platform) as no longer fashionable, and instead focus on developing mobile apps (iOS and Android).There are various services that are only available to mobile users, not PC / web browser users. One I can recall off the top of my head is Snapchat a decade ago. Other examples today include various bike sharing apps, and possibly some banking apps too. Often, the web app and mobile app don't reach feature parity. Often, the company pushes people to download the mobile app and discourages visiting the website (e.g. Reddit).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think "looks like" is very ephemeral to what being a mainframe IS. it's true that MP systems can look like a single entity, but they are highly asynchronous. The prism architecture meant a single clock state propagating cleanly across the CPU(s) provided a consistent, time managed framework to be all things to all people. (thats how I understand it)A Sun E10000 is to my mind, as close as a mainframe gets in the post-sparc era. The Tandem non-stops had some of it, the final Dec cluster model was getting there but in a distributed async clocked manner.In the end the point of the mainframe was the TPC. The sustained rate it could process edge device request-response sequences inside the bounds of your choices in the CAP theorem. Distributed systems solve the same problem, but with other consequences. It still freaks me out that IBM had so many irons in the fire they had room to do this, AND to make unix work inside this, and manage legacy, and scale out to whole-of-government or SAGE or SABRE or you-name-it.I hated using AIX as a sysadmin from Dec world view btw. I'm not an IBM fanboi. I lived in the competition.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055556</guid></item><item><title>27. Vega's Puzzling Disk</title><link>https://news.ycombinator.com/item?id=42054569</link><description>
&lt;![CDATA[
&lt;p&gt;55 points points by JPLeRouzic on 2024-11-05T19:43:34 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The article notes Vega’s presence in lots of sci-fi. To add one more: Karl Schroeder’s Virga series is placed within the Vega system (not a spoiler, so far as I know.) I’m still reading through the series, but I came across them through a recommendation from Cory Doctorow — which is high praise. What appear to be fun light adventure novels (and they’re very good at that) hide stronger insight and criticism, political especially.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054569</guid></item><item><title>28. Tencent Hunyuan-Large</title><link>https://news.ycombinator.com/item?id=42054186</link><description>
&lt;![CDATA[
&lt;p&gt;142 points points by helloericsf on 2024-11-05T18:52:09 &lt;/p&gt;
&lt;p&gt;The Tencent Hunyuan Large-Scale Chinese Word Embedding Dataset is a resource aimed at providing researchers with pre-trained word embeddings for the Chinese language. The dataset includes word embeddings trained on a large corpus of Chinese text to support various natural language processing tasks. Users can access and utilize these word embeddings in their research or applications related to Chinese language processing.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Not open source. Even if we accept model weights as source code, which is highly dubious, this clearly violates clauses 5 and 6 of the Open Source Definition. It discriminates between users (clause 5) by refusing to grant any rights to users in the European Union, and it discriminates between uses (clause 6) by requiring agreement to an Acceptable Use Policy.EDIT: The HN title was changed, which previously made the claim. But as HN user swyx pointed out, Tencent is also claiming this is open source, e.g.: "The currently unveiled Hunyuan-Large (Hunyuan-MoE-A52B) model is the largest open-source Transformer-based MoE model in the industry".&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The model meets/beats Llama despite having an order-of-magnitude fewer active parameters (52B vs 405B). Absolutely bonkers. AI is moving so fast with these breakthroughs -- synthetic data, distillation, alt. architectures (e.g. MoE/SSM), LoRA, RAG, curriculum learning, etc.We've come so astonishingly far in like two years. I have no idea what AI will do in another year, and it's thrilling.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; Territory” shall mean the worldwide territory, excluding the territory of the European Union.Anyone have some background on this?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054186</guid></item><item><title>29. Mozilla is eliminating its advocacy division</title><link>https://news.ycombinator.com/item?id=42055979</link><description>
&lt;![CDATA[
&lt;p&gt;219 points points by doener on 2024-11-05T23:04:45 &lt;/p&gt;
&lt;p&gt;The Mozilla Foundation has laid off a significant portion of its staff focused on advocacy and global programs, citing budget constraints and the need to refocus on technical development. The organization, known for its Firefox web browser, faces criticism for the decision as it impacts key aspects of its mission to promote an open and accessible internet. Mozilla plans to transition some programs to community-led initiatives and is prioritizing investments in products and technologies rather than non-profit initiatives.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;A lot of people here will react to the advocacy cuts, and the idea that advocacy make up such a large portion of the workforce.30 percent seemed like a lot, but I think it's just 30 percent of the foundation's direct staff. I suspect the corporation employs more people than the foundation? So stuff like development is not included in that count.I do wonder if the cuts are because of anticipation of lower search revenue from Google with tech restricting legislation on the horizon and google's focus pivoting to AI.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;A job for advocacy division is to, uhm, advocate for the product and mission.We all know how that has worked out in the last decade or so (down to &lt;3% market share from 14% in 2014 and 31% in 2009, though I wonder about absolute numbers as number of Internet users has gone up).It's fine for Mozilla to recognize this as a failed approach (or team), without dropping their mission altogether.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;dupe: https://news.ycombinator.com/item?id=42054867&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055979</guid></item><item><title>30. What if they are all wrong? (2020)</title><link>https://news.ycombinator.com/item?id=42051231</link><description>
&lt;![CDATA[
&lt;p&gt;74 points points by macleginn on 2024-11-05T13:13:17 &lt;/p&gt;
&lt;p&gt;The website explores the idea of considering different perspectives and possibilities, challenging conventional wisdom or established beliefs. It raises questions about the validity of popular opinions and encourages readers to think critically, fostering curiosity and open-mindedness towards alternative viewpoints.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;As someone not in the field of mathematics, I actually didn't realize there was such an emphasis on attempting to prove famous conjectures correct. I thought the famous conjectures were famous precisely because knowing the veracity of the conjecture (or independence with respect to some formal system) would be a monumental event in any case.I also assumed many mathematicians utilized the strategy of attempting to disprove something as a way to reveal the proof. Sort of like how the best chess players tend to spend most of their thinking time mentally challenging their planned move as opposed to novice chess players who tend to look for reasons confirming why their move will be a good one. Is this not the case?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Any theorem was a conjecture before its formal proof was accepted by the community. Thus the importance of conjectures is a proxy to the importance of theorems: they are proto-theorems.The fact that the human mind is capable of searching for new mathematical theorems specifically here instead of there, is quite interesting. It's as if a skilled mathematician has knowledge that is bigger than math itself.Penrose used this as argument for the special nature of consciousness, wrongly - it probably makes more sense to remember how the way the human mind is not exact and produces errors all the time plays a huge role in a creative process. And luckily we can amend the human mind by social processes that help eliminating errors again.This way, a conjecture can be thought of as a claim to truth in a competitive environment and that would explain why proving the truth is regarded so much higher.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think this sentiment is coming from the same place as that of people who oppose more "pure" scientific pursuits in general. You can ask "what good does it do me that some guy was able to go to the moon?" or "who cares about theorizing about black holes, they're really far away", but ultimately pursuing these goals is what got us such crucial everyday stuff like GPS. Sure, you may not care about the goal (even though I think they're worthy goals), but you sure as heck benefit from the journey that got us there. Similarly, chasing mathematical conjectures, even the ones that turn out false, sets us off on journeys on which we discover/invent ever more sophisticated and powerful mathematical tools. And these tools have an amazing tendency to give us insight into broader problems, and help us prove other theorems, even if the conjecture we were originally chasing turns out to be false. It is in this way that chasing conjectures gets us closer to the truth, regardless of their own truthiness.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051231</guid></item><item><title>1. Title drops in movies</title><link>https://news.ycombinator.com/item?id=42056923</link><description>
&lt;![CDATA[
&lt;p&gt;496 points points by gaws on 2024-11-06T02:48:06 &lt;/p&gt;
&lt;p&gt;The website features a searchable database of movie title drops, where characters say the title of the film within the movie itself. Users can browse through various movies to find instances of title drops, offering a fun and unique way to explore and revisit films.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;While the 1995 Japanese anime series, Neon Genesis Evangelion revolves around human-shaped weapons called "Evangelions", the "Neon Genesis" part of the title is neither part of the original Japanese name, nor its direct translation. The Japanese name is 新世紀エヴァンゲリオン / Shin-seiki evangerion, "Evangelion of a new era/century". The series has other non-direct translations too, and apparently this style was approved of the original creators, but it was always a bit of a mystery whether the gap in the interpretation was intentional or not.However, over two decades later, with the re-boot movie series Rebuild of Evangelion, in the final scenes of the final movie, the protagonist name-drops the words "neon genesis" in appropriate context. I've never grinned as hard in movie theater.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Intentionality matters. "It" should not count as a title drop.  Nor Barbie (or any movie where the title is the characters name). But I understand it would be way more difficult to run the numbers with such a  constraint.  But this is a case where, to me, the results are very much tainted and thus I had to stop reading.  To me this is like when developers run into a hard issue and somehow play a game of semantics with the wording of a ticket to avoid putting together something useful for the user&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Including films where the title is a character name makes the data set less interesting. “Barbie title-drops a ton!” yeah ok.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:46:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056923</guid></item><item><title>2. Useful built-in macOS command-line utilities</title><link>https://news.ycombinator.com/item?id=42057431</link><description>
&lt;![CDATA[
&lt;p&gt;733 points points by yen223 on 2024-11-06T05:51:40 &lt;/p&gt;
&lt;p&gt;This website provides a comprehensive overview of useful macOS command line utilities for various tasks, including managing processes, networking, file manipulation, and system monitoring. The article covers essential commands and their functionalities, providing insights into how these utilities can enhance productivity and efficiency for users navigating the macOS command line interface.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;A couple more:    afconvert(1) - an audio file format converter, which includes Apple's superior AAC codec from the Core Audio framework

    diskutil(8) - tons of tools for fixed and removable storage

Examples:    afconvert in.wav -o out.m4a -q 127 -s 2 -b 160000 -f m4af -d 'aac '

    mb=300; diskutil eraseVolume APFS myramdisk `hdiutil attach -nomount ram://$((mb*2048))`&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I would like to also recommend the app:   hear (macOS speech recognition and dictation via the command line)

See: https://sveinbjorn.org/hear(Uses built-in macOS capabilities for transcription from audio to text.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Few additions.open -n file.pdf : opens new instance of Preview application which is useful if you want to open the same file twice (for example to look at different pages at once).caffeinate -d : prevents display turning off, useful if you want to look at display without moving mouse.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057431</guid></item><item><title>3. New images of Jupiter</title><link>https://news.ycombinator.com/item?id=42057851</link><description>
&lt;![CDATA[
&lt;p&gt;441 points points by 0xFACEFEED on 2024-11-06T07:30:37 &lt;/p&gt;
&lt;p&gt;The website provides a platform for processing images captured by the JunoCam instrument aboard NASA's Juno spacecraft on its mission to Jupiter. Users can access and analyze images taken during specific timeframes and mission phases, such as Perijove 66, which occurred between October 1 and November 1, 2024. The site allows for detailed examination and enhancement of these images for scientific research and public engagement.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;These come from Juno, a mission sent in 2011 and orbiting Jupiter since 2016. Must say it wasn't really on my radar anymore, but looking at the timeline on Wikipedia, it's still going around and getting close ("perijove") every month and a week or so, at an ever-increasing longitude https://en.wikipedia.org/wiki/Juno_(spacecraft)#Timeline The planned end of the mission is in about a year. The camera was "included in the payload to facilitate education and public outreach [but] later re-purposed to study the dynamics of Jupiter's clouds"&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Juno was something about radar - penetrating the cloud layers to see what was below.In college my son worked on the FFT engine that processed the radar data. He has code circling Jupiter!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Alien feel (and even unsettling at times).I guess we have grown used to this by now, but from the Moon landing pictures, to the Mars rovers and the various asteroid and planetary missions the objects of the Solar system are now vivid, complex and above all, "real" places.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057851</guid></item><item><title>4. Passport Photos</title><link>https://news.ycombinator.com/item?id=42069646</link><description>
&lt;![CDATA[
&lt;p&gt;913 points points by gaws on 2024-11-06T21:23:50 &lt;/p&gt;
&lt;p&gt;Max Siedentopf has created a playful and imaginative project that showcases unusual and creative passport photo concepts. The series features a variety of quirky and humorous portraits that defy traditional passport photo norms. Using props, costumes, and unconventional backgrounds, the project aims to transform the mundane task of taking passport photos into a fun and artistic experience. The images serve as a refreshing and entertaining twist on a typically tedious process, encouraging viewers to see passport photos in a new light.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Looking at other art by him, his latest piece Democracy features three figures in voting booths, one with their pants pulled down. Sure feels timely. He wrote a nice blurb with it too, I love it when artists include some of their thoughts in portfolios rather than just the photos alone (though this piece was a sculpture).https://maxsiedentopf.com/democracy/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Oh! Something I took a part in on HN. That's a first. Almost everything there was practical. Highly recommend checking out all of Max's work, beaming with creativity.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It's a lot of "fun" trying to get acceptable photos. Last week I went to my local American Automobile Association (AAA) office to get an International Driver's Permit (IDP). It's just a translation of your license, which is valid for 1 year. I had to take 2 passport-sized photos with me, which I did.But I was told they wouldn't be accepted because I had long hair and a beard in them, but short hair and no beard now. That's absurd, because it's the same photo used in both of my passports, and there's no requirement that you don't alter your appearance from your passport photo. Somehow border guards can crack the code.Amusingly, my California driver's license shows short hair and no beard, but the AAA person wasn't even looking at my CA license at the time. What happens if I grow long hair and a beard before I travel? Was he just trying to upsell me on a $9.99 photo?We had a hell of a time getting the UK passport authorities to accept the photos we sent in for her passport; they recommend getting your photos taken at an "official" UK location where the digital photos are identified by a code you send in. Well, we happened to be traveling through Australia during this timeframe, so we were able to stop at an Australian Post Office, which supposedly had the same "digital" system, but instead of a code to send to the UK authorities, they handed us printed photos and a web link. Thankfully I was able to use the web link to download the photo and upload it to the UK site, where it was approved almost immediately, and the new passport arrived back at our home before we returned from our trip. But there's no user-obvious criteria that was being used to reject the SEVERAL rounds of photos we had sent to the UK earlier.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42069646</guid></item><item><title>5. Trump wins presidency for second time</title><link>https://news.ycombinator.com/item?id=42057647</link><description>
&lt;![CDATA[
&lt;p&gt;1693 points points by koolba on 2024-11-06T06:49:49 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;All: please make sure you're up on the site guidelines before commenting: https://news.ycombinator.com/newsguidelines.html. That means editing out snark, swipes, and flamebait. Or you can simply follow this metarule, which is also in there: "Comments should get more thoughtful and substantive, not less, as a topic gets more divisive."This thread could be worse (ok, it could be a lot worse) but I'm still noticing people breaking the rules. Please follow them instead—it will be a better experience for all of us, including yourself.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It's the economy, stupid:-Inflation is not prices; it is the rate of change in prices.  Low inflation doesn't imply low prices.
-Aggregate statistics don't necessarily explain individual outcomes.The Dems failed on this count massively, and have, for maybe the last 40 years, which is about the amount of time it took for my state to go from national bellwether (As goes Ohio, so goes the nation) to a reliably red state.  This cost one of the most pro-union Senators (Sherrod Brown) his job.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;About 20 million votes less than the 2020 election, with about 15 million less for the democrats, and a measely 4 million less for the republicans. Thought that was interesting.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057647</guid></item><item><title>6. Private Cloud Compute Security Guide</title><link>https://news.ycombinator.com/item?id=42062230</link><description>
&lt;![CDATA[
&lt;p&gt;350 points points by djoldman on 2024-11-06T13:48:55 &lt;/p&gt;
&lt;p&gt;The website provides documentation on Apple's private cloud compute service, detailing the technical aspects and best practices for setting up and maintaining secure private cloud deployments. It offers guidance on securely developing and deploying applications within a private cloud environment, emphasizing protection of data and ensuring compliance with security standards and protocols.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;There's something missing from this discussion.What really matters isn't how secure this is on an absolute scale, or how much one can trust Apple.Rather, we should weigh this against what other cloud providers offer.The status quo for every other provider is: "this data is just lying around on our servers. The only thing preventing a employee from accessing it is that it would be a violation of policy (and might be caught in an internal audit.)" Most providers also carve out several cases where they can look at your data, for support, debugging, or analytics purposes.So even though the punchline of "you still need to trust Apple" is technically true, this is qualitatively different because what would need to occur for Apple to break their promises here is so much more drastic. For other services to leak their data, all it takes is for one employee to do something they shouldn't. For Apple, it would require a deliberate compromise of the entire stack at the hardware level.This is very much harder to pull off, and more difficult to hide, and therefore Apple's security posture is qualitatively better than Google, Meta or Microsoft.If you want to keep your data local and trust no-one, sure, fine, then you don't need to trust anyone else at all. But presuming you (a) are going to use cloud services and (b) you care about privacy, Apple has a compelling value proposition.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Sibling comments point out (and I believe, corrections are welcome) that all that theater is still no protection against Apple themselves, should they want to subvert the system in an organized way. They’re still fully in control. There is, for example, as far as I understand it, still plenty of attack surface for them to run different software than they say they do.What they are doing by this is of course to make any kind of subversion a hell of a lot harder and I welcome that. It serves as a strong signal that they want to protect my data and I welcome that. To me this definitely makes them the most trusted AI vendor at the moment by far.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is probably the best way to do cloud computation offoading, if one chooses to do it at all.What's desperately missing on the client side is a switch to turn this off. It's really intransparent which Apple Intelligence requests are locally processed and which are sent to the cloud, at the moment.The only sure way to know/prevent it a priori is to... enter flight mode, as far as I can tell?Retroactively, there's a request log in the privacy section of System Preferences, but that's really convoluted to read (due to all of the cryptographic proofs that I have absolutely no tools to verify at the moment, and honestly have no interest in).&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42062230</guid></item><item><title>7. Show HN: SuperSplat – open-source 3D Gaussian Splat Editor</title><link>https://news.ycombinator.com/item?id=42060856</link><description>
&lt;![CDATA[
&lt;p&gt;229 points points by ovenchips on 2024-11-06T12:07:06 &lt;/p&gt;
&lt;p&gt;The website allows users to access a 3D editor where they can interact with and customize a 3D model of a toy cat. Users can manipulate the model using different tools and features available in the editor, enabling them to experiment with various modifications and view the cat from multiple angles.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This is neat but Splats are not really mean to be edited in this way.Splats are sort of like byte code, they are the compiled and optimized representation of reflected light as semi-transparent guassians.Or you can think of them as the PDF equivalent of a Google or Word Doc.  All the logic is gone, and you just have final optimized results.Generally when you edit PDFs, the results are not great and you cannot make major edits because the layout won't reflow, etc.So while this is cool, I don't think it will take off unless there is another innovation in terms of either using AI to "reflow" the lighting and surfaces after an edit, or inferring more directly the underlying representations (true surface properties and the light sources.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I could imagine this as a clean-up tool for splats.  In any case, beautiful interface and the sample model made me smile.  Thanks for sharing.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;There's an app for Quest 3 called Gracia, which allows you to see these in 3D space:- https://www.meta.com/en-gb/experiences/gracia/25784099001234...- https://www.gracia.ai&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42060856</guid></item><item><title>8. 98.css – A design system for building faithful recreations of old UIs</title><link>https://news.ycombinator.com/item?id=42056918</link><description>
&lt;![CDATA[
&lt;p&gt;408 points points by OuterVale on 2024-11-06T02:46:58 &lt;/p&gt;
&lt;p&gt;This website seems to offer a minimalist stylesheet called 98.css that emulates Windows 98. It provides a nostalgic design reminiscent of the classic operating system, allowing users to incorporate the look and feel of Windows 98 into their web projects through a simple and lightweight CSS file.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I made something similar as well (that includes both 3.11, 95, 2000, XP, CDE and Mac OS 9, and also all the default color schemes of those): https://nielssp.github.io/classic-stylesheets/?theme=win9x&amp;s...My focus was not so much on pixel perfect, but instead on creating something that would also work and look aesthetically pleasing on modern systems, like with higher DPI monitors and such. So one of the the things I did was to recreate all the icons and symbols in SVG.I tried posting it as a Show HN when I added XP and Mac OS 9, but it didn't get much attention. Maybe the title of the project isn't as catchy.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Author here – happy to see this posted again!This was my burnout recovery project and I wrote some thoughts on it recently https://notes.jordanscales.com/98-css-reflections&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;My collection:The Sims https://thesimscss.inbn.dev/Windows 98 https://jdan.github.io/98.css/Windows XP https://botoxparty.github.io/XP.css/Windows 7 https://khang-nd.github.io/7.css/Edward Tufte https://edwardtufte.github.io/tufte-css/&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056918</guid></item><item><title>9. The deep learning boom caught almost everyone by surprise</title><link>https://news.ycombinator.com/item?id=42057139</link><description>
&lt;![CDATA[
&lt;p&gt;276 points points by slyall on 2024-11-06T04:05:01 &lt;/p&gt;
&lt;p&gt;The website discusses the reasons behind the rapid growth of deep learning in the field of artificial intelligence. It highlights key factors such as increased computation power, the availability of large datasets for training, algorithmic innovations, and the parallel development of hardware specifically designed for deep learning tasks. The article emphasizes how these factors have collectively contributed to the proliferation of deep learning applications across various industries.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The article credits two academics (Hinton, Fei Fei Li) and a CEO (Jensen Huang).  But really it was three academics.Jensen Huang, reasonably, was desperate for any market that could suck up more compute, which he could pivot to from GPUs for gaming when gaming saturated its ability to use compute.  Screen resolutions and visible polygons and texture maps only demand so much compute; it's an S-curve like everything else.  So from a marketing/market-development and capital investment perspective I do think he deserves credit.  Certainly the Intel guys struggled to similarly recognize it (and to execute even on plain GPUs.)But... the technical/academic insight of the CUDA/GPU vision in my view came from Ian Buck's "Brook" PhD thesis at Stanford under Pat Hanrahan (Pixar+Tableau co-founder, Turing Award Winner) and Ian promptly took it to Nvidia where it was commercialized under Jensen.For a good telling of this under-told story, see one of Hanrahan's lectures at MIT: https://www.youtube.com/watch?v=Dk4fvqaOqv4Corrections welcome.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think there is a slight disconnect here between making AI systems which are smart and AI systems which are useful. It’s a very old fallacy in AI: pretending tools which assist human intelligence by solving human problems must themselves be intelligent.The utility of big datasets was indeed surprising, but that skepticism came about from recognizing the scaling paradigm must be a dead end: vertebrates across the board require less data to learn new things, by several orders of magnitude. Methods to give ANNs “common sense” are essentially identical to the old LISP expert systems: hard-wiring the answers to specific common-sense questions in either code or training data, even though fish and lizards can rapidly make common-sense deductions about manmade objects they couldn’t have possibly seen in their evolutionary histories. Even spiders have generalization abilities seemingly absent in transformers: they spin webs inside human homes with unnatural geometry.Again it is surprising that the ImageNet stuff worked as well as it did. Deep learning is undoubtedly a useful way to build applications, just like Lisp was. But I think we are about as close to AGI as we were in the 80s, since we have made zero progress on common sense: in the 80s we knew Big Data can poorly emulate common sense, and that’s where we’re at today.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think neural nets are just a subset of machine learning techniques.I wonder what would have happened if we poured the same amount of money, talent and hardware into SVMs, random forests, KNN, etc.I don't say that transformers, LLMs, deep learning and other great things that happened in the neural network space aren't very valuable, because they are.But I think in the future we should also study other options which might be better suited than neural networks for some classes of problems.Can a very large and expensive LLM do sentiment analysis or classification? Yes, it can. But so can simple SVMs and KNN and sometimes even better.I saw some YouTube coders doing calls to OpenAI's o1 model for some very simple classification tasks. That isn't the best tool for the job.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057139</guid></item><item><title>10. Show HN: Hacker News frontpage as a print newspaper that you can personalize</title><link>https://news.ycombinator.com/item?id=42063709</link><description>
&lt;![CDATA[
&lt;p&gt;369 points points by nimbusega on 2024-11-06T15:23:42 &lt;/p&gt;
&lt;p&gt;The website covers various topics related to cybersecurity, hacking, technology, and internet news. It provides updates on the latest incidents, trends, and developments in the world of hacking and cybersecurity. The content includes articles, tutorials, discussions, and resources aimed at informing and educating readers about these subjects.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;But that just redirects. It would be nicer to also fetch the text and media when you click on a title.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This doesn't look like a print newspaper. Print newspapers are much denser (in general) and have different headline sizes to emphasize the editor's choice of stories. This looks like a corporate blog home page or something. Some people will like this presentation; I'm pretty happy with HN as it is. But congratulations on shipping!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Looks super neat! I've had a longtime dream of working on a similar project, but I want to make it "Daily Prophet" styled, inspired by the Harry Potter series - https://harrypotter.fandom.com/wiki/Daily_Prophet?file=Daily.... With gifs and effects :)A few years ago, a similar project was posted on HN that I thought was really cool too - E Ink smart screen puts a newspaper on your wall (https://news.ycombinator.com/item?id=22831323).&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42063709</guid></item><item><title>11. Trudeau government bans TikTok from operating in Canada</title><link>https://news.ycombinator.com/item?id=42070946</link><description>
&lt;![CDATA[
&lt;p&gt;609 points points by empressplay on 2024-11-06T23:04:39 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Instead of the laser focus on TikTok as a threat, it would be better for the US and Canada to have real data protection laws that would apply equally to TikTok, Meta, Google, Apple, and X. What the EU has done is far from perfect but it bans the worst practices. The Chinese can buy all of the information they want on Americans and Canadians from ad brokers, who will happily sell them everything they need to track individuals' locations.Perhaps the way to get anti-regulation politicians on board with this is for someone to do what was done to Robert Bork and legally disclose lots of personal info on members of Congress/Parliament, obtained from data brokers and de-anonymized.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; "Most people can say, 'Why is it a big deal for a teenager now to have their data [on TikTok]?' Well in five years, in 10 years, that teenager will be a young adult, will be engaged in different activities around the world,"I’m technically Gen-Z (but just barely) and this is something that really worries me. It’s become increasingly normal in recent times to share absolutely everything online but I’ve got a pretty grim feeling that this isn’t  gonna end well. People don’t realize that the AI’s being trained on your data today will act as an internet history that you can never delete.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;To be clear, they're not banning the app, they're banning ByteDance from having offices in Canada&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42070946</guid></item><item><title>12. Kernel optimization with BOLT (binary optimization and layout tool)</title><link>https://news.ycombinator.com/item?id=42005429</link><description>
&lt;![CDATA[
&lt;p&gt;165 points points by chmaynard on 2024-10-31T10:45:19 &lt;/p&gt;
&lt;p&gt;The website article discusses the process of creating custom Linux kernels and details the steps involved in selecting, configuring, and building a kernel tailored to specific requirements. It explores the benefits of custom kernels, including improved performance and stability, as well as potential challenges such as compatibility issues. The article provides insights into kernel configuration options, addressing common pitfalls, and optimizing the kernel build process to ensure a successful outcome.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Here is another interesting BOLT article, this one on PostgreSQL optimization:https://vondra.me/posts/playing-with-bolt-and-postgres/"results are unexpectedly good, in some cases up to 40%"&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Instruction Cache and TLB trashing is an often overlooked consequence of code bloat and sometimes of overly aggressive micro-benchmark driven optimization.Reorganizing the binary is an interesting approach to minimize the cost, but I think that any performance oriented developer should keep in mind that most projects are rarely dependent on a single hot loop but on many systems working together and competing for space in the cache(s).I generally use -Os instead of -O2 and -O3 in my projects, while trying to reduce code bloat to a minimum for that reason.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;One can try it out with CachyOS/Arch:https://cachyos.org/blog/2411-kernel-autofdo/&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42005429</guid></item><item><title>13. Model Predictive Control in the Browser with WebAssembly</title><link>https://news.ycombinator.com/item?id=41992851</link><description>
&lt;![CDATA[
&lt;p&gt;112 points points by thunderbong on 2024-10-30T08:15:37 &lt;/p&gt;
&lt;p&gt;The website discusses implementing Model Predictive Control (MPC) to stabilize a cart-pole system. It explores how to model the dynamics of the system and optimize control inputs to keep the pole upright. The article explains the concept of MPC, the objectives of the control algorithm, and provides code snippets to implement MPC for controlling the cart-pole system efficiently.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I am delighted to see a renewed interest in the field of systems control! This is awesome work!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I'd be interested, if any one had suggestions, on MPC applied to ML/AI systems -- it seems this is an underserved technique/concern in MLEng, and I'd expect to see more on it.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Author of the post here - happy to answer any questions.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=41992851</guid></item><item><title>14. Only 5.3% of US welders are women. After years as a professor, I became one</title><link>https://news.ycombinator.com/item?id=42056420</link><description>
&lt;![CDATA[
&lt;p&gt;259 points points by Michelangelo11 on 2024-11-06T00:24:48 &lt;/p&gt;
&lt;p&gt;The article discusses the author's transition from being a writing professor to becoming a welder. It highlights the lack of gender diversity in the field of welding, with only 5.3% of welders in the U.S. being women. The author shares her personal experiences and challenges in entering a male-dominated profession, emphasizing the importance of breaking stereotypes and encouraging more women to pursue careers in welding.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;What comes across from the article to me is the class barrier more than the gender one - basically it's a posh person finding out what the "real world" looks like.Shop talk and banter are fairly universal. Any difference is going to be a target. Thin bloke who doesn't look strong enough? Ginger hair? Tall guy, short guy? Weird tattoo, etc. Definitely the one black guy or the one white guy is going to get shit. But is it malicious? Almost certainly not.The other thing, which in my experience is relatively common worldwide, is that working class communities are more accepting of male-female dynamics. In academia and in highbrow society the tendency is to basically sanitise every social interaction. When you're in an environment where that isn't happening then you can't suddenly ignore it any more.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; “You’re better looking than the guy I talked to before.” Such harassment remains common for tradeswomenIf people think this is harassment, no wonder people experience a lot of harassment.Unless there was more to it the correct answer is along the lines of "yes thankfully" and then a laugh.I'd recommend a good look in the mirror when looking for the problem in such situations.Same goes for the thing about trying to discreetly notifying that someone has dirty hands:Yes, I don't know what is up with Americans and demanding everyone has clean hands at all times, but as long as that is a thing this probably is meant as a favor. Maybe clumsily, but still.More generally the saying: "when you hear hooves, think horses, not zebras" comes to mind:If you expect things to be meant funny or helpful (and give people some slack) maybe life becomes a lot less stressful than if everything has to be seen through a lens of gender dynamics.And if one is known as a reasonable person, I guess people will also take your side if you have to be loud and clear about something, e.g. if it turns out someone wasn't just clumsily trying to be nice or funny.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; I laid down the welds and put my hood up and the guy goes, ‘Well, goddamn, bitch can weld,’ and I was like, ‘Oh my god, thank god.’”The article refers to various forms of sexism and harassment, including the passage above. I’m absolutely not denying that these things happen in the workplace. That would be insane.But it is also true that the exact exchange above could completely have happened between two guys. Anyone who knows tradesmen understands that there’s a fair amount of good natured hassling of coworkers that has nothing to do with sexism.A lot of this work is dangerous and has to happen quickly and on schedule. You’re not really given serious responsibilities until you can demonstrate you’re not going to get someone crushed under a heavy weight or burned.It might be that she is misinterpreting some of this, but I must concede that she’s kind of a badass because she completed all three years of training and actually does work as a welder.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056420</guid></item><item><title>15. Switch 2 will be backwards compatible with Switch</title><link>https://news.ycombinator.com/item?id=42062841</link><description>
&lt;![CDATA[
&lt;p&gt;318 points points by ashitlerferad on 2024-11-06T14:32:32 &lt;/p&gt;
&lt;p&gt;The article states that a successor to the Nintendo Switch will be backwards compatible with the existing Switch console, as confirmed by Nintendo. This means that the new console will be able to play the games from its predecessor. This move by Nintendo aims to ensure that players can continue enjoying their existing game libraries on the new system, providing a smooth transition for consumers and possibly boosting the appeal of the upcoming console.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This shouldn't come as a surprise to anyone. Nintendo has had a trend for the past couple decades of releasing "sequel" consoles that are essentially a modernized version of the old one with extra features, compatible with everything that released on the predecessor.With all three major console manufacturers prioritizing backwards compatibility, and the rise in PC gaming (universally backwards compatible), people are starting to catch on to the fact that old games don't "expire" after 10 years. I wouldn't be surprised if backwards compatibility just becomes the standard for all gaming consoles going forward.Tangential, but I'm also interested in seeing how games that released on old consoles and are continued to be played, like Fortnite, will support aging hardware. I don't like that Epic can one day announce the game just no longer works on that console, rendering your purchases null and void until you upgrade your hardware, but I can't expect them to update that version of the game forever.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;And this reveals the real reason Nintendo came after Switch emulators - to buy some extra time before Switch 2 gets properly emulated.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;They're being purposely coy though on what this actually means. Backwards compatibility with digital/e-games, or backwards compatible with the physical carts?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42062841</guid></item><item><title>16. U.S. chip revival plan chooses sites</title><link>https://news.ycombinator.com/item?id=42054779</link><description>
&lt;![CDATA[
&lt;p&gt;172 points points by pseudolus on 2024-11-05T20:14:02 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Wolfspeed is building a fab in North Carolina that will make SiC based chips. They are receiving $750 million from the CHIPS and Science Act and will likely receive another $1 billion in tax credits.https://en.wikipedia.org/wiki/CHIPS_and_Science_ActSiC transistors and diodes are used in high power applications like locomotives, EV chargers and industrial motor controls. In their catalog they have a half-bridge power module rated for 1200V and 760A, which to me is amazing that a semiconductor can handle that much.https://www.wolfspeed.com/products/power/sic-power-modules/h...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It seems that the world is dividing into two camps- the ones who want to hunker down and bunker down into mini-empires, shunning globalisation. Expecting great rewards, by turning economics into trapdoor functions with loads of export and zero imports and tarifs as shield.And the others, who don't want - because they can't. For some globalisation is a navel, a lifeline without which there countries economies would wither and die. The exact same layout pre-WW2.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Well the revival may be halted depending on the election:&gt; The US CHIPS and Science Act's future may depend on the outcome of Tuesday's Presidential Election after House Speaker Mike Johnson suggested the GOP would likely move to repeal the $280 billion funding bill if the party wins a majority in Congress.* https://www.theregister.com/2024/11/04/chips_act_repeal/but a little while later:&gt; Johnson, who voted against the legislation, later said in a statement that the CHIPS Act, which poured $54 billion into the semiconductor manufacturing industry, “is not on the agenda for repeal.”* https://apnews.com/article/mike-johnson-chips-act-d5504f76d3...so ¯\_(ツ)_/¯&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054779</guid></item><item><title>17. Unix Programmer's Manual Third Edition [pdf] (1973)</title><link>https://news.ycombinator.com/item?id=42055644</link><description>
&lt;![CDATA[
&lt;p&gt;183 points points by rbanffy on 2024-11-05T22:12:02 &lt;/p&gt;
&lt;p&gt;The provided link leads to a PDF document that contains the Unix V3 manual. This manual provides comprehensive documentation on the Unix Version 3 operating system, detailing commands, syntax, and usage instructions for various functions within the Unix environment. It serves as a valuable resource for users looking to understand and effectively utilize Unix V3.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&gt; the number of UNIX installations has grown to 16, with more expected.What a time.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;My favorite (and also surprising) old Unix document is an USENIX paper from 1984, describing the /proc filesystem:https://news.ycombinator.com/item?id=26298564&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I hadn't realized there was a built in "interactively delete files asking the user" command, "dsw" this far back. I wonder when and why it got dropped?&gt; For each file in the given directory ("." if not
specified) d_s_w_ types its name. If "y" is typed,
the file is deleted; if "x", d_s_w_ exits; if anything else, the file is not removed.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055644</guid></item><item><title>18. Monorepo – Our Experience</title><link>https://news.ycombinator.com/item?id=42062074</link><description>
&lt;![CDATA[
&lt;p&gt;178 points points by vishnumohandas on 2024-11-06T13:37:03 &lt;/p&gt;
&lt;p&gt;The article discusses the advantages and challenges of using a monorepo (a version control system where all code is stored in a single repository) in software development. It shares insights and lessons learned from transitioning to a monorepo structure, highlighting benefits such as improved code sharing and easier dependency management, while also addressing issues like build and deployment complexities. The retrospective provides valuable reflection on the impact and outcomes of implementing a monorepo approach in a development workflow.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;    &gt; Moving to a monorepo didn't change much, and what minor changes it made have been positive.

I'm not sure that this statement in the summary jives with this statement from the next section:    &gt; In the previous, separate repository world, this would've been four separate pull requests in four separate repositories, and with comments linking them together for posterity.
    &gt; 
    &gt; Now, it is a single one. Easy to review, easy to merge, easy to revert.

IMO, this is a huge quality of life improvement and prevents a lot of mistakes from not having the right revision synced down across different repos.  This alone is a HUGE improvement where a dev doesn't accidentally end up with one repo in this branch and forgot to pull this other repo at the same branch and get weird issues due to this basic hassle.When I've encountered this, we've had to use another repo to keep scripts that managed this.  But this was also sometimes problematic because each developer's setup had to be identical on their local file system (for the script to work) or we had to each create a config file pointing to where each repo lived.This also impacts tracking down bugs and regression analysis; this is much easier to manage in a mono-repo setup because you can get everything at the same revision instead of managing synchronization of multiple repos to figure out where something broke.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Every monorepo I've ever met (n=3) has some kind of radioactive DMZ that everybody is afraid to touch because it's not clear who owns it but it is clear from its quality that you don't want to be the last person who touched it because then maybe somebody will think that you own it.  It's usually called "core" or somesuch.Separate repos for each team means that when two teams own components that need to interact, they have to expose a "public" interface to the other team--which is the kind of disciplined engineering work that we should be striving for.  The monorepo-alternative is that you solve it in the DMZ where it feels less like engineering and more like some kind of multiparty political endeavor where PR reviewers of dubious stakeholder status are using the exercise to further agendas which are unrelated to the feature except that it somehow proves them right about whatever architectural point is recently contentious.Plus, it's always harder to remove something from the DMZ than to add it, so it's always growing and there's this sort of gravitational attractor which, eventually starts warping time such that PR's take longer to merge the closer they are to it.Better to just do the "hard" work of maintaining versioned interfaces with documented compatibility (backed by tests).  You can always decide to collapse your codebase into a black hole later--but once you start on that path you may never escape.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The #1 benefit for me regarding the monorepo strategy is that when someone on the team refers to a commit hash, there is exactly one place to go and it provides a consistent point-in-time snapshot of everything. Ideally, all of the commits on master are ~good, so you have approximately a perfect time machine to work with.I have solved more bugs looking at diffs in GitHub than I have in my debugger simply by having everything in one happy scrolly view. Being able to flick my mouse wheel a few clicks and confirm that the schema does indeed align with the new DTO model props has saved me countless hours. Confirming stuff like this across multiple repos &amp; commits can encourage a more lackadaisical approach. This also dramatically simplifies things like ORM migrations, especially if you require that all branches rebase &amp; pass tests before merging.I agree with most of the hypothetical caveats, but if you can overcome them even with some mild degree of suffering, I don't see why you wouldn't fight for it.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42062074</guid></item><item><title>19. Superstreamer – OSS streaming toolkit from video source to player</title><link>https://news.ycombinator.com/item?id=42025619</link><description>
&lt;![CDATA[
&lt;p&gt;151 points points by thunderbong on 2024-11-02T11:09:41 &lt;/p&gt;
&lt;p&gt;The website provides a tool called SuperStreamer that allows users to easily stream video content from popular platforms like Amazon Prime, Netflix, and more, through a single interface. SuperStreamer aims to simplify the streaming experience by aggregating content from various services into one place, making it convenient for users to access and watch their favorite shows and movies without having to switch between multiple streaming platforms.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I skimmed the Readme, the What is Superstreamer? page, and features list. I still don't understand when I would use this, or when I would recommend it to someone. I'm an engineer somewhat familiar with the space.You may consider starting with a simple unique value proposition and reworking presentation from there.Take the first sentence of the Readme as example: "Superstreamer is a self hostable platform that aims to simplify the complexities of video delivery" - and answer questions:1. Who is benefiting?2. How is this better?3. What complexity is being solved?4. What's the tangible outcome, or CTA?5. What well-known alternative is this related to?ChatGPT took a stab at it. Not amazing, but something to start with:"Superstreamer is a self-hosted platform that simplifies video delivery, giving you full control over your content without third-party dependencies. Reduce costs, customize your setup, and deliver high-quality streams with ease. Drop &lt;competitor&gt; today and get started in minutes."Also simple things like defining an acronym before it's used goes a long way.Overall presentation, UX, design, code quality, and detail is a homerun IMO. Nice work, I can tell you put a heap of passion into it.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Author here, this is a fun surprise to wake up to! I was doubting whether my project was "ready to post on HN" but someone beat me to it.With Superstreamer, I'd like to create building blocks that simplify video end-to-end. While I initially wrote it as an "all-in-one" toolkit, I'm more leaning towards an open architecture. Like, you could use Stitcher to insert HLS interstitials (like ads, or bumpers) but have your original playlists come from Mux, Cloudflare Stream, etc... The transcode and package infrastructure is there for you to use it if you'd like to stick to a fully self hostable solution.As for player, it's a neat facade around HLS.js (kudos to the maintainers, their project is great), while initially a streaming library, the facade exposes an interface that makes sense for UI developers.Happy to answer any questions you have.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Something wrong with ffmpeg -&gt; icecast?  Those have been around forever.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42025619</guid></item><item><title>20. Tracker Beeper (2022)</title><link>https://news.ycombinator.com/item?id=42057036</link><description>
&lt;![CDATA[
&lt;p&gt;375 points points by gaws on 2024-11-06T03:21:09 &lt;/p&gt;
&lt;p&gt;The website discusses the creation of a device called the Tracker Beeper, designed to locate lost items using radio waves and a portable locator. The author details the technical aspects of the project, including the hardware used, software development, and the challenges faced during the design process. The Tracker Beeper is intended to aid in finding misplaced or hidden items by emitting beeps, helping users locate their belongings efficiently.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;It would be mostly quiet (remember that humans only hear up to ~20 kHz).Sure, this is a joke today, but if we continue down our current path, we would probably hit ultrasonic rates in the not too distant future.The video was fun and insightful to watch.  Big fan of sonification of computer processes.  We can hear such a large and important range of frequencies (more than the 'audible range' because we hear impulses in the subsonic range as events) and it works as a nice complementary in real time for an experience that charts can't convey.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Chrome's combined search + address bar seems like a fantastic data source for reverse search warrants: https://en.wikipedia.org/wiki/Reverse_search_warrantImagine a reverse warrant for any person who has searched “torproject.or” in the process of navigating to torproject.org&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This would be like the old school computing environment where you get an audible beep every time something is written to your hard disk. People noticed abusive code much more easily then.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057036</guid></item><item><title>21. 3D Rotation Design</title><link>https://news.ycombinator.com/item?id=42058355</link><description>
&lt;![CDATA[
&lt;p&gt;133 points points by fisian on 2024-11-06T09:07:17 &lt;/p&gt;
&lt;p&gt;The website describes a project by Matt Keeter, showcasing a tool for interactive three-dimensional modeling and 3D printing. It introduces the concept of rotational extrusion, which creates objects by revolving a 2D shape around an axis, allowing users to design custom shapes easily. The website provides an interactive demonstration of this process and offers the tool for users to experiment with their own designs, promoting creativity and exploration in 3D modeling.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Interesting but lacking some information. First up, of course, most people are familiar with rotating the camera rather than a single object. This is how most 3d viewers work, even if the orbit point is locked to the center of an object (e.g. in a 3d product display). So it's important to specific which we're talking about in an introductory article on 3d rotation methods.But, ok. We're talking about schemes to rotate a single object rather than the camera.The turntable controls they talk about are a special case of gimbal controls where we lock rotation to one or two axes. But in my personal experience, when it's two or three axes people still call it gimbal controls whereas turntable controls is rotation in a single axis (as if on a turntable, hence the name). But then again, 3d terminology is so mixed up across different fields that maybe some people have only heard the two axes version called a turntable. Not a big deal, but  why no mention at all of gimbal controls?Then, trackballs. In my experience, when it's limited to a single hemisphere of rotation, these are called arcball controls. Trackballs are supposed to emulate a trackball mouse which don't have this limitation.And finally, no mention at all of the dreaded gimbal lock (where two of axes end up overlaid on each other and the controls loses a degree of freedom), which is a major reason for choosing one type over another.Overall, not an amazing article. I checked it again to see if I missed anything and realized it's a blog post for some app - so, basically an ad - which probably explains the lack of effort.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;FYI, from 2017.Also, Matt Keeter has some serious skills.I always thought his Antimony CAD program[1] was neat, and sad that it seems to have died.  I've yet to figure out how to get it to run on newer versions of linux (The last time I tried was about 3 years ago, and I was just using a raspberry pi.)[1] https://www.mattkeeter.com/projects/antimony/3/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; There's another, more subtle critique of this system: it lacks path independence. This means that if you start and end a drag with your mouse at a particular location, the rotation will depend on the path that your mouse took.Actually, when I accidentally tumble models with that kind of UI, I just drag it in a circle until it's right side up.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42058355</guid></item><item><title>22. Show HN: Aide, an open-source AI native IDE</title><link>https://news.ycombinator.com/item?id=42063346</link><description>
&lt;![CDATA[
&lt;p&gt;192 points points by skp1995 on 2024-11-06T15:01:00 &lt;/p&gt;
&lt;p&gt;The website provides tools and resources to help developers create conversational AI applications using natural language processing. It offers a platform for building virtual assistants, chatbots, and voice-enabled applications with pre-built modules and integration capabilities for various platforms. The focus is on simplifying the development process and making it accessible to a wide range of users, including those without extensive coding knowledge.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Been using Cursor since launch. Really frustrating how they charge per message (500/mo) instead of by token usage. Like, why should a one-line code suggestion cost the same as refactoring an entire class? Plus it's been losing context lately and making rookie mistakes.Tried Zed AI but couldn't get into it - just doesn't feel as smooth as Cursor used to. GitHub Copilot is even worse. Feels like they're so obsessed with keeping that $10/month price point that they've gutted everything. Context window is tiny and the responses are barebones.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Links to the project, I'm guessing these :)https://github.com/codestoryai/aidehttps://aide.dev/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;If it's a fork of VS code it should be trivial to also support Linux and Windows. Why is it MacOs only?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42063346</guid></item><item><title>23. Defibrillation devices save lives using 1k times less electricity</title><link>https://news.ycombinator.com/item?id=42056954</link><description>
&lt;![CDATA[
&lt;p&gt;109 points points by wglb on 2024-11-06T02:54:44 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The article is about internal defibrillators. External ones are still the same as (good grief) 35 years ago (well maybe down from 300J to 200J). The only change I've noticed is moving from a gel for the pads to a gel pad (which feel like a frog, chuck one in your partners bed and let them find it!) which reduced the possibility of burning and odd smells in your ambulance. Fortunately my sense of smell wasn't great and often had a partner who smoked (and was allowed to in the olden days) in the ambulance to dull it. You kids don't know how it was having to actually manually read the trace instead of all this new-fangled automation that guides you through it.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is actually interesting for multiple reasons. One is the technology. The other is the positive outcome rate for cardiac arrest after 30 days is so low.The percentage of cardiac arrest survivors with positive outcomes 30 days after release depends on the type of cardiac arrest, and can range from 40% to 82%:In-hospital cardiac arrest (IHCA)
The 30-day survival rate for IHCA is around 25% in the United States and up to 35% in European countries. *In one study, the 30-day survival rate was 40%, with 34% of survivors having good neurological outcomes*.Out-of-hospital cardiac arrest (OHCA)
The probability of survival after OHCA can be increased by providing immediate cardiopulmonary resuscitation (CPR) and using an automated external defibrillator (AED). In one study, *10% of people who experienced OHCA survived with a favorable neurological outcome*.https://pmc.ncbi.nlm.nih.gov/articles/PMC8359113/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This appears to be a simulation study done in 2d.Similar results have been observed in 2d simulations for more than 20 years, no one had managed to translate them to application.One of the problems is, that 2 d and 3d reaction-diffusion systems are very different when it comes to so-called topological charge conservation. One can show that interactions of the applied electrical field can be described by its influence on the topological charges.In 2d these topological charges are limited to points in 3d they form curves.Points are limited to drifting and colliding, lines can twist, self collide, form rings and so on making translating 1d results to 3d quite difficult.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056954</guid></item><item><title>24. What Shapes Do Matrix Multiplications Like?</title><link>https://news.ycombinator.com/item?id=42055616</link><description>
&lt;![CDATA[
&lt;p&gt;156 points points by skidrow on 2024-11-05T22:08:24 &lt;/p&gt;
&lt;p&gt;The website explains the concept of matrix multiplication by visually illustrating how it is performed through a step-by-step process. It breaks down the calculations involved in multiplying two matrices and shows examples of different matrix shapes to demonstrate how they are manipulated in the multiplication process. The resources aim to provide a clear understanding of matrix operations and help users grasp the fundamentals of linear algebra.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I recall some optimization advice to choose a leading dimension that is NOT a power of two, in order to avoid cache set associativity conflicts. Guess it's highly hardware dependent (in particular, that advice was for cpu's not GPU's).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Great post! I appreciate the diagrams.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;TL;DR: make sure your matrix dimensions are divisible by 2 often.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055616</guid></item><item><title>25. Forget CDK and AWS's insane costs. Pulumi and DigitalOcean to the rescue</title><link>https://news.ycombinator.com/item?id=42065561</link><description>
&lt;![CDATA[
&lt;p&gt;136 points points by mavdi on 2024-11-06T17:15:43 &lt;/p&gt;
&lt;p&gt;The GitHub repository stoix-cloud-saver is a storage management tool designed to help users save and restore their digital assets efficiently. It includes features such as backups, archives, and retention policies for organizations looking to manage their cloud storage effectively. The tool aims to simplify the process of storing and recovering data on the cloud for users.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Hetzner has been our "expensive AWS cloud costs" saviourWe've also started switching our custom Docker compose + SSL GitHub Action deployments to use Kamal [1] to take advantage of its nicer remote monitoring features[1] https://kamal-deploy.org&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;For anyone deliberating between Pulumi and CDK let me recommend what I consider the best of both worlds: CDKTF, Hashicorp’s answer to Pulimi (my quote not theirs).It’s got everything you want:- strong type system (TS),- full expressive power of a real programming language (TS),- can use every existing terraform provider directly,- compiles to actual Terraform so you can always use that as an escape hatch to debug any problems or interface with any other tools,- official backing of Hashicorp so it’s a safe betIt’s a super power for infra. If you have strong software dev skills and you want to leverage the entire TF ecosystem without the pain of Terraform the language, CDKTF is for you.(No affiliation)https://developer.hashicorp.com/terraform/cdktf&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Pulumi is really a royal piece of shit.  Why the f*ck am I writing code to do "deployment".  In C# --&gt; new Dictionary&lt;string, object&gt; when dealing with a values.yaml for instance.  The whole need to figure out when and when not to use Apply.Give me Terraform (as much as I hate it) any day.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42065561</guid></item><item><title>26. WebSockets cost us $1M on our AWS bill</title><link>https://news.ycombinator.com/item?id=42067275</link><description>
&lt;![CDATA[
&lt;p&gt;305 points points by tosh on 2024-11-06T18:50:02 &lt;/p&gt;
&lt;p&gt;This article discusses how the use of WebSockets significantly increased the AWS bill of a company, leading to unexpected high costs. It explains the challenges faced with scaling and managing WebSockets on AWS, highlighting the impact on cost and performance. The author shares valuable insights and recommendations on optimizing WebSocket usage to control expenses and improve system efficiency.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Classic story of a startup taking a "good enough" shortcut and then coming back later to optimize.---I have a similar story: Where I work, we had a cluster of VMs that were always high CPU and a bit of a problem. We had a lot of fire drills where we'd have to bump up the size of the cluster, abort in-progress operations, or some combination of both.Because this cluster of VMs was doing batch processing that the founder believed should be CPU intense, everyone just assumed that increasing load came with increasing customer size; and that this was just an annoyance that we could get to after we made one more feature.But, at one point the bean counters pointed out that we spent disproportionately more on cloud than a normal business did. After one round of combining different VM clusters (that really didn't need to be separate servers), I decided that I could take some time to hook up this very CPU intense cluster up to a profiler.I thought I was going to be in for a 1-2 week project and would follow a few worms. Instead, the CPU load was because we were constantly loading an entire table, that we never deleted from, into the application's process. The table had transient data that should only last a few hours at most.I quickly deleted almost a decade's worth of obsolete data from the table. After about 15 minutes, CPU usage for this cluster dropped to almost nothing. The next day we made the VM cluster a fraction of its size, and in the next release, we got rid of the cluster and merged the functionality into another cluster.I also made a pull request that introduced a simple filter to the query to only load 3 days of data; and then introduced a background operation to clean out the table periodically.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; One complicating factor here is that raw video is surprisingly high bandwidth.It's weird to be living in a world where this is a surprise but here we are.Nice write up though. Web sockets has a number of nonsensical design decisions, but I wouldn't have expected that this is the one that would be chewing up all your cpu.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The problem is not on network level.The problem is that the developers behind this way of streaming video data seem to have no idea of how video codecs work.If they are in control of the headless chromium instances, the video streams, and the receiving backend of that video stream...why not simply use RDP or a similar video streaming protocol that is made exactly for this purpose?This whole post reads like an article from a web dev that is totally over their head, trying to implement something that they didn't take the time to even think about. Arguing with TCP fragmentation when that is not even an issue, and trying to use a TCP stream when that is literally the worst thing you can do in that situation because of roundtrip costs.But I guess that there is no JS API for that, so it's outside the development scope? Can't imagine any reason not to use a much more efficient video codec here other than this running in node.js, potentially missing offscreen canvas/buffer APIs and C encoding libraries that you could use for that.I would not want to work at this company, if this is how they develop software. Must be horribly rushed prototypical code, everywhere.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42067275</guid></item><item><title>27. Hacking cars in JavaScript (Replay attacks in the browser with the HackRF)</title><link>https://news.ycombinator.com/item?id=42028890</link><description>
&lt;![CDATA[
&lt;p&gt;83 points points by rmason on 2024-11-02T20:05:17 &lt;/p&gt;
&lt;p&gt;The website discusses the concept of replay attacks in JavaScript, where an attacker intercepts and replicates data packets to impersonate a legitimate user. It explores how the HackRF tool can be used to capture signals for these attacks, demonstrating the potential vulnerabilities in security protocols such as the Key Fob Authentication System. The article delves into the technical aspects of replay attacks, providing insights on how to identify and prevent such malicious activities in various contexts.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Lots of other interesting projects on the author's site, check them out&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42028890</guid></item><item><title>28. Launch HN: Midship (YC S24) – Turn PDFs, docs, and images into usable data</title><link>https://news.ycombinator.com/item?id=42066500</link><description>
&lt;![CDATA[
&lt;p&gt;86 points points by maxmaio on 2024-11-06T18:05:55 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Heres a real world use case, our company has moved our pension provider. This provider like the old one sucks at providing me with a good way to navigate through the 120 funds I can invest in.I want to create something that can paginate through 12 pages of html, perform clicks, download pdf fund factsheet, extract data from this factsheet into excel or CSV. Can this help? What's the best way to deal with the initial task of automating webpage interactions systematically?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Congrats on the launch. I just sent y'all an email – I'm curious with what you can do with airline crew rosters.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Saw your demo video. Are you focusing on the finance sector primarily? It is a challenging industry IMO, requiring high accuracy and has strict privacy/security bar. How do you address these concerns?Curious what are the biggest complain from your users? Are they willing to manually auditing the numbers in the table, make sure the output is 1. accurate. 2. formatted in the table they expected.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42066500</guid></item><item><title>29. 131M American Buildings</title><link>https://news.ycombinator.com/item?id=42025037</link><description>
&lt;![CDATA[
&lt;p&gt;159 points points by marklit on 2024-11-02T09:03:28 &lt;/p&gt;
&lt;p&gt;The website details a project where advanced technology was used to scan buildings at Oak Ridge National Laboratory (ORNL) in collaboration with the Federal Emergency Management Agency (FEMA). The project aimed to generate highly detailed 3D models of structures to assist in disaster response planning and other emergency scenarios. High-tech equipment like LiDAR scanners and a cutting-edge imaging technique called structured-light 3D scanning were utilized to capture accurate representations of the buildings. The website provides a detailed account of the technology used, the process involved, and the significance of the project for enhancing emergency preparedness and response efforts.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;About this website: as soon as i scroll downwards, the font-size doubles and page margins increase quite a bit. So I'm reading skinny paragraphs in large-ish type.As soon as i scroll upwards, the font size shrinks back to normal and page margins similarly retreat.No matter where i am in the page, i scroll down it does the one; i scroll up it does the other.FWIW I'm using the DuckDuckGo browser on Android.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I am tempted to import this data into my system and build a pivot table of building type (PRIM_OCC) by state.I could then graph the data (pie chart, bar graph, etc) to show how the building type distribution (e.g. residential ratio per hospital) varies between the states.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;any cool ideas I could build with this data?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42025037</guid></item><item><title>30. Physicists spot quantum tornadoes twirling in a 'supersolid'</title><link>https://news.ycombinator.com/item?id=42067233</link><description>
&lt;![CDATA[
&lt;p&gt;84 points points by elsewhen on 2024-11-06T18:46:53 &lt;/p&gt;
&lt;p&gt;Physicists have observed quantum tornadoes within a supersolid, a strange state of matter that combines the properties of a solid and a superfluid. The researchers used a novel experimental setup to visualize these tornado-like excitations and gain insights into the behavior of supersolids. The findings offer new understanding of exotic quantum phenomena and potential applications in quantum information processing.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I’m way out of my depth in this subject, but I find this incredibly fascinating.I had to read up on supersolids; still not fully understanding.I once had a naïve perspective that we’d figured out all the “big” stuff in science, but I’m now of the perspective that we’re still only scratching the surface.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;there were missing waffles, next to the gnocci and spaghetti&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42067233</guid></item><item><title>1. Using Ghidra and Python to reverse engineer Ecco the Dolphin</title><link>https://news.ycombinator.com/item?id=42076884</link><description>
&lt;![CDATA[
&lt;p&gt;390 points points by bbayles on 2024-11-07T14:25:30 &lt;/p&gt;
&lt;p&gt;The website scrutinizes the game "Ecco the Dolphin," exploring its gameplay elements, philosophical undertones, and unique qualities in the gaming landscape. The author delves into the game's exploratory and atmospheric design, discussing its challenging gameplay mechanics and thought-provoking narrative elements that set it apart from conventional video games.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The hash is merely a CRC32; exactly this one (polynomial 0x77073096, code is wrong)https://web.mit.edu/freebsd/head/sys/libkern/crc32.c(The decoded ints in the post are the constants in this CRC32).Knowing it's a CRC32 and knowing the polynomial allows inverting the answers in log time instead of exponential time by exploiting the modular math of the polynomial rings.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;When the original Ecco came out on the Megadrive (Genesis), I spent all my hard-earned money to buy it. That game is obscenely hard. I got frustrated, so I sat down for the afternoon with a pen and paper and somehow managed to decode the password system. I teleported to the final level and completed it the next day.Then I was wracked with guilt about spending all my money on a game I completed in two days.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;QQRIQ is a phonetic abbreviation of "kukuriku", which is the sound of the rooster in Hungarian and in several other languages (Polish "kukuryku", Hebrew " קוקוריקו" etc.). Makes wonder what the process for choosing the passwords was.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:46:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42076884</guid></item><item><title>2. I'm not mutable, I'm partially instantiated</title><link>https://news.ycombinator.com/item?id=42073001</link><description>
&lt;![CDATA[
&lt;p&gt;196 points points by tlack on 2024-11-07T03:17:45 &lt;/p&gt;
&lt;p&gt;The website discusses incomplete data structures in programming and the importance of handling partial or missing data effectively to avoid errors and ensure robustness in software development. It explores strategies for dealing with incomplete data, such as using sentinel values, optional types, or proper error handling techniques to maintain data integrity and enhance the reliability of programs. The article emphasizes the need to consider different scenarios when working with incomplete data structures to improve the overall quality and performance of software systems.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I've never used it in production, but I have a deep love of Prolog, just because of how different it is from any other programming language I've used. As a programming paradigm, it found it as eye-opening as functional programming. What I found interesting is that you are operating on logical statements and pattern matching, which often means that the same "function" can be used for multiple different things. For example:append([], List, List).append([Head|Tail], List, [Head|Rest]) :-
    append(Tail, List, Rest).Is a simple list append function: append(X, Y, Z) is a predicate that match if Z is the list of all elements of X, followed by all elements of Y. You can use it to concatenate lists, of course. But you can also use it to confirm that a particular list start with a particular sequence, or ends with a particular sequence! The idea that the same predicate can be used in multiple different ways is really fascinating to me. I have no idea to what extent that would scale in a large system, but it's very interesting&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Partially instantiated data structures are also available in Haskell (via Laziness), in OCaml (via tail modulo cons, https://inria.hal.science/hal-03146495/document) and Koka (via constructor contexts, https://dl.acm.org/doi/pdf/10.1145/3656398)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It seems like whether this represents a mutable or immutable data structure depends on the operations you allow. If polling with nonvar() is allowed, couldn’t you see variables mutate as you do more unification? But if it’s not allowed, I guess you get a variable to be defined later?Compare with a Promise. If you can check whether it resolved, you can see it mutate. If the only operation allowed is to await it then from the code’s point of view, it might be considered an immutable reference to the pending result.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42073001</guid></item><item><title>3. QNX is now free for anything non-commercial, plus there's an RPi image</title><link>https://news.ycombinator.com/item?id=42079460</link><description>
&lt;![CDATA[
&lt;p&gt;548 points points by JohnAtQNX on 2024-11-07T18:35:22 &lt;/p&gt;
&lt;p&gt;The website provides information about the QNX operating system and its applications in various industries like automotive, medical, and industrial automation. It highlights the reliability, security, and real-time capabilities of QNX for developing embedded systems in connected vehicles, autonomous driving, healthcare devices, and smart factories. The website promotes QNX as a versatile and robust solution for enabling innovation in the Internet of Things (IoT) ecosystem and connecting devices across different sectors.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;If only you could believe them.QNX has been "opened" twice before. Each time, there was a rug pull, and it went closed again.Before the first rug pull, open source groups routinely added QNX to their target list. There was a Firefox for QNX. Eclipse had QNX as a target. GCC and most of the Gnu command line tools could be built for QNX.
There was a desktop environment, Photon. I used that as a primary desktop for three years when working on a DARPA Grand Challenge vehicle.All of that went away after the Harman acquisition of QNX in 2004.Then, in 2007, QNX went open source. You could even look at the microkernel. It wasn't openly licensed, but you could look inside and build it.In 2010, RIM acquired QNX, and, with no warning, closed the source. All open source development related to QNX ceased, and QNX lost all credibility in the community. So QNX shot itself in the foot. Twice.Note the contractual terms.[1] "TERMINATION. This Agreement and licenses granted hereunder may be terminated by either Party upon written notice to the other Party". QNX can pull the plug at any time. Since they've done so twice in the past, there's a good chance that will happen again.Now, if QNX is serious about this, the way to go is to use the licensing model Epic uses for Unreal Engine. Unreal Engine is behind most AAA game titles. The basic terms are that you can download the source and use it for anything you want, and there's no charge until you get the first $1 million in revenue from your product. Then Epic takes a 5% royalty.[2] This has been extremely successful for Epic. There's not much of a piracy problem, because if your game gets enough revenue to matter, it has enough visibility that their licensing people will notice. Meanwhile, there's a large pool of people using Unreal Engine.That's the way to do it if you want more adoption of QNX. Take the Epic term sheet to your lawyers and management. And have them take a look at Unreal Engine's revenue growth vs. QNX.As I once told a QNX sales rep, your problem isn't that you're being pirated. It's that you're being ignored.[1] http://www.qnx.com/download/feature.html?programid=51624[2] https://cdn2.unrealengine.com/UnrealEngine/faq/UnrealEngineE...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;For QNX 8.0, here’s a saved-you-five-minutes direct link to the developer terms associated with noncommercial use:https://support7.qnx.com/download/download/51624/BB_QNX_Deve...(I am not your lawyer, this is not legal advice. This is not a comprehensive review, assessment, or summary of possible interpretations of that license. Seek professional counsel from a lawyer before acting on anything stated below.)These terms open with a ‘user did not have an opportunity to review and agree before binding themselves, their business, and/or their institution’ clause that may well wholly invalidate the entire document in the US, so please review these with your lawyer before use, so that your usage is not put at risk due to legalese overreach.Academics, only students and faculty of your institution qualify, and your usage under this license will be viewed by your legal team as you signing a binding agreement on behalf of your employer; make sure you’re not exposed to liability through open source contributors or at risk of being fired for misrepresenting yourself as a signing authority for your institution.Cloud users, your license is restricted to AWS per their terms; use on GCP, Heroku, or any other server instance not under your personal contractual control may result in owing licensing fees.Only OSI definitions of “Open Source” are permissible here; this disqualifies anyone licensing software under a restrictive non-commercial license from making use of the QNX non-commercial license, as per OSI, all such restrictions are not “open source”.Social apps are excluded by the “high risk” clause, which prohibits any use under these terms to develop applications that could harm society. Take care not to  create viral applications that violate this clause.They collect and retain all serial numbers identifiable on all hardware you use in association with this product.Your noncommercial license may be severed unconditionally at any time without recourse, regardless of whether you have faithfully complied with the terms; at which time you may be compelled under contract to provide an undefined ‘certification’ of indeterminate cost that you deleted all QNX code provided to you.Stay safe, folks.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;15 years too late (since you last snatched QNX away from us), and with a license that you can revoke at any time. What are you blackberry folk smoking?I guess your "benevolence" is no coincidence given that real-time support was merged into the linux kernel a month ago...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42079460</guid></item><item><title>4. AI for real-time fusion plasma behavior prediction and manipulation</title><link>https://news.ycombinator.com/item?id=42077319</link><description>
&lt;![CDATA[
&lt;p&gt;248 points points by agomez314 on 2024-11-07T15:12:10 &lt;/p&gt;
&lt;p&gt;The website discusses the application of machine learning for real-time profile control in tokamaks, which are devices used to harness nuclear fusion as a potential clean energy source. The article highlights the challenges of controlling plasma parameters within tokamaks and proposes using machine learning algorithms to optimize control strategies and improve performance. Various approaches, such as neural networks and reinforcement learning, are explored for their potential to enhance tokamak operation and efficiency through adaptive control strategies.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;See also https://www.ri.cmu.edu/ai-meets-fusion-cmu-princeton-join-fo...(that was the submitted link but we changed it via https://news.ycombinator.com/item?id=42077657)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;TIL: it's not just buzzwords.https://en.wikipedia.org/wiki/Fusion_power#Machine_learning&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;There is a lot of AI research in the nuclear fusion space. For inertial confinement fusion (a competing technology to magnetic confinement fusion, e.g., tokamaks) the National Ignition Facility (NIF) used it for their experiment that resulted in "ignition."My lab is collaborating with researchers at the Laboratory for Laser Energetics to use AI to improve inertial confinement fusion (ICF). We recently put out this paper [1] using Kolmogorov-Arnold Networks (KANs) to predict the outcome of ICF experiments. Currently, existing physics simulators are based on old Fortran code, are slow, and have a high error between their predictions and actual laser shots, so among other goals, we are trying to build better predictors using neural networks. This is needed since it is hard to rapidly iterate on real data, since they only have a dataset of around 300 ICF shots.[1] https://arxiv.org/abs/2409.08832&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42077319</guid></item><item><title>5. Visualizing binary files with ImHex's DSL, the "pattern language"</title><link>https://news.ycombinator.com/item?id=42070153</link><description>
&lt;![CDATA[
&lt;p&gt;180 points points by xy2_ on 2024-11-06T22:00:09 &lt;/p&gt;
&lt;p&gt;The article discusses the application of the Imperative Hexagon System (ImHexS) pattern language for parsing binary structures. It explains how the language can be employed to describe and understand various aspects of binary formats, allowing for efficient parsing and manipulation of binary data. The example provided showcases the power and flexibility of ImHexS in handling complex binary structures.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I have a strong memory that AFL - american fuzzy lop the binary fuzzer had a feature similar to what this was doing based on the highlighted portions and screenshots. It wasn't the AFL status screen, it was (may have been a) third party app, and it would color code parts of the input files based on the outputs or whatever from afl's processing.For example, there was a color key that explained that say, purple meant "magic bytes", like "0x4a46494600" for JFIF0, and if any part of the input file caused errors it meant it was probably a checksum and needed to be "fixed" so afl could properly fuzz all the functions in the source code.I'm not super in to fuzzing or that realm anymore, so i doubt i could describe it better than i did, here. I clicked through to see if someone have leveraged the AFL stuff for use in another tool, which would be cool.edit: i think it was afl-analyze - i had a go at the source code for aflplusplus:&gt;  A nifty utility that grabs an input file and takes a stab at explaining its structure by observing how changes to it affect the execution path.&gt; Another tool in AFL++ is the afl-analyze tool. It takes an input file, attempts to sequentially flip bytes and observes the behavior of the tested program. It then color-codes the input based on which sections appear to be critical and which are not; while not bulletproof, it can often offer quick insights into complex file formats.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Other tools for parsing and analyzing binary data are listed here: https://github.com/dloss/binary-parsing&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Kind of related, a tool that allows you to hand write ASCII-art-annotated hex dump files, while also able to generate the original binary file from such text file: https://github.com/netspooky/xx/blob/main/examples/elf.xx&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42070153</guid></item><item><title>6. Excerpts from a conversation about personal information management</title><link>https://news.ycombinator.com/item?id=42076200</link><description>
&lt;![CDATA[
&lt;p&gt;165 points points by JNRowe on 2024-11-07T12:50:29 &lt;/p&gt;
&lt;p&gt;The website contains excerpts from a conversation with John Wiegley, JohnW, and Adam Porter, Alphapapa, discussing personal information management (PIM). The conversation delves into various tools and strategies for managing personal information effectively, including the use of Emacs Org mode, reminders, capturing ideas, and maintaining a knowledge base. They explore how to streamline workflows, prioritize tasks, and optimize information retrieval processes to enhance productivity and organization within personal and professional contexts.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The note on semantic and operational distinction of notes is interesting. I personally ditched hierarchies when I switched to Org-Roam. I used to think all the time where a specific note would belong - should I organize my notes by dates? Should I use the datetree feature of Org-Mode? Should I put everything in one file or split between multiple files grouping notes by some categories or tags.These days, the only question I have to ask myself is "in what context do I want to rediscover this note?". For example, I don't usually sit around thinking: "Didn't we discuss this SSH-related problem with Jeffrey and Anna back in May? Let me go to the may-2024 folder of my notes and grep through them...". Instead, I would just go to either of these notes titled: 'ssh' or 'Jeffrey' or 'Anna' and search for backlinks, where I will surely find my notes related to that discussion, even if they're spread out across multiple days and many notes in multiple places. And it doesn't really matter where specific notes are - which file, what nested hierarchy of headings, etc.Zettelkasten really does work. You just need a quick an easy way of cross-linking different notes. I highly recommend this little book called 'How to Take Smart Notes', it's fairly small, you can go through it within an hour or so. And remember the famous quote of Richard Feynman: "Notes aren't a record of my thinking process. They are my thinking process"... If you don't find a good way of taking notes, you won't be doing a good job of thinking.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Wiegley's "Today's agenda has 133 items on it," now joins David Foster Wallace's "I received 500,000 discrete bits of information today," in quotes I wish I could recite to others to express how I think and feel.Tangentially,&gt; I have over 30,000 tasks in my Org Mode overall. 23,000 of them are TODOs. Several thousand of them are still currently open. I'm never gonna see them all. Even if I wanted to, I'm never gonna see them all.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I think this is interesting but I'm totally out of the loop.He links to https://github.com/brabalan/org-review - what is that? What is org mode and org mode review? What is a sketchnote and how do you create one?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42076200</guid></item><item><title>7. Ultraprecise method of aligning 3D semiconductor chips invented</title><link>https://news.ycombinator.com/item?id=42013508</link><description>
&lt;![CDATA[
&lt;p&gt;142 points points by thebeardisred on 2024-11-01T02:25:40 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Could this also be used for manufacturing lots of other microscopic things? layer by layer?"Instead, their method finds errors up to 0.017 nm along side-to-side measures (x and y axes) and 0.134 nm when assessing the distance between the two chips (z-axis)."Could you make some very very sensitive and tiny seismic sensors with this?edit:
"
Arbabi also points out that this method can be used to make displacement sensors that can be used for measuring displacements and other quantities. "Many physical quantities that you want to detect can be translated to displacements, and the only thing you need is a simple laser and a camera," he says.For instance, "if you want a pressure sensor, you could measure the movement of a membrane." Anything that involves movement—vibration, heat, acceleration—can in theory be tracked by this method."&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The last bit about using this same technique for sensors is pretty cool. Ultra-sensitive microphones or touch sensors would be pretty awesome.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is not novel in general - the same technique has been used in lens alignment for decades.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42013508</guid></item><item><title>8. Linux Syscall Support</title><link>https://news.ycombinator.com/item?id=42022088</link><description>
&lt;![CDATA[
&lt;p&gt;175 points points by btdmaster on 2024-11-01T22:14:12 &lt;/p&gt;
&lt;p&gt;The website provides support for Linux system calls in the Chromium project, focusing on enabling system call emulation for sandboxed processes. It offers code, tools, and resources to aid in developing and maintaining system call support within the Chromium browser for Linux-based environments. The site is a collaborative platform dedicated to improving system call compatibility and security for Chromium on Linux systems.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;See also Linux's nolibc headers, which allows one to write C software that completely bypass libc, but instead directly operate through syscalls.https://github.com/torvalds/linux/tree/master/tools/include/...A sample use-case? I was developing an Erlang-like actor platform that should operate under Linux as well as a bare-metal microkernel, and all I needed is a light layer over syscalls instead of pulling the entire glibc. Also it provides a simple implementation for standard C functions (memcpy, printf) so I don't have to write them myself.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Can't wait for Zig team to adopt this over libc, citing concerns about "libc not existing on certain configurations"[1][1] https://github.com/ziglang/zig/issues/1840&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Disappointing that errors are still signaled by assigning to `errno` (you can apparently override this to some other global, but it has to be a global or global-like lvalue).The kernel actually signals errors by returning a negative error code (on most arches), which seems like a better calling convention. Storing errors in something like `errno` opens a whole can of worms around thread safety and signal safety, while seemingly providing very little benefit beyond following tradition.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42022088</guid></item><item><title>9. Automat</title><link>https://news.ycombinator.com/item?id=42013109</link><description>
&lt;![CDATA[
&lt;p&gt;230 points points by surprisetalk on 2024-11-01T01:07:56 &lt;/p&gt;
&lt;p&gt;Automat is an art collective that utilizes new technology to create interactive installations and experiences. They focus on merging art, technology, and human interaction to create immersive and engaging digital artworks. Their projects include a variety of mediums such as light, sound, and interactivity, all aimed at exploring the intersection between art and technology. Through their work, Automat aims to push boundaries, challenge perceptions, and inspire creativity in the digital age.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;So let me get this straight, not only does it not explain what it is, it's a bit of a puzzle to even get to the download links, and then it straight up downloads an .exe which you expect me to run on my computer?Give me more info without me having to pry it out of you through finding your github which honestly isn't much more descriptive.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This style of website will be rife soon - there’s more and more popping up. Even yesterday, I was looking at https://comancheindians.tilda.ws/enThese websites would have been super hard to resource the assets, but now with Gen AI it’s simple.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;An interesting experiment, very reminiscent of the early 90s' Magic Cap, Microsoft Bob, et al. But objects in physical
space afford a discoverability that can't be replicated here, and the metaphor thus quickly and inevitably becomes a burden.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42013109</guid></item><item><title>10. Australia proposes ban on social media for those under 16</title><link>https://news.ycombinator.com/item?id=42071310</link><description>
&lt;![CDATA[
&lt;p&gt;459 points points by robbiet480 on 2024-11-06T23:38:58 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Given the lack of interest in the industry “self” regulating, and/or taking responsibility of, the content; what other option is there. It seems there’s little interest globally.With my direct and indirect experiences of social media; I strongly support this.That said; how does a young individual get updates to public transport outages that are only available via twitter/x, or read the menu of the local cafe that is only posted on Facebook?I do worry about the implementation, especially if government owned. The government has, in the past, said one thing and executed another. (DNS metadata collection for ISP’s, for example) Whilst I have nothing to hide, and am happy to be entirely transparent with them; I can appreciate, respect, and understand the hesitation.And, if government owned; how long until it’s “privatised”.Will be interesting to see how this plays out.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Apart from the logistical issues with tracking and verifying everyone's identity, I think cutting teenagers off from an (admittedly very manipulated and dysfunctional) source of community is not a straightforwardly good idea. To give some examples, isolated LGBT teenagers probably benefit from being able to find and talk to people like them, and people into all kinds of niche hobbies and interests can be inspired to learn and create by other people into the same thing (cosplayers, digital artists, electronic musicians, etc). Also social media is used for organizing a ton of IRL events as well. (It would be nice if online community was not all centered on Facebook/Twitter/etc, but unfortunately that's the current situation.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;As usual, the problem with this is that it assumes a way to perfectly identify somebody on the internet, which in turns mean a way to perfectly identify, in real time, somebody carrying permanently a tracking device with GPS, microphone and camera.It's crazy that all the things we considered the worst of dystopia in the 80's, thinking nobody would be stupid enough to do, and that those societies in SF books were only distant fictions, are things we are actively seeking now.Things like "Find my" and "air tags" are already beloved my millions, people use it to track loved ones and they swear by it. Even very intelligent, educated people.There is such a cognitive dissonance between people swearing the last election meant a likely dictatorship and the same people setting up a tech rope around their necks in case a dictatorship does happen.My now-dead Jewish grandfather met my grandmother during the French occupation because she was making fake papers. He would be horrified if he knew what we are doing right now with our data.My German ex was born in East Germany, 11 years before the fall of the Berlin Wall. She thinks people are mad to believe that tracking is not going to be abused.What the hell is going on?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42071310</guid></item><item><title>11. Launch HN: Codebuff (YC F24) – CLI tool that writes code for you</title><link>https://news.ycombinator.com/item?id=42078536</link><description>
&lt;![CDATA[
&lt;p&gt;241 points points by jahooma on 2024-11-07T17:06:28 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Congratulations on your launch!  But I confess that I am really confused.  This sounds exactly like Aider, but closed source and it's locked into a single LLM API?  I just watched you use it, and looks a lot like Aider too?  Why would I use this over Aider?I've seen people say "you don't have to add files to Codebuff", but Aider tells me when the LLM has requested to see files.  I just have to approve it.  If that bothers you, it's open source, so you could probably just add a config to always add files when requested.Aider can also run commands for you.What am I missing?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The demos I see for these types of tools are always some toy project and doesn't reflect day to day work I do at all. Do you have any example PRs on larger more complex projects that have been written with codebuff and how much of that was human interactive?The real problem I want someone to solve is helping me with the real niche/challenging portion of a PR, ex: new tiptap extension that can do notebook code eval, migrate legacy auth service off auth0, record and replay API GET requests and replay a % of them as unit tests, etc.So many of these tools get stuck trying to help me "start" rather than help me "finish" or unblock the current problem I'm at.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Noting Codebuff is manicode renamed.It's become my go-to tool for handling fiddly refactors. Here’s an example session from a Rust project where I used it to break a single file into a module directory.https://gist.github.com/cablehead/f235d61d3b646f2ec1794f656e...Notice how it can run tests, see the compile error, and then iterate until the task is done? Really impressive.For reference, this task used ~100 credits&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42078536</guid></item><item><title>12. URAvatar: Universal Relightable Gaussian Codec Avatars</title><link>https://news.ycombinator.com/item?id=42074348</link><description>
&lt;![CDATA[
&lt;p&gt;114 points points by mentalgear on 2024-11-07T07:20:32 &lt;/p&gt;
&lt;p&gt;The website provides information about the Urgently Generated Captioning Assistance (URGCA) project, which aims to develop a system for generating accurate and timely captions for emergency broadcast messages. The project focuses on improving real-time captioning quality using automatic speech recognition (ASR) technology and enhancing communication accessibility for individuals who are deaf or hard of hearing during emergencies.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Given the complete lack of any actual details about performance I would hazard a guess that this approach is likely barely realtime, requiring top hardware, and/or delivering an unimpressive fps. I would love to get more details though.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Who will use this? Handing over your photo information so someone can impersonate you in video call to trick your family or friends?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Seems like this would (eventually) be big for VR applications. Especially if the avatar could be animated using sensors installed on the headset so that the expressions match the headset user. Reminds me of the metaverse demo with Zuckerberg and Lex Friedman&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42074348</guid></item><item><title>13. The guy who gave a negative review to Battlezone 98 Redux after playing 8k hours</title><link>https://news.ycombinator.com/item?id=42015269</link><description>
&lt;![CDATA[
&lt;p&gt;266 points points by isaacfrond on 2024-11-01T09:27:22 &lt;/p&gt;
&lt;p&gt;The article follows the author's quest to find and interview a player who left a negative review for the game Battlezone 98 Redux after playing for over 8,000 hours. Despite the dedication of the player, the review highlighted valid concerns with the game's development and community issues. The author explores the nuanced perspective of the player and their criticisms, ultimately finding that the negative review was justified and sheds light on important aspects of the gaming community and industry.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;To be fair, it kinda makes sense. The person best equipped to criticise a game or work is probably often someone who's experienced it for the longest. That way, they get to know all the things that don't add up, get repetitive on repeat playthroughs, various UI and UX annoyances that get worse the more you experience them, etc.There's a reason the biggest fans of a game or film or TV series tend to give some of the harshest criticism, and why the most active users of a tool or program tend to have the most to say about it.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I loved this game growing up as it was one of the few games which ran well on our family computer, despite not having an internet connection to participate in any of the PvP elements. It was probably the most played game of my childhood. I've also logged almost 300 hours in the redux version on steam.Interestingly, since I didn't have the internet to participate in the MMO elements of the game, my views of it are entirely rooted in the storyline and campaigns. The community is something I haven't experienced. And none of these netcode or pvp bugs or phantom players showed up there.I love the game. In the single player modes, you can play as the NSDF (US) forces, USSR, (and later as the Chinese forces too) in a sci-fi retelling of the space race where you discover alien relics throughout our solar system and try to piece together where they came from, and more importantly, where they went. And it did this while combining a first-person vehicle combat mode with a top-down RTS system that, in my opinion, worked really well together. And I still take inspiration from it in hobby game projects I work on.Now that I've grown up as a software developer I've thrown so many hours into writing Lua scripts to build my own missions and AI, and creating custom maps!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;My god I love BZ98. For me, the remaster was frustrating. The most annoying thing was that certain things, like the combat AI, had been improved in ways that broke the balance of the single player campaign. I doubt players with the subject’s level of mastery would be bothered, but it significantly reduced my enjoyment.It remains a rare gem, though. There are so few RTSs that place you in the world there isn’t even a name for the genre. The only others I can think of are Brutal Legend and Sacrifice. But BZ98 was the one that I discovered first.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42015269</guid></item><item><title>14. Mushroom Color Atlas</title><link>https://news.ycombinator.com/item?id=42078581</link><description>
&lt;![CDATA[
&lt;p&gt;219 points points by gaws on 2024-11-07T17:12:39 &lt;/p&gt;
&lt;p&gt;The website serves as an extensive Mushroom Color Atlas that showcases a wide variety of mushroom species with detailed photographs and descriptions. It aims to educate individuals about different types of mushrooms, focusing on their colors and unique features to aid in identification. The collection of images and information provides a valuable resource for mushroom enthusiasts, researchers, and anyone interested in learning more about these fungi.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This is so incredible. My friend's mom loves dying wool with natural pigments (she even gets her wool from local alpacas!) and she'll go crazy for this. She has wanted a blue/green for a while and it turns out there's one that actually grows around us.Actually a lot of these mushrooms can be found around where I live. I'll have to go on some hunts before winter!edit: It would be cool to see something like this for other materials like barks and leaves. As teenagers we used to go around the woods finding her all kinds of weird stuff to dye things with... usually while hunting for our own mushrooms (not for dying things)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I have the book this site is based on and it's beautiful. My wife is a quilter and we plan to make a quilt from our local foraging.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is absolutely beautiful.I’m tempted to make a color palette out of this spectrum for my plotting library! A “fungi” palette&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42078581</guid></item><item><title>15. Show HN: BemiDB – Postgres read replica optimized for analytics</title><link>https://news.ycombinator.com/item?id=42078067</link><description>
&lt;![CDATA[
&lt;p&gt;179 points points by exAspArk on 2024-11-07T16:25:40 &lt;/p&gt;
&lt;p&gt;The website is a repository for BemiDB, a tool used for simplifying and organizing JSON in a MongoDB database. It provides a user-friendly interface to easily manage and visualize data within MongoDB collections. BemiDB allows users to create, read, update, and delete documents in a user-friendly manner, making it easier to work with JSON data in MongoDB.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Looking at the syncer it seems like copying data to csv from the whole table everytime (?)
Code: https://github.com/BemiHQ/BemiDB/blob/6d6689b392ce6192fe521a...I cant imagine until at what scale can you do this and is there anything better we can do before using debezium to sync the data via cdc?Edit: add code permalink&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;As much as DuckDB is cute I've mostly come to believe that Clickhouse is the perfect thing to pair Postgres with. This is especially true now that they've acquired PeerDB and are integrating it into the Clickpipes cloud product.DuckDB is neat, and I understand why a company like BemiDB would build their product on top of it, but as a prospective customer embedded databases are a weird choice for serious workloads when there are other good open-source solutions like Clickhouse available.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;What I would really love is a dead simple way to:
1) connect to my transactional Postgres db
2) define my materialized views
3) have these views update in realtime 
4) query these views with a fast engineAnd ideally have the whole thing open source and be able to run it in CIWe tried peerdb + clickhouse but Clickhouse materialized views are not refreshed when joining tables.Right now we’re back to standard materialized views inside Postgres refreshed once a day but the full refreshes are pretty slow… the operational side is great though, a single db to manage.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42078067</guid></item><item><title>16. Functional ultrasound through the skull</title><link>https://news.ycombinator.com/item?id=42021450</link><description>
&lt;![CDATA[
&lt;p&gt;180 points points by lawrenceyan on 2024-11-01T20:52:45 &lt;/p&gt;
&lt;p&gt;The website discusses the process of Functional Ultrasound (fUS) imaging for brain research and neuroimaging studies. It explains how fUS can provide a high spatial and temporal resolution to capture brain activity in real-time. The article details the benefits, limitations, and applications of fUS technology in studying brain function, neuroscience, and potential future developments in the field.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Surely this is easily solved with time-reversed acoustics. Just stab a transmitter into the brain with an ice pick to the point you want to measure, and pick up the signal at lots of locations around the skull. Now you have both a mapping from an input signal (the reverse of the signal you picked up) that you can send to precisely target that point, and you know it looks like after it comes out from that point (the original signal you picked up).Now you can tell exactly what is going on and the person is thinking! Specifically it'll be either: (1) "oh my god, I have an ice pick in my brain" or (2) nothing, because they have an ice pick in their brain.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;“The thing that nobody tells you is that you can buy a real human skull online (shoutout to skullsunlimited.com). We did that, and then CT scanned it.”This is an A+&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is fun, and the modeling is cool for sure, but it's well known that ultrasound can be used with surgical precision in the human brain.Focused ultrasound is already used for non-invasive neuromodulation. Raag Airan's lab at Stanford does this for example using ultrasound uncaging.https://www.frontiersin.org/journals/neuroscience/articles/1...https://www.sciencedirect.com/science/article/pii/S089662731...Also see the work by Urvi Vyas, eghttps://pubmed.ncbi.nlm.nih.gov/27587047/I don't mean to discount the cool imaging-related reconstruction of a point spread function, but rather to say that ultrasound attenuation through the skull an soft tissue has already been well characterized and it's not a surprise that it is viable to pass through.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42021450</guid></item><item><title>17. Evaluating the world model implicit in a generative model</title><link>https://news.ycombinator.com/item?id=42073801</link><description>
&lt;![CDATA[
&lt;p&gt;146 points points by dsubburam on 2024-11-07T05:51:32 &lt;/p&gt;
&lt;p&gt;The website presents a research paper titled "Adaptive Robustness for Deep Learning," authored by Hu et al. The paper introduces a new approach to enhance the robustness of deep learning models through a technique called Adversarial Training with Dynamic Adversarial Perturbations (AT-DAP). This method aims to improve the model's resilience against adversarial attacks by dynamically adjusting the perturbations during training, leading to enhanced generalization and performance gains on image classification tasks. The authors conduct experiments across various datasets and demonstrate the effectiveness of the proposed approach in improving the robustness of deep learning models.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;An LLM necessarily has to create some sort of internal "model" / representations pursuant to its "predict next word" training goal, given the depth and sophistication of context recognition needed to to well. This isn't an N-gram model restricted to just looking at surface word sequences.However, the question should be what sort of internal "model" has it built? It seems fashionable to refer to this as a "world model", but IMO this isn't really appropriate, and certainly it's going to be quite different to the predictive representations that any animal that interacts with the world, and learns from those interactions, will have built.The thing is that an LLM is an auto-regressive model - it is trying to predict continuations of training set samples solely based on word sequences, and is not privy to the world that is actually being described by those word sequences. It can't model the generative process of the humans who created those training set samples because that generative process has different inputs - sensory ones (in addition to auto-regressive ones).The "world model" of a human, or any other animal, is built pursuant to predicting the environment, but not in a purely passive way (such as a multi-modal LLM predicting next frame in a video). The animal is primarily concerned with predicting the outcomes of it's interactions with the environment, driven by the evolutionary pressure to learn to act in way that maximizes survival and proliferation of its DNA. This is the nature of a real "world model" - it's modelling the world (as perceived thru sensory inputs) as a dynamical process reacting to the actions of the animal. This is very different to the passive "context patterns" learnt by an LLM that are merely predicting auto-regressive continuations (whether just words, or multi-modal video frames/etc).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Really glad to see some academic research on this- it was quite obvious from interacting with LLMs that they form a world model and can, e.g. simulate simple physics experiments correctly that are not in the training set. I found it very frustrating to see people repeating the idea that “it can never do x” because it lacks a world model. Predicting text that represents events in the world requires modeling that world. Just because you can find examples where the predictions of a certain model are bad does not imply no model at all. At the limit of prediction becoming as good as theoretically possible given the input data and model size restrictions, the model also becomes as accurate and complete as possible. This process is formally described by the Solomonoff Induction theory.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I've seen some very impressive results just embedding a pre-trained KGE model into a transformer model, and letting it "learn" to query it (I've just used heterogenous loss functions during training with "classifier dimensions" that determine whether to greedily sample from the KGE sidecar, I'm sure there are much better ways of doing this.). This is just subjective viewpoint obviously, but I've played around quite a lot with this idea, and it's very easy to get a an "interactive" small LLM with stable results doing such a thing, the only problem I've found is _updating_ the knowledge cheaply without partially retraining the LLM itself. For small, domain-specific models this isn't really an issue though - for personal projects I just use a couple 3090s.I think this stuff will become a lot more fascinating after transformers have bottomed out on their hype curve and become a tool when building specific types of models.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42073801</guid></item><item><title>18. A rudimentary quantum network link between Dutch cities</title><link>https://news.ycombinator.com/item?id=42008401</link><description>
&lt;![CDATA[
&lt;p&gt;153 points points by FrankyHollywood on 2024-10-31T16:21:18 &lt;/p&gt;
&lt;p&gt;A rudimentary quantum link has been successfully demonstrated between two Dutch cities by researchers at Delft University of Technology (TU Delft). This achievement marks a significant step towards a quantum internet, using quantum networks to create secure communication channels. The experiment involved transmitting quantum information over a distance of 1.3 kilometers using fiber-optic cables, showcasing the potential for quantum technology to revolutionize communication systems.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Hi all! I'm one of the co-authors. Honestly it's a dream to end up on HN with my research. As mentioned in the video we made, it has been a long road (6-7 years) to achieve this absolute moonshot of a project. I think we'll look back on this demonstration as the first experiment that truly made a distributed and real-world deployed quantum network. Not only did we use a (quantum) hardware platform capable of quantum processing, we also generated the entanglement in a way that it can be used in further quantum computations. In order for all this to work on a distributed network, we had to fully design and build the architecture to support that, both hard- and software. And we did it successfully!Besides hard-working PhD students, another key ingredient that our research institute QuTech facilitated, was the collaboration with expert hardware and software engineers, allowing us to quickly transform new ideas into (deployable) products. A great show of what's possible when academia mixes with professional engineering.
But of course there was enough hacking and tinkering going on that it warrants to be on HN ;)You can reply here if you have any questions, I'll be checking throughout the day. Thanks!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I've worked in quantum nonlinear optics during my first postdoc 12 years ago, and back then we could only dream of the efficiency of frequency conversions that are used here. So many advances in just a decade, and most of them don't even make the news.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;the article: https://www.science.org/doi/10.1126/sciadv.adp6442&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42008401</guid></item><item><title>19. Edge Scripting: Build and run applications at the edge</title><link>https://news.ycombinator.com/item?id=42079275</link><description>
&lt;![CDATA[
&lt;p&gt;102 points points by gnabgib on 2024-11-07T18:17:20 &lt;/p&gt;
&lt;p&gt;The website introduces Bunny Edge Scripting as a new method for building and deploying applications at the edge. It discusses the benefits of edge scripting, such as faster performance, reduced latency, and enhanced security, allowing developers to run code closer to end-users for a more efficient user experience. Bunny Edge Scripting is designed to simplify the process of deploying code to the edge servers while ensuring high availability and scalability for applications.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;"Please note that normal charges for CDN bandwidth are billed separately"Compared to cloudflare workers, which has free bandwidth, bunnys bandwidth is not that cheap at 0.01$/GBSo while their example suggests stream-encoding video is possible, it would probably be cost-prohibitive.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;  BunnySDK.net.http.serve(async (request: Request): Response | Promise&lt;Response&gt; =&gt; {
    return new Response("Hello World");
  });

I love that pretty much all the JS runtimes have settled on `(Request): Response`[0], but I really wish they would standardize starting the server as well. Would make writing cross-runtime services easier.[0]: https://blog.val.town/blog/the-api-we-forgot-to-name/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;They're undercutting CF Workers - requests are $0.2/million rather than $0.3/million, and CPU time costs the same.Seems pretty good on paper. There's no free allowance like you get with Workers though.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42079275</guid></item><item><title>20. Imaging shapes of atomic nuclei in high-energy nuclear collisions</title><link>https://news.ycombinator.com/item?id=42078826</link><description>
&lt;![CDATA[
&lt;p&gt;45 points points by bookofjoe on 2024-11-07T17:31:25 &lt;/p&gt;
&lt;p&gt;The website discusses a scientific study on a newly discovered cellular pathway that regulates memory consolidation in the brain. The study reveals a specific signaling mechanism involving the activation of a particular protein that plays a crucial role in the formation and retrieval of memories. Understanding this pathway could potentially lead to advancements in treating memory-related disorders and cognitive impairments.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;From this very cool paper:" In an ironic twist, this effectively realizes Richard Feynman’s analogy of the seemingly impossible task of ‘figuring out a pocket watch by smashing two together and observing the flying debris’. "&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The pre-print: https://arxiv.org/abs/2401.06625&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42078826</guid></item><item><title>21. Sustainable Web Interest Group Is Formed</title><link>https://news.ycombinator.com/item?id=42079758</link><description>
&lt;![CDATA[
&lt;p&gt;151 points points by agumonkey on 2024-11-07T19:05:11 &lt;/p&gt;
&lt;p&gt;The Sustainable Web Interest Group has been established by the World Wide Web Consortium (W3C) to address environmental concerns related to web technologies. The group will focus on promoting sustainability in web design and development, reducing the carbon footprint of internet technologies, and encouraging eco-friendly practices within the industry. They aim to develop guidelines, recommendations, and tools to help make the web more environmentally friendly and energy-efficient.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Everyone in the comments wants to blame JavaScript for the world’s ills. That is both stupid and grossly uninformed.When you live next to a Google or Facebook data center some reality starts to set in. They easily consume most of the output of a single small urban power plant on their own. It’s nuts. I didn’t realize how nuts it is until someone explained it to me, in my part time job I work with a Houston based power company lawyer that specializes in contracts for data centers. I doubt those massive data centers are reliant on JavaScript.As for JavaScript there is a simple solution that works wonders in every other industry: licensing and liability. The code is bad because the developers that write it are shit. That’s never going to change until businesses have a financial incentive to train for competence. All the wishful thinking about less JavaScript is just more virtue signaling.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It's a good effort, but a lot of this stuff reads more like the usual bureaucratic virtue-signaling that's popular these days. All that's needed to drastically decrease energy use is to just take late-90s/early 2000s web technology and push it to its limits. Zero JS unless absolutely necessary.Two days ago I was watching the election results on various sites, along with many others. Some sites just didn't work in a slightly older browser, and those which did were still consuming a lot more resources than they really needed. It shouldn't require the latest in web technologies and computing hardware to show a simple dynamically updating outline map.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Small bundle sizes are anti-Google/Facebook/et al. Google/Facebook needs to create standards to maintain control of the web and then incentivize implementation of those features in bundles. Chrome itself has a huge resource footprint, that often mirrors the common Ruby-ism about high resource usage.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42079758</guid></item><item><title>22. Hyperlight: Virtual machine-based security for functions at scale</title><link>https://news.ycombinator.com/item?id=42078476</link><description>
&lt;![CDATA[
&lt;p&gt;110 points points by yoshuaw on 2024-11-07T17:01:31 &lt;/p&gt;
&lt;p&gt;The website introduces HyperLight, a virtual machine-based security solution for functions at scale, enhancing security by isolating computing environments. It highlights the benefits of HyperLight in preventing sensitive data leakage and protecting servers from potential attacks. The tool leverages firewall policies, containment, and network filters to establish a secure environment for running functions efficiently and securely.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The Azure Upstream team has been working on a really fast hypervisor library written in Rust for the past three years. It does less than you'd conventionally do with hypervisors, but in turn it can start VMs around 2 orders of magnitude faster (around 1-2ms/VM).I think this is really cool, and the library was just released on GitHub for anyone to try. I’m happy I got to help them write their announcement post — and I figured this might be interesting for folks here!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; These micro VMs operate without a kernel or operating system, keeping overhead low. Instead, guests are built specifically for Hyperlight using the Hyperlight Guest library, which provides a controlled set of APIs that facilitate interaction between host and guestSounds like this is closer to a chroot/unikernel than a "micro VM" - a slightly more firewalled chroot without most of the os libs, or a unikernel without the kernel. Pretty sure it's not a "virtual machine" though.Only pointing this out because these sorts of containers/unikernels/vms exist on a spectrum, and each type carries its own strengths and limitations; calling this by the wrong name associates it with the wrong set of tradeoffs.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Don't see any mention of firecracker, which is the first thing I think of in this space. Anyone have a TL;DR comparison?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42078476</guid></item><item><title>23. Five minutes of exercise a day could lower blood pressure</title><link>https://news.ycombinator.com/item?id=42080747</link><description>
&lt;![CDATA[
&lt;p&gt;165 points points by geox on 2024-11-07T20:42:10 &lt;/p&gt;
&lt;p&gt;The article discusses a study that suggests just five minutes of exercise a day might help lower blood pressure. Researchers found that even short bursts of physical activity could have significant benefits on blood pressure levels. The study emphasized the importance of incorporating brief periods of exercise into daily routines for overall health and blood pressure management.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Tabata et al.[1] found in the mid-1990s that just 2-4 minutes of "high-intensity intermittent training may improve both anaerobic and aerobic energy supplying systems significantly." This was popularized as "Tabata training" 20+ years ago. I generally believe that brief bouts of exercise can be very beneficial, especially because they're easier to do consistently over the long-term vs. more time-consuming routines. For a decade now, I've just been running through my neighborhood most days for 20-30 minutes (with some sprints mixed in) and doing one or two maximal sets of pushups or pullups or barbell exercises at home on a weekly basis. I know a lot of people who got really into longer (e.g. 60-90 minute) gym routines but couldn't sustain it for more than a few months, and then stopped doing anything.[1] https://journals.lww.com/acsm-msse/Fulltext/1996/10000/Effec...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I have a neighbour who's in his 60s. Blood pressure was of the charts while in his 40s. The guy was cycling to work everyday (and thought that was enough exercise) and was living a stressful family and work life.Doctor never prescribed any drugs but told him that he had to start exercising. Signed up for judo class. He couldn't believe the amount of exercise he got from the warm up alone. Been doing judo 3 days a week for 20 years now. Haven't had any heart or blood pressure issues since.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;How much more evidence do we need, that exercise is good and any amount is better than none?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42080747</guid></item><item><title>24. The Brothers Grimm: A Biography</title><link>https://news.ycombinator.com/item?id=42074124</link><description>
&lt;![CDATA[
&lt;p&gt;53 points points by benbreen on 2024-11-07T06:46:37 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Some very nice writing here by author Anne Matthews. I especially liked her closing paragraph:A shy girl in London loved these stories once. So did a boy from South Africa, and one in Belfast, and another in California. When their own narratives flowered, Beatrix Potter, J. R. R. Tolkien, C. S. Lewis, and George Lucas knew whom to thank. Without the labors of Jacob and Wilhelm Grimm, there would be no Peter Rabbit, no Middle-earth, no Narnia, and definitely no Star Wars.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I've really been fascinated with how explicitly people set out to build nations in the 19th Century. I read Christopher Krebs' _A Most Dangerous Book: Tacitus's Germania from the Roman Empire to the Third Reich_ and it traces a different lineage in the same process- the process of turning someone who, say, lived in Mainz and thought of themselves as Hessian in 1800, into  the person who lived in the same building in 1900 and thought of themselves as German.In some ways, I've long suspected that there was a lot of freedom in that to build a culture ideally suited for the then present situation. "Fuenf minuten vor der Zeit, ist des Deutschen Puenktlichkeit" (1) in particular always struck me as something invented because it made the factories and the trains run better. It was first written down in 1880, attributed by a Silesia newspaper to Pomerania, and I really don't know that many people 100 years earlier, say, would have had a conception of what a "German" was in that sense. And before trains and factories, in an era when time is primarily told by the bells of the town clock tower and looking at the angle of the sun, no one would have had a real conception of what five minutes meant. So it couldn't really have been some ancient saying, carried down for hundreds of years. It had to be invented right around 1880.1: German "on time" is five minutes before it starts.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I wonder why the most important element of their political biography is not mentioned: they were among the Göttingen Seven.[1][1] https://en.wikipedia.org/wiki/G%C3%B6ttingen_Seven&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42074124</guid></item><item><title>25. Show HN: TutoriaLLM – AI Integrated programming tutorials</title><link>https://news.ycombinator.com/item?id=42072709</link><description>
&lt;![CDATA[
&lt;p&gt;109 points points by Soumame on 2024-11-07T02:32:44 &lt;/p&gt;
&lt;p&gt;The website repository provides tutorials and materials on various programming languages, tools, and technologies. Users can access resources such as sample code, instructions, and explanations to learn and improve their proficiency in coding. These tutorials cover a wide range of topics including web development, data structures, algorithms, and more, making it a valuable resource for individuals looking to enhance their programming skills.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;How do you run code in Bedrock? I don’t use computer games at all, but my son plays Minecraft a lot and is into programming. I investigated options for programming in Minecraft, there is Tinker, an app that lets you program in scratch, but it is not very usable, and there are Minecraft servers where you can program in Java, but the learning process is rather steep for that one and also it works only for Java Edition Minecraft, while most of my sons friends use Bedrock. Supposedly there is also Education Edition, but I have no idea how to install it - it seems that it is only available for schools.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I tried it out on my phone and was very impressed with how well it worked on mobile.  Cramped, but usable.I would love to see simple turtle graphics and canvas output modes. And maybe a retro style serial terminal with glowing text.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Best of luck! You'll probably get a better response here if the readme also has English. It's typically the first thing other software developers will look at in a project.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42072709</guid></item><item><title>26. The English Paradox: Four decades of life and language in Japan</title><link>https://news.ycombinator.com/item?id=42072647</link><description>
&lt;![CDATA[
&lt;p&gt;178 points points by pwim on 2024-11-07T02:24:38 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I'm Japanese.Speaking English in Japan is very challenging. All my friends and family speak Japanese, and everything from social media to news is completely accessible in Japanese.I'm an entrepreneur, and I use English when talking with international clients and overseas VCs. However, I lack confidence, and the communication tends to remain superficial, making it difficult to effectively do business internationally.
In this environment, it's hard to feel a real necessity to communicate in English.
Since elementary school, we've been told that being able to speak English is extremely important, and I studied hard. Yet in this environment, there are rarely opportunities to actually use English.When foreigners tell us about the importance of English, they may not fully understand that it doesn't really matter much to most Japanese people.
Japanese people might start speaking English when they truly need it.Rather than that, I'd be happier if AI could provide real-time translation for everything.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I only speak English, but I have found and theorized that one's ability to learn and retain a L2 is heavily affected by your society's "need" to communicate outside of the national language. This article largely reinforces that theory.If people do not have a need to learn another language, it becomes an uphill battle. People in Finland report higher levels of English competency than people in France (despite French being much closer to English than Finnish is) because there are so many fewer Finnish speakers. Finns wanting to experience warm beaches or global cities need to communicate when traveling to those places outside of Finland. France meanwhile has mountains, beaches, a big domestic market, ample media, and international reach.Japan is much more like France than Finland - the geographic diversity allows one to ski or sunbathe within the same country. The domestic market for goods and services is huge. Japan creates and exports so much culture that English speakers wish to learn Japanese to consume more of it. When there is little "need" to learn another language, it is not only less enticing but actually harder to do so.This culminates in anglophones being at a disadvantage in acquiring a L2 compared to nearly anyone else. A lot of people worldwide do want to practice their English with a native speaker. Many international institutions use English as the lingua franca. Even during a layover in Montreal, my (then) girlfriend ordered a smoothie in French and was replied to in English (this could be a commentary on Canadian bilingualism, but I'll leave that for another day) - it's hard for an anglophone to practice and perfect another language when the world around them already speaks better English than their L2.So considering Japan's strong domestic market, culture, and the stark differences between the languages, it was never a shock to me that their English proficiency isn't where one would immediately expect it. Thank you for sharing your thoughts and the deep experience behind them.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I've lived in Japan for over a decade and I think this article summarizes some aspects of English education well.  I'd like to share a few of my thoughts and experiences too.English is often put on a very high pedestal. Speaking fluent English is associated with being "elite".  A tech company in my city is slowly moving to doing all development work in English. I went to a casual tech talk event they held.  Every talk was given in Japanese and most of them started with a joke along the lines of "[In English] Hello everyone, good evening! [In Japanese] Hahah, of course I'm not going to give the whole talk in English"  It makes sense to give all the talks in Japanese to a Japanese speaking audience, but the whole vibe was that English was so impossible that the idea of giving a talk in English was absurd.Some of my friends have kids with mixed-roots.  They have grown up speaking English and Japanese. They sometimes modify their English pronunciation to sound "more Japanese" when they start English classes in school.  They don't want to stand out amongst their peers.I remember one kid, who was tri-lingual. He told a story about being called upon in English class to translate the Japanese word for "great-grandfather".  He translated it correctly but his teacher said "No, it's grand-grandfather". They teacher and the class laughed at him.  Of course, there are bad teachers everywhere but one wonders if the teacher would have tried to take him down a peg so much if he fit in a bit better. He ended up moving to Germany with his family. It makes me feel quite sad that a kid born and raised here can end up feeling more at home in a place he has no connection to.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42072647</guid></item><item><title>27. The evolutionary mystery of the German cockroach</title><link>https://news.ycombinator.com/item?id=42030615</link><description>
&lt;![CDATA[
&lt;p&gt;90 points points by softwaredoug on 2024-11-03T01:44:41 &lt;/p&gt;
&lt;p&gt;The website discusses the genetics and evolution of German cockroaches. It explores the mystery of how German cockroaches develop resistance to insecticides through genetic mutations and adaptation. The article highlights the resilience and rapid evolution of these pests in response to human attempts to control their populations.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;TL;DR. this imho is the interesting heart of the article:they proposed that when Asian cockroaches were transported along the trade routes from south and southwest Asia into Europe, this species could not establish persistent populations. Without local success, they were hardly noted by anybody. Only a few survivors that found ways to live within structures could make it through the cold European winters, and over time these survivors evolved into the German cockroach. The species was therefore truly European.went to work testing the hypothesis by sequencing genetic data from German cockroaches in many parts of the world, as well as Asian cockroaches and other relatives. Last month they published the results of this work. The new data showed something a little different from the urban Europe hypothesis.B. germanica didn't originate in Germany or elsewhere in Europe as a new species and later spread throughout other parts of the world. Island southeast Asia, Ethiopia, and China all had diversity of B. germanica that was as old as in Europe. Every one of these populations came from common ancestors that shared a history of drift and adaptation around 2100 years long. Before this, those ancestors diverged from the Asian cockroach, B. asahinai.The German cockroach deserves to be widely known as an example of rapid evolution of a new species. Not only does it inhabit environments where few insects survive, its environments didn't even exist before a few thousand years ago.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;How about house spiders? And all the garden spiders that come into our houses in the autumn? Note I am all in favour of spiders, particularly if they eat roaches!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;wonder when the origin of museum beetles will get figured out
as the name sugests,they are only found in museums,wiki is short and does not get into any historical mentionshttps://en.wikipedia.org/wiki/Museum_beetle&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42030615</guid></item><item><title>28. Gladiators in ancient Anatolia lived to entertain the masses</title><link>https://news.ycombinator.com/item?id=42048105</link><description>
&lt;![CDATA[
&lt;p&gt;71 points points by diodorus on 2024-11-05T02:33:03 &lt;/p&gt;
&lt;p&gt;The website delves into the history and significance of the ancient Olympic Games, highlighting the evolution of the games from ancient Greece to modern times. It discusses the cultural and athletic aspects of the Olympics, exploring the rituals, competitions, and impact of the games throughout history. The article sheds light on the archaeological discoveries related to the Olympics and their lasting legacy in the present day.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I would say they were dying to entertain the masses too.And then during the thrilling final act, it often came true.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; A pair of mounted gladiators featured in the initial spectacleAnyone have primary sources for this? Diodorus?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This looks like professional wrestling to me. Way to go, Anatolians!&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42048105</guid></item><item><title>29. One year, 41M digits: How Luke Durant found the largest known prime number</title><link>https://news.ycombinator.com/item?id=42069246</link><description>
&lt;![CDATA[
&lt;p&gt;59 points points by ortusdux on 2024-11-06T20:56:47 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;https://archive.ph/2XAbZ&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; The discovery was the result of almost exactly one year of work and about $2 million of Durant’s own money.&gt; Durant, who made his money off the boom, said he put his time and money into the project to show people that they aren’t helpless to technology giants and that we can figure out massive problems if we work together.If I sold absolutely everything I owned, I would not even have close to half of what it Durant invested in his pet project. While I like his intended sentiment, I can't help but notice the irony.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; Durant, who made his money off the boom, said he put his time and money into the project to show people that they aren’t helpless to technology giants and that we can figure out massive problems if we work together.I can appreciate the sentiment but&gt; The discovery was the result of almost exactly one year of work and about $2 million of Durant’s own money.doesn't really show me much especially since&gt; The prime number Durant discovered serves no real purpose for society.This sort of shows the opposite: if it takes $2M to discover something that doesn't have a real purpose, yeah I definitely feel a bit helpless against tech giants trying to do anything that is marginally useful.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42069246</guid></item><item><title>30. Even Microsoft Notepad is getting AI text editing now</title><link>https://news.ycombinator.com/item?id=42074083</link><description>
&lt;![CDATA[
&lt;p&gt;247 points points by redbell on 2024-11-07T06:40:21 &lt;/p&gt;
&lt;p&gt;"Microsoft is rolling out AI-powered features in Notepad to help users write and edit text more efficiently. The new capabilities include automatic text rewriting suggestions and improved word predictions to enhance the editing process. By leveraging machine learning, Microsoft aims to assist users in creating clearer and more concise written content within the Notepad app."&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;So, they went from not updating in forever, to finally updating it in some meaningful ways a couple years ago, to adding crap that no one wants pretty much right away. Too much, MS. Shoulda quit while you were ahead with tabs.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;A while ago I wrote about my experience using Windows for work after 10 years of being a Linux-only user [1]. One of the positive notes I had was:&gt; As a positive note, the default text editor Notepad is nice and lightweight, a good piece of software.Unfortunately, they screwed it up with Windows 11. And apparently they are doubling down on this.[1] https://sebastiano.tronto.net/blog/2023-01-28-windows-deskto...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; It’s worth noting that you’ll have to sign in to your Microsoft account to use Rewrite, as it’s “powered by a cloud-based service that requires authentication and authorization.”They are truly data leeches trying to lap at any cut you might have for a bit of tasty data.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42074083</guid></item><item><title>1. Multiple new macOS sandbox escape vulnerabilities</title><link>https://news.ycombinator.com/item?id=42084588</link><description>
&lt;![CDATA[
&lt;p&gt;519 points points by transpute on 2024-11-08T06:10:14 &lt;/p&gt;
&lt;p&gt;The website provides a comprehensive analysis of macOS sandbox escapes, focusing on vulnerabilities and exploits in recent versions of macOS. Specific attention is given to new techniques and strategies used by researchers to bypass macOS security measures, highlighting the potential risks and implications of these escapes in the context of cybersecurity. Detailed technical information, exploit code, and mitigation recommendations are also included, making it a valuable resource for security professionals and researchers.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;It's a bit odd that the response here is to patch every single XPC service individually. This feels like some kind of design issue in the sandbox itself. Why are so many XPC services that are clearly intended to be app private reachable from sandboxed apps?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;MacOS should really have some kind of capabilities based Darwin containers, rather than what seems like a giant tangle of blacklists.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;MacOS (ie NeXTstep) was built from the ground up to be an open and extremely extensible OS.There were countless ways to add in some 3rd party extension or hook. Since there were multiple runtimes to access your software, it was actually an impressive technical feat at the time to have it all work together seamlessly.Java, classic Mac, X11, and the NeXTstep codebases all ran together without issue due to several of the kernel's extensible entry-points.On top of that, the platform had APIs that let apps talk to each other without issue.However, little by little, Apple has backtracked on that philosophy and continues to close the system down. Quite a fascinating journey.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:46:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42084588</guid></item><item><title>2. LoRA vs. Full Fine-Tuning: An Illusion of Equivalence</title><link>https://news.ycombinator.com/item?id=42085665</link><description>
&lt;![CDATA[
&lt;p&gt;215 points points by timbilt on 2024-11-08T09:58:24 &lt;/p&gt;
&lt;p&gt;The website discusses a research paper titled "Adversarial Attacks for Handwriting Recognition Systems." The paper explores how machine learning models utilized in handwriting recognition systems can be vulnerable to adversarial attacks, leading to incorrect predictions. The study examines different attack strategies and their impact on the performance of the recognition systems, showcasing the need for improved robustness in such models to defend against adversarial manipulation.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This tracks with my feelings making and using Stable Diffusion Loras and fine tunes. Still, with the speed to train and use, Loras have worked for me in most use cases and it hasn't been worth fine tuning the entire model.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; We randomly initialize A such that it has singular values of 1, freeze it, and only train B. When we do this, we see a sharp reduction in high ranking intruder dimensions in comparison to those in normal LoRAThis sounds interesting, but I can't see that they do much with this result. Are they saving it for a follow up paper? I would think that if their whole paper is about a big problem with LoRAs and they then find what looks like an easy solution for that problem that would warrant more than a paragraph just before the conclusion.It would also have been interesting if they included the DoRA method, they reference it briefly and that paper claims to resemble fine tuning learning behavior.But perhaps this paper is focused on LoRA behavior, and a separate paper comparing various improvements is better.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;So, in layman’s terms, LoRa appears to “traumatize “ the model to some degree, connecting the vector space with strong “jumpers” (intruder dimensions)  to change it’s behavior, instead of subtly conforming the entire model into a shape that accommodates the new data.These jumpers or shortcuts do create connections between the relevant new concepts in the model, but by directly connecting them instead of associating them through the existing network of concepts, nuance is lost and the bypassed areas become deemphasized, leading to forgetting of previously held  associations.Because of this, In general, fine tuning produces better results than LoRa in most cases, especially when forgetting of existing training is detrimental.Or, to further oversimplify the issue in SE terms, LoRa == monkeypatching.  (Is this a kind of intruder dimension?)&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42085665</guid></item><item><title>3. Stabilizing the Obra Dinn 1-bit dithering process (2017)</title><link>https://news.ycombinator.com/item?id=42084080</link><description>
&lt;![CDATA[
&lt;p&gt;460 points points by CharlesW on 2024-11-08T04:15:59 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Having worked on graphics programming for more than a decade, I still didn't pick on that when I played the game. Considering the overall visual language of the game, I'd say it's 100 hours well spent.Could have easily published this at SIGGRAPH under temporal coherence for non-photorealistic rendering.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;For people who are unaware "Return of the Obra Dinn" and "Papers, Please" are both games by Lucas Pope and they are both considered absolute classics and have won multiple awards. Well worth checking out even if you don't consider yourself a typical game-enjoyer. They are not typical games.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Harsh 1-bit dithering is such an interesting topic - even in 2d there are multiple ways of doing it, each with trade-offs and advantages.It is amazing to me that something that was so integral to the 80s computing experience is now actually quite tricky on modern hardware. For my own project[0] I found that it is almost impossible to ensure a one-to-one mapping between offscreen pixels and the canvas provided by the browser.[0] https://sheep.horse/2023/1/improved_web_component_for_pixel-...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42084080</guid></item><item><title>4. Mitochondria Are Alive</title><link>https://news.ycombinator.com/item?id=42088758</link><description>
&lt;![CDATA[
&lt;p&gt;519 points points by mailyk on 2024-11-08T17:39:43 &lt;/p&gt;
&lt;p&gt;The website discusses the role of mitochondria, often referred to as the powerhouse of the cell, in producing energy through the process of oxidative phosphorylation. It explains the structure of mitochondria, their evolutionary origins, and their significance in various aspects of biology, including cell metabolism, aging, and disease. The article emphasizes the importance of mitochondria in sustaining life and the impact of mitochondrial dysfunction on overall health and well-being.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This article is framed as if there is something novel and profound here, but the "aliveness" of mitochondria is simply a matter of how we choose to apply the label "life" - a human linguistic construct that exists independently of the biological phenomena. This is not a new discussion - science has been considering this question for many decades, just as it has with viruses. These all come down to arguments about semantics and don't add anything to the science.Mitochondria are fascinating and there is still a huge amount to learn about them but they are totally dependent on the cell's machinery. Most of their genes, the code for their structure, are in the nuclear DNA. A glaring omission if you are trying to make the case that mitochondria are independently living. My heart can exist independently of me, and be transplanted into other people, but does it mean that it is alive?The implication of the whole article is that there something we have missed. This really isn't the case. Lynn Margulis's endosymbiotic origin of mitochondria was challenged by many, and it did spark a scientific debate - that's how science works. She won the argument comprehensively decades ago and is well established science. There have been many such endosymbiotic events in the history of life - there are subfields of evolutionary biology that study these processes.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Mitochondria are why I’m a Rare Earther.In Earth’s history, mitochondrial endosymbiosis occurred once. Without that you don’t have the energy budget for complex life. Moreover, there may be a narrow window where it can happen: modern microbiology has defences and selection pressures that it make inhospitable to the hobbling chimeræ the first mitochondrial cells would have been.Until mitochondria, the emergence of life from nothing is plausible. With mitochondria, its progression to complex, multicellular and intelligent life makes sense. Both processes in small steps can be replicated, more or less, in the lab. But that one moment is not and has not been. As a result, I think the universe has lots of living slop but very few plants and animals.(Aside, look at ATP go: https://www.youtube.com/watch?v=lUrEewYLIQg&amp;t=939s)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This article managed to hit two classic science journalism cliches in just the first few paragraphs.(1) “Someone hypothesizing a very dramatic theory with weak evidence was considered wrong by most colleagues but later vindicated when strong evidence emerged”. (No mention of thousands of other dramatic hypotheses that turned out wrong.)(2) “You may have heard in unsophisticated popularization that [philosophical claim ultimately hinging on semantic distinction] was false, but really it’s true [assuming my preferred semantics]”.Aren't we all tired of this yet? Aren’t science journalists embarrassed by this stuff?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42088758</guid></item><item><title>5. Claude Shannon: Mathematician, engineer, genius and juggler (2017)</title><link>https://news.ycombinator.com/item?id=42034305</link><description>
&lt;![CDATA[
&lt;p&gt;155 points points by xiande04 on 2024-11-03T17:09:42 &lt;/p&gt;
&lt;p&gt;The website discusses the unique talent and contributions of Claude Shannon, a mathematician, engineer, and skilled juggler. Shannon, known as the "father of information theory," was a brilliant mind who not only made significant advancements in science and technology but also excelled in juggling, showcasing his multi-faceted abilities. The article explores Shannon's passion for juggling and how it intersected with his mathematical and engineering pursuits, highlighting his innovative and creative approach to both disciplines.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Some more fun facts about Claude Shannon, from this New Yorker article (https://www.newyorker.com/tech/annals-of-technology/claude-s...):He built a flame-throwing trumpet and a rocket-powered Frisbee. He built a chess-playing automaton that, after its opponent moved, made witty remarks. Inspired by the late artificial-intelligence pioneer Marvin Minsky, he designed what was dubbed the Ultimate Machine: flick the switch to “On” and a box opens up; out comes a mechanical hand, which flicks the switch back to “Off” and retreats inside the box.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Highly recommend giving The Bit Player[0] a watch for those interested in learning more about Claude Shannon and their pursuits in both their academic and personal life.[0] https://thebitplayer.com/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Kind of off-topic, but one thing that really confuses me about Shannon's biography is the following: according to the authors of "A Mind at Play", Shannon was diagnosed with Alzheimer's disease in 1983 [0], and the illness progressed "very quickly". They continue:&gt; In too-brief moments, the family was given a flash of the Claude they knew. [His daughter] Peggy remembered that she “actually had a conversation with him in 1992 about graduate school programs and what problems I might pursue. And I remember being just amazed how he could cut to the core of the questions I was thinking about, I was like, ‘Wow, even in his compromised state he still has that ability.’”So in 1992, an actual meaningful conversation with him seemed to be unexpected, and after 9 years of "quickly progressing" Alzheimer's, I would expect him to be in really terribly shape and barely coherent. Yet there is an article about him from 1992 [1], which shows him at age 75, in good shape, still able to juggle and to hold a conversation about his achievements and about information theory:&gt; “My first thinking about [information theory]," Shannon said, “was how you best improve information transmission over a noisy channel. This was a specific problem, where you're thinking about a telegraph system or a telephone system. But when you get to thinking about that, you begin to generalize in your head about all these broader applications."[0] https://www.quora.com/How-did-Claude-Shannon-come-to-terms-w...[1] https://spectrum.ieee.org/claude-shannon-tinkerer-prankster-...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42034305</guid></item><item><title>6. Show HN: Asterogue, my sci-fi roguelike, is now playable on the web</title><link>https://news.ycombinator.com/item?id=42085036</link><description>
&lt;![CDATA[
&lt;p&gt;284 points points by chr15m on 2024-11-08T07:43:02 &lt;/p&gt;
&lt;p&gt;Asterogue is a lifestyle brand that focuses on providing advice and resources for living a well-rounded life. Their articles cover a range of topics including wellness, beauty, travel, and self-improvement. The website aims to inspire and educate readers on how to enhance their overall well-being and cultivate a sense of balance in their daily lives.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Asterogue is a "juicy" graphical coffeebreak roguelike I made that is pretty much directly inspired by the original Rogue in terms of scope and features. You descend 17 levels into the heart of an asteroid to find The Orb and save the universe. There are a bunch of different monsters which get progressively harder as you descend. Instead of magic there is technology and you can pick up nanotech items and beakers of chemicals to buff your character (or hurt them if you get unlucky).I built Asterogue over the course of a couple of months while I was bored on a break from work due to illness. The game was always built with web tech but I only released it on Android and Windows at first because that seemed to be the right way to release a game. Well I recently realized maybe the right way is the wrong way. Maybe this web thing really is catching on. So now I'm trying out a web release to see if I can make it easier for more people to play Asterogue. So far this is working well and the game is getting more daily players than it ever did as a native app, which I'm very grateful for!For the web based version I am trying a new payment model. The original Asterogue was like most other games in that you simply buy it in the app store or on Itch and download the game. This time around I am trying a new experiment with this and instead of buying a downloadable binary, you can play the first few levels free in your browser and then you pay one-time to unlock the full game online if you want to continue. I think this strikes a nice balance for players as you get to try it out and only continue if you're actually into the game once you have picked up the vibe. I haven't really seen this done before with web based games so it's all a bit of an experiment.This release also includes a bunch of fixes and new features based on feedback I received from players after the native version was release.Anyway, I hope you enjoy my little roguelike game. Have fun!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;On the subject of scifi roguelikes, I've sunk 700+ hours into Jupiter Hell.  I've been playing roguelikes since the original Rogue in the 80s and I think JH is the GOAT: skill tree that rewards experimentation, learning curve that never feels unfair, and that "just one more level" itch propelling you forward.  Add in a fresh take on ranged combat mechanics, a strip-it-to-essentials design (a winning run takes me ~3h on Ultraviolence), and a legitimately good custom 3D engine, and you have something that I think will be recognized as a classic for years.https://store.steampowered.com/app/811320/Jupiter_Hell/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Chris is also the developer behind rogule[0], a daily roguelike dungeon in a similar style as wordle or tradle type games.Absolutely been enjoying it the past year.[0]: https://rogule.com/game.html&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42085036</guid></item><item><title>7. Perceptually lossless (talking head) video compression at 22kbit/s</title><link>https://news.ycombinator.com/item?id=42084977</link><description>
&lt;![CDATA[
&lt;p&gt;207 points points by skandium on 2024-11-08T07:30:31 &lt;/p&gt;
&lt;p&gt;The website discusses live portrait compression, focusing on computationally efficient methods. It explores the challenges of real-time image compression for live video streaming and offers insights into optimizing compression algorithms. The article emphasizes the importance of maintaining image quality while achieving high compression rates and discusses various techniques and considerations for improving live portrait compression performance.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This reminds me of a scene in "A Fire Upon the Deep" (1992) where they're on a video call with someone on another spaceship; but something seems a bit "off".  Then someone notices that the actual bitrate they're getting from the other vessel is tiny -- far lower than they should be getting given the conditions -- and so most of what they're seeing on their own screens isn't actual video feed, but their local computer's reconstruction.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;These sorts of models pop here quite a bit, and they ignore fundamental facts of video codecs (video specific lossy compression technologies).Traditional codecs have always focused on trade offs among encode complexity, decode complexity, and latency. Where complexity = compute. If every target device ran a 4090 at full power, we could go far below 22kbps with a traditional codec techniques for content like this. 22kbps isn't particularly impressive given these compute constraints.This is my field, and trust me we (MPEG committees, AOM) look at "AI" based models, including GANs constantly. They don't yet look promising compared to traditional methods.Oh and benchmarking against a video compression standard that's over twenty years old isn't doing a lot either for the plausibility of these methods.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Bit off putting that it's Musk for some reason, maybe it's just overexposure to his bullshit, I could quite happily never see him again.Maybe there is a custom web filter in there somewhere that could block particular people and images of them.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:47:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42084977</guid></item><item><title>8. Λ-2D: An Exploration of Drawing as Programming Language</title><link>https://news.ycombinator.com/item?id=42085273</link><description>
&lt;![CDATA[
&lt;p&gt;203 points points by threeme3 on 2024-11-08T08:30:54 &lt;/p&gt;
&lt;p&gt;The website focuses on a project exploring drawing as a programming language by incorporating concepts from lambda calculus. It discusses how drawing shapes and lines can be represented through programming principles, providing visual and interactive examples to demonstrate the intersection of art and math in creating digital designs.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;If you like this, you may find automation project engineer work fun... or at least familiar. Function block diagrams are quite like this: There function blocks are connected together with wires, and the order of operations is defined by block order. Blocks themselves are like builtin functions in the engine, or they can also be composites. The diagram is executed once per control cycle and generally (if no jump blocks exist), each block is always executed exactly once per control cycle regardless of if their inputs have changed or not.And that is how control logic for anything from breweries to petrochemical plants is implemented! Fun stuff! I happen to work on the UI side of an FBD-based control system, so I float around this stuff day-to-day.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Ugh.... similar to BitGrid[1] (my own hobby horse), but not.  I imagine bits marching in parallel across a grid in the ultimate simplification of an FPGA. It's an idea that either has supreme utility (Petaflops for the masses), or doesn't... it's all down to how much energy a DFF takes on an ASIC. (This is a pair of numbers I've been trying to find forever... static power, and energy to load a bit)Oh... and the programming model, nobody likes plopping logic down on a grid, they try to abstract it away as fast as possible. I don't have sufficient focus to be able to do that bit.[edit] Somewhere in exploring this, I came across Von Neumann cellular automaton[2] and Nobili cellular automata[3], which I've not encountered, despite being interested similar ideas for decades. It's frustrating just how little discoverability there is in this portion of computer science.Of course both share the same insane foundation:  The set of FSAs define a cell space of infinite size. All FSAs are identical in terms of state-transition function, or rule-set.

It's that one "simplification" that relegates them to the domain of code golf.[1] https://github.com/mikewarot/Bitgrid[2] https://en.wikipedia.org/wiki/Von_Neumann_cellular_automaton[3] https://en.wikipedia.org/wiki/Nobili_cellular_automatapps: If anyone wants to run with the idea of a BitGrid, I'd appreciate it&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&gt; Technically the language is Turing complete at this point, but will be excruciatingly laborious to use, violating my design rule #2.I stopped at step #1 with my Lambda Diagrams [1]. The bottom of that page links to all other graphical lambda calculus notations I know of (just added this one).[1] https://tromp.github.io/cl/diagrams.html&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42085273</guid></item><item><title>9. FDA proposes ending use of oral phenylephrine as OTC nasal decongestant</title><link>https://news.ycombinator.com/item?id=42082998</link><description>
&lt;![CDATA[
&lt;p&gt;271 points points by impish9208 on 2024-11-08T00:56:49 &lt;/p&gt;
&lt;p&gt;The FDA is proposing to eliminate the use of oral phenylephrine as an over-the-counter nasal decongestant due to concerns about its effectiveness and safety. The agency aims to remove this active ingredient from OTC monograph products as studies have shown it may not provide significant benefits for congestion relief when taken orally. The proposal opens up an opportunity for public comment and consumer feedback to inform the final decision on the use of phenylephrine in OTC medications.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Context for readers from countries where this isn't an issue, or anyone who hasn't followed decongestant news: one of the most effective decongestants is called pseudoephedrine.https://en.wikipedia.org/wiki/PseudoephedrineIn the past this was easily available, with the most popular brand being Sudafed. My parents always told me that one should take Sudafed when flying after having had a cold, in order to avoid severe ear pain from the pressure changes, but people would also obviously take it when not flying, just in order to reduce the discomfort of the congestion itself.Pseudoephedrine is very effective. It is also used to synthesize the somewhat related illegal drug methamphetamine ("meth"). Historically, meth manufacturers would hire people to buy large amounts of pseudoephedrine pills at pharmacies and supermarkets, then grind them up and synthesize meth from them.In order to deter this, authorities in the U.S. restricted the availability of pseudoephedrine, while not making it prescription-only, by limiting the amount that people could buy, and requiring buyers to show ID and be put on a registry (which law enforcement could use in investigations). I think this is the only drug that is treated this way. Some people stopped buying pseudoephedrine entirely, either because they were offended by these rules or because they were afraid that they could wrongly be implicated in meth investigations if they appeared to buy it too often.The pharmaceutical industry produced an alternative called phenylephrine, the substance that this proceeding relates to. Most manufacturers of pseudoephedrine-based drugs, including Sudafed, formulated alternative decongestants using phenylephrine. There are no legal restrictions on phenylephrine drugs; one can buy them anonymously and in any quantity. Customers have complained for years that these are much less effective than the original formulations.A couple of years ago this regulatory authority started looking into the question of whether phenylephrine is actually completely useless as a decongestant (rather than just much worse than pseudoephedrine). Their preliminary review of studies suggested that it is probably, in fact, useless. This proceeding is now proposing to ban it on the grounds that it's ineffective and so people should not be encouraged to buy and use it as a medicine for purposes for which it doesn't actually work.(There doesn't seem to be much corresponding initiative to remove or reduce the restrictions on pseudoephedrine.)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;One of my favorite papers is "A simple and convenient synthesis of pseudoephedrine from N-methylamphetamine" [1].This is a satirical paper. Because pseudoephedrine (i.e. the good decongestant) is very difficult to obtain due to restrictions, but "N-methylamphetamine can be procured at almost any time on short notice", the paper describes how to synthesize pseudoephedrine from meth with a procedure that looks valid.[1] https://improbable.com/airchives/paperair/volume19/v19i3/Pse...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I remember complaining to my friends about how frustrating it was to hear that a medicine I frequently used turned out to be placebo, exactly one year ago today. Opened this article up, I'm currently taking the _exact same_ one in the article photo - it's what I had lying around and I had forgotten the name of the "bad" sudafed (it's sudafed PE). They need to take it off the shelves quicker. Every day is tens of thousands of more people who are scammed.Putting my money where my mouth is and leaving a comment on the FDA proposal...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42082998</guid></item><item><title>10. In Memory of Stiver</title><link>https://news.ycombinator.com/item?id=42039184</link><description>
&lt;![CDATA[
&lt;p&gt;381 points points by thunderbong on 2024-11-04T06:56:23 &lt;/p&gt;
&lt;p&gt;The website pays tribute to a JetBrains employee named Stiver, who passed away. It highlights his contributions to the IntelliJ IDEA project and his impact on the community. The article reflects on his technical expertise, mentoring skills, and personal qualities that made him a valued team member. Colleagues reminisce about their memories of working with Stiver and express their condolences. The post serves as a heartfelt homage to a beloved colleague.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Fernflower is one of the few really powerful java decompilers out there that had good support for the bad bytecode that dex2jar would produce.I've spent many hours pouring through the output of Fernflower looking for what some obfuscation algorithm has come up with.Dogspeed, Stiver. Your work, "legitimate" or not, has benefitted the world. o7&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Didn't know about that side of his talent. Among broader Russian audience Stiver was known as a maintainer of the largest pirate library in Russian (see https://news.ycombinator.com/item?id=41634780).&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Back in the day, I had to deal with some poorly documented closed source Java applications (e.g. IBM WebSphere). Tools like Fernflower and its precursors were invaluable to fill the gaps.Thank you, Stiver, and R.I.P.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039184</guid></item><item><title>11. Show HN: Draw.Audio – A musical sketchpad using the Web Audio API</title><link>https://news.ycombinator.com/item?id=42080377</link><description>
&lt;![CDATA[
&lt;p&gt;232 points points by StreamGobbler on 2024-11-07T20:06:39 &lt;/p&gt;
&lt;p&gt;The website draw.audio allows users to create musical compositions by drawing on a digital canvas. Users can draw shapes, lines, and patterns which are then translated into unique sounds and melodies, providing an interactive and creative way to make music.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Hello HN community!Out of my love for synthesizers and web development, I created a free audio sequencer called draw.audio, which includes selectable scales, waveforms, effects, LFOs, and more.While there are other “tone matrix” style webapps out there, I couldn’t find one that quite scratched the itch for a large grid layout, modern design, and easily accessible modulation controls. So that was the inspiration, alongside my addiction to synths and hardware jam-boxes like the Synthstrom Deluge.Draw.audio uses the Web Audio API without any other frameworks or libraries. I tried to keep it as lightweight as possible. The to-do list includes a tutorial, pattern preset browsing, more audio effects, light visual animations, and open-sourcing it.In case you'd like tips:
• It’s more fun on touch screens, like an iPad.
• It's kid friendly! In my limited testing, kids enjoy drawing on it.
• The share button generates a direct link to anything you create.A big thank you to Sheer Havoc for creating the logo and other graphics!And thank you all for checking it out! I’d love to hear any feedback you have. &lt;3-Randy (long-time lurker, first time poster, and HN fan from SF)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Nice. This made me think of Conway's Game of Life so I made a little mashup of a tone matrix with GoL. https://matthewbilyeu.com/tone-of-life.html&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Love it! Related fun toy:
http://roland50.studio/&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42080377</guid></item><item><title>12. Rust for tokenising and parsing</title><link>https://news.ycombinator.com/item?id=42083547</link><description>
&lt;![CDATA[
&lt;p&gt;275 points points by thunderbong on 2024-11-08T02:35:26 &lt;/p&gt;
&lt;p&gt;The website discusses the use of Rust programming language for personal development, emphasizing its benefits in improving coding skills, problem-solving abilities, and overall learning experience. It highlights the advantages of Rust's safety features, performance optimizations, and supportive community for self-improvement and tackling programming challenges. The article shares insights into resources and strategies for utilizing Rust effectively for personal growth and skill enhancement.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;About 2 months ago I would have said the same as the author, but I kept running against the hard edges of Rust: the borrow checker. I realised that while I really liked using algebraic data types (e.g. Enums) and pattern matching, the borrow checker and the low level memory concerns meant I spent a lot of time fighting the borrow checker instead of fighting the PL issues at the heart of my project. So while tokenising/parsing was nice, interpreting and typechecking became the bane of my existenceWith that realisation I started looking for another more suitable language - I knew the FP aspects of Rust are what I was looking for so at first I considered something like F# but I didn't like that it's tied to microsoft/.NET. Looking a bit further I could have gone with something like Zig/C but then I lose the FP niceness I'm looking for. I also spent a fair amount of time looking at Go, but eventually decided that 1. I wanted a fair amount of syntax sugar, and 2. golang is a server side language, a lot of its features and library are geared towards this use case.Finally I found OCaml, what really convinced me was seeing the syntax was like a friendly version of Haskell, or like Rust without lifetimes. In fact the first Rust compiler was written in OCaml, and OCaml is well known in the programming language space. I'm still learning OCaml so I'm not sure I can give a fair review yet, but so far it's exactly what I was looking for.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This is, to me, an odd way to approach parsing. I get the impression the author is relatively inexperienced with Rust and the PL ideas it builds on.A few notes:* The AST would, I believe, be much simpler defined as an algebraic data types. It's not like the sqlite grammar is going to randomly grow new nodes that requires the extensibility their convoluted encoding requires. The encoding they uses looks like what someone familiar with OO, but not algebraic data types, would come up with.* "Macros work different in most languages. However they are used for mostly the same reasons: code deduplication and less repetition." That could be said for any abstraction mechanism. E.g. functions. The defining features of macros is they run at compile-time.* The work on parser combinators would be a good place to start to see how to structure parsing in a clean way.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I don't know. Having written a small parser [0] for Forsyth-Edwards chess notation [1] Haskell takes the cake here in terms of simplicity and legibility; it reads almost as clearly as BNF, and there is very little technical ceremony involved, letting you focus on the actual grammar of whatever it is you are trying to parse.[0] https://github.com/ryandv/chesskell/blob/master/src/Chess/Fa...[1] https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notati...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42083547</guid></item><item><title>13. Practical Radio Circuits (2003) [pdf]</title><link>https://news.ycombinator.com/item?id=42024680</link><description>
&lt;![CDATA[
&lt;p&gt;153 points points by _Microft on 2024-11-02T07:34:28 &lt;/p&gt;
&lt;p&gt;The website contains a document titled "Practical Radio Circuits" by Raymond Haigh, which provides detailed information and diagrams on building various radio circuits. The document covers topics such as oscillators, amplifiers, mixers, detectors, and filters, offering practical guidance for constructing radio circuits for communication purposes.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;A friend and I have been trying to build an AM radio. We got a few working, like the basic "crystal" (germanium diode) one with an earpiece, generally picking up 1 or 2 stations very faintly. Then some attempts with an AM radio IC (TA7642), some that use a couple diodes and LM386 op-amp but they're generally terrible, if they work at all. It seems that following random schematics off the web or a youtube screenshot doesn't work very well.I do have an RF design book I haven't started (by Chris Bowick) as well as this PDF now, which should be even more practical, so I'm hopeful I can figure it out. I also have some test equipment such as nanoVNA, tinySA, and an oscilloscope which makes it possible to get visibility into how stuff behave beyond "I don't hear anything; no idea what's wrong." I was able to see how the tank circuit was behaving as you tune it.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;You can pick up a pretty reasonable amount of radio signal with the right length of wire and a properly tuned LC circuit tank.I didn’t believe it until I tried it, but it’s a surprisingly good first pass at an FM frontend.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Some thoughts - this is a good overview of how stagnant the hobbyist state of the art was 20 years ago. You could probably have built all of these circuits with the those exact parts in 1973. Pretty much everything in this collection but the superhet and direct-conversion receivers is obsolete and was at best obsolescent at the time. You can think of a typical SDR as a dual-conversion receiver with a conversion stage in the digital domain.  Superregens were used in remote controls right up through the turn of the century, but by the time this was written no one was designing new ones.  I saw a TRF front end on a commercial ultrasound device in that era but it was not typical.Many RF transistors are no longer available in through-hole though you can probably find small quantities for hobby projects.  The msph10 is long gone.  And good luck sourcing dual-gate mosfets even in smt.  Infineon might still make a couple.As a digression, it does make me think TRF receivers are probably a better learning tool than the my-second-radio regenerative receiver.  Crystal radios, of course, are pure magic and it’s sad that so few people get to build them as kids.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:48:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42024680</guid></item><item><title>14. Making Electronic Calipers</title><link>https://news.ycombinator.com/item?id=42087560</link><description>
&lt;![CDATA[
&lt;p&gt;127 points points by surprisetalk on 2024-11-08T15:29:27 &lt;/p&gt;
&lt;p&gt;The website provides a tool called Calipertron for transforming and preprocessing machine learning models' prediction probabilities. Calipertron assists in applying monotonic calibrations or monotonic transformations to ensure the predictive fairness and reliability of the model's output. The tool supports various transformations and enables users to visualize the impact of these changes on the model's predictions, allowing for enhanced interpretability and performance evaluation of machine learning models.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Author here. Lots of questions about precision --- in the article I calculated 0.6mm as the standard deviation of 200ms worth of phase measurements (n=124) while the slide wasn't moving.I'd love to hear any advice/ideas re:- approaches for figuring out what's currently limiting the accuracy (i.e., noise sources)- the relative merits of averaging in time vs phase domain- how to improve the analog frontend (See my collaborator Mitko's github repo for the hardware schematics: https://github.com/MitkoDyakov/Calipatron/blob/main/Hardware...)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I don't actually see an accuracy number, only the claim of "millimeter precision", which is actually pretty bad for calipers. Looks like a fun project though. Basically a linear resolver sensor I guess. From how much effort the author has put into the project I'd estimate the accuracy is much better than +/- 0.5mm.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Be sure to watch Big Clive's video that's linked in the article. It's amazing how cheap digital calipers have gotten, and how accurate they are at that price. They probably use a 4-bit MCU or an ASIC to do the calculations and output the data --- both to the screen, and an often-hidden serial port. The use of a non-absolute encoding leading to drift, and the higher standby power consumption which was distinctive of the infamous battery-eating Mitutoyo clones, seems to have been largely solved within the past few years. There are even solar models available for not much more.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42087560</guid></item><item><title>15. Python Logic Simulation Library</title><link>https://news.ycombinator.com/item?id=42041355</link><description>
&lt;![CDATA[
&lt;p&gt;71 points points by mediisoccuspupa on 2024-11-04T13:30:57 &lt;/p&gt;
&lt;p&gt;The website provides a tool called SeqLogic, designed for sequence analysis in biological data. SeqLogic enables users to define complex relationships between sequences using a logic-based formalism, aiding in the identification of patterns and structures within biological sequences. This tool allows for the creation of custom rules to be applied to sequence data to extract meaningful information and discover patterns that may not be evident through standard analysis methods.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;These experiments are always unique, and each is interesting in its own way.Can you comment on the use of asynchronous code rather than generators? For example, here's a throw-away example of a clock using generators and a syntax that's otherwise similar to yours:  from more_itertools import take
  
  def drv_clock():
      while True:
          yield "1b1"
          yield "1b0"
  
  for x in take(10, drv_clock()):
      print(x)

I have written signal flow graphs (including feedback) using a generator-style approach, intended to prototype datapaths that are then manually translated into RTL. It's different, but not completely different.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42041355</guid></item><item><title>16. After decades, FDA moves to pull ineffective decongestant off shelves</title><link>https://news.ycombinator.com/item?id=42083559</link><description>
&lt;![CDATA[
&lt;p&gt;299 points points by coloneltcb on 2024-11-08T02:37:02 &lt;/p&gt;
&lt;p&gt;The FDA is proposing to remove oxymetazoline, a common decongestant found in products like Afrin, due to being ineffective and potentially harmful. The agency highlights that extended use could lead to rebound congestion, making the condition worse. Studies have shown limited efficacy in treating nasal congestion, and the FDA advises seeking alternative solutions like saline sprays for relief.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Previously (with direct link to the FDA ruling): https://news.ycombinator.com/item?id=42082998&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;[dupe]Official release:https://news.ycombinator.com/item?id=42082998&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42083559</guid></item><item><title>17. The evolution of nepotism in academia, 1088-1800</title><link>https://news.ycombinator.com/item?id=42017730</link><description>
&lt;![CDATA[
&lt;p&gt;82 points points by surprisetalk on 2024-11-01T15:16:57 &lt;/p&gt;
&lt;p&gt;The website discusses research on the impact of capital taxation on economic growth using a dynamic general equilibrium model. It examines different tax structures and their effects on the saving rate, capital intensity, and labor productivity within the economy. The study finds that capital taxation can have significant implications for long-term growth, suggesting that lower capital taxes may lead to increased investment and ultimately foster economic development.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&gt;”human capital was strongly transmitted from parents to children”That doesn’t sound distasteful to me at all. Is that bad?Can we make a distinction between parents raising their kids and giving them great opportunities, and “nepotism” where people are put in no-show jobs or are wholly incompetent?It seems like the system of “nepotism” the paper describes is not bad at all, but instead is working well since the paper observes that when passing occupation from father to son would be inefficient/lead to bad social outcomes, it happens far less&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Here's an interesting extract:&gt; We find evidence of nepotism for 5–6.6% of scholars’ sons in Protestant and for 29.4% in Catholic universities and academies. Catholic institutions relied more heavily on intra-family human capital transfers. We show that these differences partly explain the divergent path of Catholic and Protestant universities after the Reformation.This relates to an important paper providing evidence that indeed Protestantism was associated with scientific progress: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389708&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;A very related article:https://link.springer.com/article/10.1007/s11192-024-04936-1&gt;Nobel laureates cluster together. 696 of the 727 winners of the Nobel Prize in physics, chemistry, medicine, and economics belong to one single academic family tree. 668 trace their ancestry to Emmanuel Stupanus, 228 to Lord Rayleigh (physics, 1904). Craig Mello (medicine, 2006) counts 51 Nobelists among his ancestors. Chemistry laureates have the most Nobel ancestors and descendants, economics laureates the fewest. Chemistry is the central discipline. Its Nobelists have trained and are trained by Nobelists in other fields. Nobelists in physics (medicine) have trained (by) others. Economics stands apart. Openness to other disciplines is the same in recent and earlier times. The familial concentration of Nobelists is lower now than it used to be.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42017730</guid></item><item><title>18. Why 4D geometry makes me sad [video]</title><link>https://news.ycombinator.com/item?id=42089196</link><description>
&lt;![CDATA[
&lt;p&gt;76 points points by surprisetalk on 2024-11-08T18:23:00 &lt;/p&gt;
&lt;p&gt;The YouTube video discusses the benefits of intermittent fasting, highlighting how it can help with weight loss, improve metabolism, and promote better overall health. The video explains different types of intermittent fasting schedules, such as the 16/8 method and the 5:2 approach, and provides tips for implementing this dietary practice. It also mentions potential side effects and advises consulting a healthcare professional before starting intermittent fasting, especially for individuals with certain health conditions.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Can someone explain why the second puzzle would need this fancy three-dimensional solution? The area of each strip doesn’t seem important to solving it:We need to cover the circle as efficiently as possible. That means having exactly one layer of strips. Zero layers doesn’t cover it, and two or more layers are wasted. As soon as you start using strips at different orientations you can’t escape an overlap somewhere. So, clearly the optimal way to do it is to use some number of parallel non-overlapping strips, and their total width will be the diameter of the circle.Not sure if this isn’t rigorous enough or something, but it seems perfectly clear to me.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Nice video, incredibly well made. But what an irritatingly clickbaity title.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I first encountered this problem solving technique of looking at the problem in higher dimension from lectures by tadashi tokieda(referenced in the video).
I highly recommend any video of him.I dont rememer finding many examples, nor a reference to it from common problem solving techniques lists(terry tao, aosp? etc). I think it deserve it's place with a catchier name perhaps&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42089196</guid></item><item><title>19. Ambulance hits cyclist, rushes him to hospital, then sticks him with $1,800 bill</title><link>https://news.ycombinator.com/item?id=42081764</link><description>
&lt;![CDATA[
&lt;p&gt;301 points points by type0 on 2024-11-07T22:22:58 &lt;/p&gt;
&lt;p&gt;A cyclist in Oregon was hit by an ambulance that rushed him to the hospital, only to be faced with a $1,800 bill for the transport. The cyclist filed a lawsuit regarding the unexpected charges, highlighting the issue of surprise medical billing in emergency situations.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;As a bicyclist, I'm constantly told how dangerous bicycles are.  Usually, I get a blank look when I explain, bicycles are very safe, it is the cars that are the dangerous part of the equation.  Now I'll have to add fast billing ambulances to the list of dangers.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;"An Oregon cyclist who was struck by an ambulance that made a right turn into him — fracturing his nose and leaving him with scrapes and other injuries across his body — has filed a $997,000 lawsuit against the ambulance provider after it scooped him up, drove him to the hospital and then billed him for the service, according to the suit."$47K for current medical costs, $50K for expected future medical costs, and $900K for pain and suffering (long-term). So the provider may not be getting away with this.Article does not say if cyclist has paid/will pay the ambulance bill.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It sounds like what's actually happening here is that the cyclist's auto insurance is picking up the tab, and in turn suing the ambulance company to get their money back.I always find this intersection of the auto and cycling worlds so strange. If he didn't have a car, he wouldn't have auto insurance, so I guess his health insurance would be covering the initial tab, and then suing the ambulance company to get their money back?If you get a moving violation on your bicycle and show a driver's license to the police, it seems you get points in your license, but if you don't have a driver's license, you don't?&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:49:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42081764</guid></item><item><title>20. The Charms of Catastrophe (1978)</title><link>https://news.ycombinator.com/item?id=42081309</link><description>
&lt;![CDATA[
&lt;p&gt;42 points points by mitchbob on 2024-11-07T21:33:42 &lt;/p&gt;
&lt;p&gt;The website discusses the essay "The Charms of Catastrophe" by Susan Sontag, exploring how modern culture is drawn to disturbing and catastrophic events like wars and natural disasters. It delves into the tendency of society to find allure and fascination in tragedy, raising questions about human psychology, media consumption, and our complex relationship with catastrophic events. The article touches on the paradoxical allure and repulsion of disaster imagery and our need to bear witness to extreme situations, offering insights into our societal fascination with catastrophe.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Interesting nugget: the Swallowtail Catastrophe (https://mathworld.wolfram.com/SwallowtailCatastrophe.html), one of the seven possible, was named by the blind French topologist Bernard Morin (https://en.m.wikipedia.org/wiki/Bernard_Morin).It was the topic of Salvador Dali’s last work (https://en.m.wikipedia.org/wiki/The_Swallow%27s_Tail)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The 'catastrophe machine' mentioned:https://www.geneva.edu/dept/chemistry-math-physics/physics-r...Very easy to throw together or simulate.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It is also worth reading Chaos Theory and the story of the scientists https://onepercentrule.substack.com/p/a-love-letter-to-chaos...&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42081309</guid></item><item><title>21. My Notes on Apple Math Notes</title><link>https://news.ycombinator.com/item?id=42090633</link><description>
&lt;![CDATA[
&lt;p&gt;114 points points by mlajtos on 2024-11-08T21:31:43 &lt;/p&gt;
&lt;p&gt;The website discusses a new type of paper made from bacteria and algae. This sustainable product is eco-friendly and biodegradable, offering a promising solution to reduce the environmental impact of traditional paper production. The paper's unique composition provides a novel approach to addressing environmental concerns associated with paper waste.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Placing text representations of the symbols above them (as interpreted by the handwriting algo) seems so obvious that it’s the sort of thing that I’ll be frustrated if Apple doesn’t adopt it. It generates confidence in the output.Some things aren’t obvious until we see them. This is one.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Maybe I'm a freak but almost all of the proposed "improvements" in this article I find distracting, annoying, and would turn me off of ever using the feature. I do NOT want my notes or content dancing around on the screen or having motion displayed because its evaluating equations or statements while I'm writing them. It's also why I disable most autocomplete and warnings in code editors. I don't complaints about syntax errors for lines I haven't finished writing.Like, why would I care about the value of `a` before I've finished writing the equation? Sometimes a tool just shutting the hell up is a good thing.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;For quite a while, I’ve kept track of how many pages are left in the books I’m reading by having a note with entries along the lines ofVargas Llosa 727-516=211I’d forgotten about math notes / assumed it only applied to handwritten notes so the first time I updated one of these notes after updating my iOS it was a little shocking to retype the = and have the difference generated automatically instead of having to figure it out on my own. I’ve been holding off updating my Macs, but I can see this feature being really handy as a sort of lite spreadsheet replacement.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42090633</guid></item><item><title>22. Ham Radio 101: What is WSPR?</title><link>https://news.ycombinator.com/item?id=42082892</link><description>
&lt;![CDATA[
&lt;p&gt;163 points points by peter_d_sherman on 2024-11-08T00:44:32 &lt;/p&gt;
&lt;p&gt;WSPR, or Weak Signal Propagation Reporting, is a digital mode for ham radio operators that enables monitoring of radio signal paths and propagation conditions. It allows hams to gather data on radio wave propagation, discover how far their signals reach, and analyze conditions to optimize communication. WSPR offers a unique tool for radio enthusiasts to improve their station setups and make the most of radio communication opportunities.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I am really curious what the future of Ham radio looks like. I have several times in my life tried to explore this hobby but mostly was turned off from it by the fact that it didn’t seem to offer much compared to what I could do on the internet aside from using public spectrum. Don’t get me wrong, I think it is cool and I see the use case for emergency response situations. But the idea of the community just never struck the cord with me how other communities have (mostly old white dudes, it seems).Am I wrong? Is there a place for hams in the world where you can more quickly and reliably reach anyone from anywhere across the internet?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I’m licensed in both the United States and Ireland. As a software engineer and electronics hobbyist, I find so many interesting things in ham radio circles. And if you’ve never experimented with RF stuff, you are missing out on a lot of fun. WSPR is one of many experimental modes worth trying. Home built and simple software defined radios like the ATmega-based https://dl2man.de/ (tr)uSDX put HF radio bands in your pocket for under $75. I’ve used digital modes on that radio to reach people on their computers 3000 miles away on 5 watts.Give it a try and I think you’ll find it’s a lot of fun.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I recently bought an RTL-SDR. I've had so much fun with it so far and learned so much, which was my goal. I designed my own antenna in Fusion 360 and built it. I'm currently developing my own SDR application with a custom spectrum display etc. So far I can demodulate AM/FM/SSB and I'm trying to get into decoding digital modes as well.There is so much to learn and enjoy even without transmitting. I like to listen in on air traffic control and download weather satellite images.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42082892</guid></item><item><title>23. Algol-68 seemed like a good idea – until it wasn't</title><link>https://news.ycombinator.com/item?id=42089740</link><description>
&lt;![CDATA[
&lt;p&gt;52 points points by Bostonian on 2024-11-08T19:28:23 &lt;/p&gt;
&lt;p&gt;The website discusses the challenges and legacy of the programming language Algol 68, originally considered as a groundbreaking and innovative language but ultimately faced difficulties in implementation and widespread adoption due to its complexity and stringent requirements. The post reflects on the design choices of Algol 68 and its impact on future programming languages.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;It's not that ALGOL-68 was that bad. It's that the description of it was terrible. There was an attempt to formalize the semantics, and it was a disaster. Nobody knew how to describe language semantics back then, so they invented a new notation. There was an ALGOL-68 report, which was incomprehensible.[1] Then there was "Informal Introduction to ALGOL-68"[2], which was difficult. Finally, there was a "Very Informal Introduction to ALGOL-68"[3], which was somewhat readable.Some sample text from the report:A "nest" is a 'NEST'. The nest "of" a construct is the "NEST" enveloped
by the original of that construct, but not by any 'defining LAYER'
contained in that original.
(The nest of a construct carries a record of all the declarations forming
the environment in which that construct is to be interpreted.
Those constructs which are contained in a range R, but not in any
smaller range contained within R, may be said to comprise a "reach". All
constructs in a given reach have the same nest, which is that of the
immediately surrounding reach with the addition of one extra "LAYER".
The syntax ensures (3.2.1.b, 3.4.1.i,j,k, 3.5.1.e, 5.4.1.1.b) that each 'PROP'
(4.8.1.E) or "property" in the extra 'LAYER' is matched by a defining.
indicator (4.8.1.a) contained in a definition in that reach.)They're trying to get hold of the concept of variable scope and lifetime, back when that was a new idea.They were also trying to invent type theory, which they needed and which didn't exist yet. The first 50 pages of the report are all about the notation they invented to be used in the rest of the report. It's not a very good notation. It's like calculus before Leibniz, when people were trying to use Newton's fluxions.[4]
Computer science just didn't have enough widely understood abstractions for people to even talk about this stuff clearly.[1] https://www.softwarepreservation.org/projects/ALGOL/report/A...[2] https://www.abebooks.com/servlet/BookDetailsPL?bi=3196204463...[3] https://www.computinghistory.org.uk/det/8776/A-Very-Informal...[4] https://en.wikipedia.org/wiki/Fluxion&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;There's a lot of hearsay in that articles, and a lot of sentiment rooted in the particulars of that time.Sure, it was a complex thing in the late 60s/early 70s. Sure, Wirth came up with something simpler. But I'm missing a deeper analysis, especially with a more modern view point where basically any language is at least as complex as Algol 68[0].&gt; Arguably Wirth’s Algol-W was a better successor to Algol-60I might not even disagree, but what were the arguments, and how are they holding up?&gt; and arguably did not have the same connections to industry as the likes of Fortran and CobolSure. But neither did Algol-W or Pascal. And pretty much anything else in the 20th century.[0]: http://cowlark.com/2009-11-15-go/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Industry did adopt ALGOL variants, it was and still is, one of the languages on the Burroughs linage.https://public.support.unisys.com/framework/publicterms.aspx...UK Navy also had a system programmed on it.Also it was largely influential in PL/I and its dialects, which were used a bit everywhere, the most well known being PL.8, PL/S and PL/M.And the competition that eventually lead to the Pascal tree of programming languages.History would have been much different if Algol 68 hadn't existed in first place.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42089740</guid></item><item><title>24. Apple Macintosh before System 7</title><link>https://news.ycombinator.com/item?id=42090544</link><description>
&lt;![CDATA[
&lt;p&gt;96 points points by rbanffy on 2024-11-08T21:17:57 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I went through the process of gathering old sources for the games I wrote in that era. Using 68K Mac emulators (BasiliskII for example) I was able to also get the compilers and other dev tools of the era such that I could compile and run from source.Looking through the sources, it was on one hand fun to marvel at the simplicity of the OS (and Mac Toolbox) from that era. I thought it was hard at the time though. Funny how hindsight (and lots and lots more experience) can change how you now see the past.(I see so many cleaner styles of coding I could have adopted - have since adopted - when I look at my old sources.)But I was amazed at how often the apps/OS crashed as I worked through trying to get them up and running within the emulators. At first I thought it was the emulator(s). But my next thought was ... maybe System 6 crashed all the time back then? I think so.Example, I would run ResEdit (a development tool) and open a file that was also open in the IDE (THINK C or THINK Pascal). Crash!Crashes required a reboot (often then requiring running Disk First Aid on the disk image and rebooting again...). I kind of see why Amiga guys laughed at us.In fact I found a few bugs in sources from 35 years ago.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;FYI if interested in visuals for the earlier system OSSystem .85! - https://apple.fandom.com/wiki/System_0.85 (December 4, 1983)System 1 - https://apple.fandom.com/wiki/System_1System 2 - https://apple.fandom.com/wiki/System_2.0System 3 - https://apple.fandom.com/wiki/System_3System 4 - https://apple.fandom.com/wiki/System_4System 5 - https://apple.fandom.com/wiki/System_5System 6 - https://apple.fandom.com/wiki/System_6 (April 1988)Bonus round - Xerox Star UX (1982) - https://www.youtube.com/watch?v=Cn4vC80Pv6Q&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Interesting: ROM code was accessed through ANNN ("A-line") traps.  Then they started using F-line traps for co-processors.  Then in the proliferation of models targeting education, they started putting out advanced CPU's without co-processors, so lots of software crashed expecting a co-processor.  But of course if Word crashed, they'd talk about monkey-patching the OS pending the next release.  Apple folks thought MS tailored their software to break the Mac, and thereby gain the upper hand in licensing talks.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42090544</guid></item><item><title>25. Principles for product velocity</title><link>https://news.ycombinator.com/item?id=42084753</link><description>
&lt;![CDATA[
&lt;p&gt;216 points points by noleary on 2024-11-08T06:48:48 &lt;/p&gt;
&lt;p&gt;The website discusses the limitations of relying solely on methodology in business, stating that methodology can become a hindrance rather than a help. The article emphasizes the importance of adaptability, creative problem-solving, and human expertise over strict adherence to a single methodology. It suggests that success in business often comes from a combination of structured methodology and flexibility in approach.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I understand the outcry over the heavy processes, but I think there are a lot of confusing statements here.The point being made is "methodology is bullshit," yet what is proposed is exactly that: a new methodology. "Fix a 60-day timeframe and do whatever fits" is a method. The truth is, everyone needs to be organized somehow, and this is why we invent methodologies, frameworks, processes - call it whatever you want - but we all need some form of organization.The problem is that some methodologies (Scrum, etc.) are heavily abused and transformed into management frameworks, which is the opposite of why they were created in the first place. But do you know how Agile was invented? It was a group of software developers, tired of heavy management processes, who came together to decide how to make their processes lightweight. Less is more.Just as one example: 
&gt; "We don’t do Figma mocks. We don’t write PRDs. We don’t really have a design system. We don’t do agile.".
Well, right from the Agile manifesto:
&gt; "Working software over pointless documentation."So it sounds like we've come full circle. That's really a pity. I wonder how we can break the cycle. I also think we should take a look at the original ideas in the old-school methodologies (Agile, etc.) because they’re not bad, just abused. They were created 20 years ago by people who were in the same situation we are in now, so there's a lot of wisdom there that shouldn't be outright rejected.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Basically, I agree … but …In my experience, to successfully reduce process, you need to have really good people.That usually means a heterogeneous mix of skilled, smart, experienced, and creative people that work well as a team, and teams like that, don’t come easily.People (and teams) are really important, and I believe it’s a mistake to think of them as some kind of interchangeable modules (as is the norm in the tech industry, these days).So good management is critical. Keeping staff for long periods of time is also critical. If you have a lot of turnover, you need process to regulate the churn. Long-term employees don’t need to be told what to do, in triplicate, every day. They Just Know, and that “tribal knowledge” is the real key. Also, people that have worked together for a long time have significantly reduced communication overhead. A lot of stuff doesn’t need to be said or written down.This goes double, when working at scale.All that said, I used to work for a corporation that treated Process as a religion.They make really, really good stuff (at scale), but the overhead can be unbearable.They still make good stuff, though, and I haven’t seen anything close, come from less process-driven outfits. Their competitors have just as much process.I wrote a piece called “Concrete Galoshes”[0], some time ago, that talks about this.[0] https://littlegreenviper.com/concrete-galoshes/&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Good stuff in here, but be cautioned that the author doesn’t mention their customers are engineers until a bit later in. Which gives a lot more leeway in allowing engineers to make a majority of decisions.In a more complex domain, like maybe selling private securities, collaboration isn’t slow, it helps us not get fined millions of dollars by the SEC.Personally, I also love minimalist process and likewise believe “methodology” is bullshit, but I caution you, the reader, to consider the specifics of the context you’re working in.For me, that means that almost everything goes figma first. Engineers + product work together to build a figma, which allows other parties to see what we’re building and contribute in a tangible and useful way.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:50:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42084753</guid></item><item><title>26. Understanding privacy risk with k-anonymity and l-diversity</title><link>https://news.ycombinator.com/item?id=42050010</link><description>
&lt;![CDATA[
&lt;p&gt;68 points points by marols on 2024-11-05T09:30:53 &lt;/p&gt;
&lt;p&gt;The website explains the concepts of k-anonymity and l-diversity, which are techniques used in data anonymization to protect individuals' privacy. K-anonymity aims to ensure that each individual in a dataset cannot be distinguished from at least k-1 others, while l-diversity goes a step further by guaranteeing that sensitive information is not overly concentrated within certain groups of records. By implementing these strategies, organizations can protect the privacy of individuals in their data while still maintaining the usefulness of the information for analysis purposes.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;This reminds me of when Apple first introduced, with great fanfare, their pivot to privacy-first and “Differential Privacy.”However, when privacy experts later examined Apple's implementation, they found that the promised privacy was largely an illusion. The parameters Apple had chosen for their Differential Privacy were so weak that only a few data exchanges would be enough to de-anonymize individual users.I don't know if they improved on it, but back then it was less about true privacy and more about the appearance of privacy and an unfortunate example of marketing (core differentiator, premium justification) taking precedence over meaningful protection.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;People interested in this will probably also like reading this friendly introduction to differential privacy: https://desfontain.es/blog/friendly-intro-to-differential-pr..., which is friendly yet goes into a lot of details and techniques in a long series of blog posts.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;No mention of ARX, but it is also a tool that lets you calculate those metrics: https://arx.deidentifier.org&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42050010</guid></item><item><title>27. Consistently faster and smaller compressed bitmaps with Roaring (2016)</title><link>https://news.ycombinator.com/item?id=42020345</link><description>
&lt;![CDATA[
&lt;p&gt;53 points points by hambandit on 2024-11-01T18:57:07 &lt;/p&gt;
&lt;p&gt;The website presents a research paper focused on a novel approach to detecting player positions in a soccer game using deep learning techniques. The method involves a convolutional neural network trained on a large dataset of soccer images to accurately localize players on the field. The study highlights the effectiveness of this method in detecting players, even in complex and cluttered game scenarios, suggesting its potential application in improving sports analytics and broadcasting technologies.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Title is confusing: this is not about the original "Roaring", but an extension of it called "Roaring+Run".Here, "bitmap" = "set of sometimes-compact integers". The "uncompressed" and several "rle" implementations are obvious. Hm, except this only seems to be talking about a particularly-naive RLE approach (suitable for storage but not computation)? If you're doing computation I expect you to use absolute offsets rather than relative ones which means you can just do binary search (the only downside of this is that you can't use variable-length integers now).Roaring is just a fixed 2-level trie, where the outer node is always an array of pointers and where the inner nodes can be either uncompressed bitvectors (if dense) or an array of low-half integers (if sparse). Also, it only works for 32-bit integers at a fundamental level; significant changes are needed for 64-bit integers.This paper adds a third representation for the inner node, the bsearch'able absolute RLE method I mentioned earlier (before even reading the paper beyond the abstract).Overall there's neither anything novel nor anything particularly exciting about this paper, but if you ignore all the self-congratulations it might work as a decent intro to the subject? Except maybe not since there are a lot of things it fails to mention (the ping-pong problem, deduplicated tries, the approach of using a separate set for sparse values in the same range, the "overall sparse but locally semi-dense" representation that uses fixed-size single-word bitsets, ...)&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Roaring bitmaps are really useful for doing phrase search in search engines.Basically you can find cases where one term is immediately before another by left shifting the right terms roaring encoded positions in all documents and bitwise-anding the similarly roaring-encoded payload of the preceding term. All with a highly compressed representation of term positions.With something like numpy you can do this in a handful of logical operations in python.https://softwaredoug.com/blog/2024/01/21/search-array-phrase...&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Hey everyone, if you're looking for a more approachable guide on bitmap compression, I wrote a blog post on it this year: https://pncnmnp.github.io/blogs/roaring-bitmaps.html. It covers run-length encoding, BBC, WAH, Concise, and even Roaring Bitmaps.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42020345</guid></item><item><title>28. Wild Ball</title><link>https://news.ycombinator.com/item?id=42082498</link><description>
&lt;![CDATA[
&lt;p&gt;55 points points by mohabnasser on 2024-11-07T23:50:58 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Pretty cool. Could the arrow keys work in addition to WASD?&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Glitches at points where the more difficult obstacles do not spawn, was able to get the time down to around 1s.The input on the leva (https://github.com/pmndrs/leva) component doesn't capture the event, leading to wild balls.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Wow you reminded me of this game I played as a teenager: Marble BlastLooks like somebody made a web version that is very similar to the version I played: https://marbleblast.vaniverse.io/Thanks for the unexpected hit of nostalgia!&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42082498</guid></item><item><title>29. Elwood Edwards, voice of AOL's 'you've got mail' alert, has died</title><link>https://news.ycombinator.com/item?id=42087087</link><description>
&lt;![CDATA[
&lt;p&gt;149 points points by tysone on 2024-11-08T14:29:09 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;https://archive.ph/bxiFP&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;For a while it was possible to pay Elwood Edwards to record a short message (https://web.archive.org/web/20080613203307/http://www.makinw...). In 2002, I had him record "Mail classified by POPFile" for my POPFile machine learning email classifier (https://getpopfile.org).You can listen to it here: https://soundcloud.com/john-graham-cumming/mail-classified-b...I paid $30 for that. And him saying "Use the source, Luke!"&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Sadly the Fastmail app wouldn’t let me set a custom notification sound but a few weeks ago I switched a frequent text contact sound to his “You’ve got mail”&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42087087</guid></item><item><title>30. The 'Invisibility Cloak' – Slash-Proc Magic</title><link>https://news.ycombinator.com/item?id=42084779</link><description>
&lt;![CDATA[
&lt;p&gt;66 points points by lapnect on 2024-11-08T06:54:22 &lt;/p&gt;
&lt;p&gt;The article discusses a technique called "slash proc", exploring how it can be used for privilege escalation in Microsoft Windows environments. By manipulating the PATH system variable, an attacker could potentially run a malicious program with elevated privileges, highlighting a security vulnerability that could be exploited. The article provides technical details and examples to demonstrate the potential impact of this technique in cybersecurity scenarios.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Interesting. What are the legitimate use cases to not treat /proc as readonly, and what are legitimate use cases to mount around and especially bind-mount random filesystems around in /proc?Like, my first impulse is "Why do we allow this?" And I guess, sure, the answer is "root is allowed to do this, because root is never not allowed". And sure I very much dislike my computer telling me "Nay I cannot do that", hence why I have no windows anymore at home.But there is some stuff that seemingly doesn't have any legitimate use case on a server. And even if protections from that stuff keep me from fixing some situations, I can still nuke and rebuild it in an hour or so.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;One way to detect when this has occurred is to use fstatfs() [0]: it will tell you whether an fd truly belongs to a procfs, or whether it belongs to some other kind of filesystem. Of course, you still have the issue of one part of a procfs being bind-mounted onto another part of a procfs (or onto a different procfs). For that, one mitigation is to double-check the st_dev of every file down the chain. But it still doesn't guarantee that you haven't been led into a recursive bind-mount: for that you have to use tricks like checking rename() error codes, or some of the fancy new openat2() flags, to test the absence of a mount-point boundary.Personally, my stance is to just blindly trust whatever /proc tells you, except in really unusual security models. Users can only end up hurting themselves by putting nonsensical things in there. (The same way no one should bother checking that /dev/null isn't a regular file, even though root can easily make it one.)[0] https://man7.org/linux/man-pages/man2/statfs.2.html&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The Unix philosophy is "everything is a file". But maintaining that abstraction indirectly leads to edge cases like this where devs may be thinking in terms of a FILESYSTEM but some of the files are, in reality, a SYSCALL API/RPC INTERFACE. This makes every new filesystem feature a potential security risk. Is it worth the abstraction? I think so.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42084779</guid></item><item><title>31. What Is a Staff Engineer?</title><link>https://news.ycombinator.com/item?id=42090771</link><description>
&lt;![CDATA[
&lt;p&gt;119 points points by CarefreeCrayon on 2024-11-08T21:55:40 &lt;/p&gt;
&lt;p&gt;The website discusses the role and responsibilities of a Staff Engineer in the tech industry. It explains that a Staff Engineer is an experienced technical leader who focuses on solving complex problems, mentoring junior engineers, and providing technical guidance to the team. The article emphasizes the importance of strong communication skills, collaboration, and a deep understanding of technical concepts for individuals aspiring to become Staff Engineers.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I don't think there's a single easy definition of "Staff Engineer" and it's usually just a title. But it might be still good to think about why those folks keep talking about this specific title.&lt;p&gt;From my observation, there is a certain inflection point in a senior level engineer's career where their expectation rapidly grows in that no one can realistically match it alone. The quality of your work will saturate and it's physically impossible to "work harder". Some extraordinary engineers could delay that point a bit but they will be eventually there.&lt;p&gt;At the moment, they will need to figure out a consistent, reproducible way to scale their contribution. If they want further career progression. The most direct way is becoming an engineering manager. Someone may develop a technical and organizational skill to influence high level decisions and prioritization. Or just become an engineering genius...&lt;p&gt;There are many other possible ways to achieve this, but the point is that further contribution at this point usually needs a radically different way. I do see that many companies tend to grant a title of "Staff Engineer" to those folks able to figure out how to handle this situation.&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I remember learning back at the beginning of my career that at places like Bell Labs and IBM, everybody who was anybody had the title "Member, Technical Staff" which was designed to be a low key humblebrag with the uniformity designed to quell egotistical agitation/competition for more and better titles.&lt;p&gt;Then everybody who didn't work at those places wanted that title too.&lt;p&gt;In banking, the title is "Vice President". It means virtually nothing, there are hundreds of them in every bank, a reason I heard was "otherwise nobody will take your calls." Many people in their 20s who go to business school to get their MBA have already been VPs at banks.&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;A Staff Engineer is a Senior Engineer that has been doing this for a while and doesn't want to be a manager or director.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:51:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42090771</guid></item><item><title>32. Neural Optical Flow for PIV in Fluids</title><link>https://news.ycombinator.com/item?id=42091092</link><description>
&lt;![CDATA[
&lt;p&gt;15 points points by mixeden on 2024-11-08T22:49:11 &lt;/p&gt;
&lt;p&gt;The website discusses the impact of the digital age on the music industry. It delves into how technology has transformed music creation, distribution, and consumption, highlighting the benefits and challenges that come with these changes. The article emphasizes the need for artists to adapt to the evolving landscape by leveraging digital tools and platforms to reach a wider audience. Furthermore, it explores the role of streaming services, social media, and artificial intelligence in shaping the future of music production and marketing.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I know you want to promote (synthical.com), but the readability of that site is very poor.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:52:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42091092</guid></item><item><title>33. The Cybergypsies (Indra Sinha, 1999)</title><link>https://news.ycombinator.com/item?id=42087309</link><description>
&lt;![CDATA[
&lt;p&gt;43 points points by speckx on 2024-11-08T14:57:14 &lt;/p&gt;
&lt;p&gt;The website discusses the book "The Cybergypsies" by Indra Sinha, published in 1999. The book delves into the experiences of a group of computer hackers and explores their unconventional lifestyles and perspectives on technology. It presents a unique look at the cyberspace subculture and offers insights into the individuals who navigate this digital world.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;As a European, it is always very fascinating to see just how &lt;i&gt;differently&lt;/i&gt; the word gypsy and the ethnic group(s) of gypsies are considered culturally over the pond.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Yes, I'm a Cybergipsy.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Is this about &lt;i&gt;real&lt;/i&gt; digital nomads?&lt;p&gt;Digital nomads is an incorrectly used term, they are nomads who do digital work. With so many people at home working digitally it's no longer the correct usage.&lt;p&gt;Off Topicish:&lt;p&gt;&amp;gt;  it’s got a slur in the title.&lt;p&gt;Gypsy is not a slur there is a large Gypsy community. Travelling is important to many of them.&lt;p&gt;I assume it's used in good faith so this is ridiculous and wrong and if you want to be Woke a racist comment since you are denying Gypsies their cultural identify.&lt;p&gt;It can be a slur just like some people identify as Redditors and being a Redditor is often used as a slur and you can mis-identified people like calling HN users Redditors as a slur. Calling Travelers or Roma people Gypsies might be a slur, but it's all a trap so could we all chill.&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:52:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42087309</guid></item><item><title>34. Guild Builds</title><link>https://news.ycombinator.com/item?id=42083292</link><description>
&lt;![CDATA[
&lt;p&gt;130 points points by colinprince on 2024-11-08T01:47:01 &lt;/p&gt;
&lt;p&gt;The website showcases the Guild Builds program, an initiative introduced by The New York Times Tech Guild. Guild Builds offers members a platform to collaborate and develop projects related to technology and media. The program aims to empower employees to create innovative solutions, enhance skills, and contribute to a more diverse and inclusive workplace. It provides opportunities for self-directed learning, fostering a community of creativity and growth within the organization.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;Neat idea! The connections game looks like it's exactly the same as the original. I'm surprised they can get away with that.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Are they game jamming whilst on strike? Outrageous! I just love it!&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Weird, how did this not get marked as a dupe by the automated system when op posted?&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=42078647"&gt;https://news.ycombinator.com/item?id=42078647&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:52:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42083292</guid></item><item><title>35. Colors of the Court – NBA Uniforms</title><link>https://news.ycombinator.com/item?id=42088250</link><description>
&lt;![CDATA[
&lt;p&gt;80 points points by abe94 on 2024-11-08T16:45:39 &lt;/p&gt;
&lt;p&gt;The website showcases an interactive data visualization project that explores the history and evolution of NBA team uniforms from 1946 to 2021. The project includes visuals and information on color trends, design changes, and brand collaborations in NBA uniforms over the years. It offers a comprehensive and engaging look at how basketball team aesthetics have evolved throughout the decades.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;It's the same story in Major League Baseball. The proliferation of alternate uniforms got so out-of-hand that the league imposed a limit of five different uniforms per team last year. Unfortunately, one of those uniforms is the City Connect uniform which is unrecognizable to the extreme for most teams.&lt;p&gt;I hate it. I want every team to go back to a white home uniform with the team name (or logo like the classic Yankees, Cubs, Tigers), and a gray road uniform with the city name, and &lt;i&gt;maybe&lt;/i&gt; one colorful Sunday home alternate worn sparingly.&lt;p&gt;It's bad enough that the rosters have high turnover every year due to free agency. I've said for a long time that it seems silly to have a favorite team, because you're basically cheering for the uniform (i.e. because the people in the uniform are changing constantly) but now that's not even true anymore.&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Money is the main driver, of course. I think this trend started in the UK.&lt;p&gt;Before the EPL, most English soccer clubs had one home, one away strip. It wasn’t that long ago that the only writing would be a single number on the back, a club crest over the front left chest (“near the heart”, you see).&lt;p&gt;Around the 1980s, it seems to me that European leagues started to experiment - England taking a bit of a lead - with shirt sponsorship. One side effect was that shirts suddenly aged. Show me an Everton shirt with “NEC” on the front, or a Manchester City shirt with “brother”, well, I know roughly what season that shirt is from.&lt;p&gt;And fans want to wear the current shirt, often. We can take the piss out of the “full kit wanker”, who turns up to a game in shirt, kit shorts and socks, waiting to be subbed in to his favourite team, but people like to show allegiance and they like to show they’re up to date - in the UK even your car number plate tells your neighbours how “with it”, and therefore how rich you are.&lt;p&gt;Each season a club changed its shirt it would see a boost in income as new shirts would replace the old. This was new. And it gave them ideas.&lt;p&gt;First, what about changing the kit when the sponsor doesn’t change? Some graphic design element, a neck line, maybe a subtle colour change?&lt;p&gt;Then the “third kit” came in. Often used in cup competitions, but occasionally an option for league games. Infamously one grey third kit had to get changed at half time at Old Trafford, as none of the Man Utd team could see each other.&lt;p&gt;And then as some non-domestic leagues took more prominence - European football in particular - some clubs decided to create home and away kits for those competitions specifically.&lt;p&gt;So now we have a situation where clubs like Man City have 3 “base” shirts, plus goalkeeper, plus fashion variants, plus the women’s team…&lt;p&gt;If other leagues can get away with this, they will. Most European leagues have a similar thing going on, and it surprised me that NBA took so long to catch up, and that NFL haven’t gone at this at full throttle.&lt;p&gt;And of course, it has created a collector’s secondary market, special editions, anniversary shirts, “retro editions”, and so on.&lt;p&gt;Sports teams sure know how to milk passion via the wallet.&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;The implication is that this is a bad thing, but I don't really see why. If you're not sure who's playing can't you just look at the score overlay and see? I don't follow sports but when I see a game on at a restaurant it only takes me a few seconds to determine which team is which.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:52:30 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42088250</guid></item><item><title>36. Cops suspect iOS 18 iPhones are communicating to force reboots</title><link>https://news.ycombinator.com/item?id=42081874</link><description>
&lt;![CDATA[
&lt;p&gt;171 points points by tosh on 2024-11-07T22:34:33 &lt;/p&gt;
&lt;p&gt;The article on MacRumors reports that Apple's upcoming iOS 18 update is rumored to include a feature that could force iPhones to reboot to thwart law enforcement's attempts to extract information from locked devices using third-party tools. This potential security measure is said to be aimed at protecting user data and privacy against unauthorized access.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;The idea that iPhones magically communicate with each other to “reboot randomly” when off a cellular network (assumably would happen on a plane easily) is pretty far fetched. The far more likely explanation is that iOS 18.0 has some radio/modem bugs that causes devices to randomly reboot, likely correlated with long periods of disuse or lack of network connectivity.&lt;p&gt;Or heck, if the phone thinks the cellular modem isn’t working (like the phone in a faraday cage), some watchdog might just timeout and reboot.&lt;p&gt;In any case, the idea that they’re randomly networking and intentionally rebooting to thwart this specific law enforcement attack seems pretty unlikely.&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;It would be beyond hilarious if Apple now went and implemented this safeguard. I don't even think a hard reboot would be necessary, simply if the phone hasn't had reception for some preset period of time, or if there's been more than some amount of incorrect logins, or no successful logins in some given amount of time, revert everything to the freshly booted state, encryption and all.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;This reads more like a chain email forward than an actual analysis of the iPhone tech stack.&lt;p&gt;Fwd: Fwd: READ THIS!!! You won't believe what the iPhone does when off network and around other iPhones!!!&lt;p&gt;&amp;gt; It is believed that the iPhone devices with iOS 18.0 brought into the lab, if conditions were available, communicated with the other iPhone devices that were powered on in the vault in AFU. That communication sent a signal to devices to reboot after so much time had transpired since device activity or being off network.&lt;p&gt;The hypothesis doesn't make any sense because the phone doesn't need to communicate with other phones to decide to restart/lock based on lack of network signal.&lt;p&gt;&amp;gt; Matthew Green, a cryptographer and Johns Hopkins professor told 404 Media that the law enforcement officials' hypothesis about  iOS 18  devices is "deeply suspect," but he was impressed with the concept.&lt;p&gt;Just about sums it up.&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:52:40 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42081874</guid></item><item><title>37. Genetic repair via CRISPR can inadvertently introduce other defects</title><link>https://news.ycombinator.com/item?id=42088504</link><description>
&lt;![CDATA[
&lt;p&gt;105 points points by amichail on 2024-11-08T17:13:37 &lt;/p&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;A lot of the graphics that explain how CRISPR work show this very careful snipping of a strand of DNA. Tiny little scissors making pinpoint accuracy revisions. I think that's lead to a deep misunderstanding for most people (including myself) on how this technology actually works.&lt;p&gt;CRISPR is amazing, but it's still a fairly blunt tool. The article talks about one way: guide RNA can often bind to sequences that are very similar to the intended sequence, but not exactly, meaning it's probable that for every intended cut you're making several unintended ones. The "scissor" action itself, Cas9 protein, is less like a scissor cut and more like a jagged tear, which can damage surrounding DNA.&lt;p&gt;The repair pathways themselves are also imperfect. It's not a copy/paste like infographics show, it's more like emergency duct taping broken ends together.&lt;p&gt;All of that stuff combined...Again, amazing technology, but I get extremely nervous when I hear people talk about introducing CRISPR-based gene editing into the human gene pool. The generational effects there are still entirely unpredictable at this stage, could be disastrous, and any actual paths to trying to roll things back would be deeply ethically fraught.&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Let's say you have a running program on a computer, and you figure out a way to swap out parts of its instructions / state in RAM while it is running.  What are the odds of your swap causing problems? Now, what if the program is 100 - 1000x more complex than anything you have ever managed to create.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;Consider a scenario where you're editing a function:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  function foo() { return a*2.1^2+0.52/2 }
&lt;/code&gt;&lt;/pre&gt;
So you do a find-all regex "1.*5" and delete &lt;i&gt;all&lt;/i&gt; matching occurrences (à la CRISPER) to get:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  function foo() { return a*2.2/2 }
&lt;/code&gt;&lt;/pre&gt;
But unbeknownst to you, the code is littered with a bunch of commented out versions of the same function you're trying to edit:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  /* function foo() { return a*1.5/2.1 } */
  /* function foo() { return a*1.95/2.4 } */
&lt;/code&gt;&lt;/pre&gt;
And now those commented out versions now become:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  /* function foo() { return a*/2.1 } */
  /* function foo() { return a*/2.4 } */
&lt;/code&gt;&lt;/pre&gt;
And now the whole program doesn't compile anymore--or your patients get Leukemia. Oops.&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:52:50 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42088504</guid></item><item><title>38. Toy Models of Superposition (2022)</title><link>https://news.ycombinator.com/item?id=42086987</link><description>
&lt;![CDATA[
&lt;p&gt;41 points points by tessierashpool9 on 2024-11-08T14:13:17 &lt;/p&gt;
&lt;p&gt;The webpage discusses a toy model of transformer circuits and their importance in presenting a simplified yet informative understanding of these circuits. The toy model serves as an educational tool, illustrating the principles of transformer operation and providing insights into the behavior of transformers in a straightforward manner. With detailed explanations and interactive visual aids, the model aims to facilitate learning about transformers in an accessible way.&lt;/p&gt;
            ]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:53:00 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42086987</guid></item><item><title>39. Gravity's Eastern Voyage</title><link>https://news.ycombinator.com/item?id=42087517</link><description>
&lt;![CDATA[
&lt;p&gt;26 points points by XzetaU8 on 2024-11-08T15:22:16 &lt;/p&gt;
&lt;p&gt;The website discusses the concept of gravity and its impact on the formation of the universe. It explores the connection between gravity and the expansion of space, reflecting on how gravity influences the behavior of matter and energy on a cosmic scale. The article delves into the role of gravity in shaping the cosmos, emphasizing its profound influence on the fundamental structure of the universe.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;&lt;a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rsnr.2024.0029" rel="nofollow"&gt;https://royalsocietypublishing.org/doi/epdf/10.1098/rsnr.202...&lt;/a&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I'm a sucker for history of science, this stuff is so interesting to me.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:53:10 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42087517</guid></item><item><title>40. The Weeds Are Winning</title><link>https://news.ycombinator.com/item?id=42087770</link><description>
&lt;![CDATA[
&lt;p&gt;95 points points by Jimmc414 on 2024-11-08T15:55:02 &lt;/p&gt;
&lt;p&gt;The website explores the impact of climate change on weed growth and discusses the potential for genetic engineering to combat superweeds. It highlights how rising temperatures and carbon dioxide levels can lead to increased weed growth, which poses a threat to food security. The article delves into the necessity for innovative solutions to address the challenges posed by these superweeds in the agriculture sector.&lt;/p&gt;
            &lt;p&gt;Top Comments&lt;/p&gt;&lt;div&gt;I've been using strong vinegar for weed control on my property for a few years now.  You do have to be careful about applying it and watch the over-spray because it is not a targeted herbicide like Roundup, it's going to kill grass and broadleaf plants alike.  Sometimes I lay down a tarp to mask off the grass border, for example.  But if you have a general weedy area that just needs to be knocked down, or a gravel path/driveway to keep clear, I have found it is just as effective, quick-acting, and long-lasting as the synthetic herbicides, with the side effect of smelling like salad dressing, instead of smelling like cancer.&lt;p&gt;I buy 30-45% concentrate depending on what is on sale, and dilute to around 10% for new weeds and 20% for full grown weeds. A little dish soap in there helps it wet down the leaves. For lawn weeds, once they are under control, I've been able to keep up with a 1/4 acre lawn with just manual weeding.  Good tools help,  I have tried a lot of weed pulling gadgets.  Using a push mower means I go slow enough to spot them, and if they get too big they jam the mower so I am motivated to pull them while they are still small.&lt;/p&gt;&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;My long-departed grandmother lived her entire life in Grodno, a city in western Belarus on Nieman river. It is a lovely and fertile region with well defined seasons of the year. All kinds of things grow there, mostly temperate weather crops, potatoes, tomatoes, peas, cucumbers, carrots, radishes, cabbages, apples, pears etc. Grandmother was a big believer in child labor so my summer was spent weeding every day. Her herbicide/pesticide were little children hands. I think vinegar was involved too. I think though if she could afford chemicals she would have. Ugh, if I never have to squish colorado potato beetle larvae from the potato leaf, I'll be happy.&lt;/div&gt;&lt;hr /&gt;&lt;div&gt;I have an acre of forest and I spend time removing invasive species like buckthorn and wild mustard to keep the forest healthy. It can be really challenging to discriminate between native and invasive plants without a lot of experience and plant identifying apps like iNaturalist. I would love to be able to sweep my phone around and have it highlight invasive plants live. Is anyone working on something like this? The technology already works in images of a single plant, I just need to identify multiple plants in one frame, and ideally live video.&lt;/div&gt;&lt;hr /&gt;]]&gt;</description><pubDate>Sat, 09 Nov 2024 06:53:20 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42087770</guid></item></channel></rss>