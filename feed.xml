<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>HN Summaries</title><link>http://andrewpoirier.github.io/hn_summarizer</link><description>The top HN articles everyday - summarized</description><lastBuildDate>Thu, 07 Nov 2024 05:00:47 -0000</lastBuildDate><item><title>1. Scientists glue two proteins together, driving cancer cells to self-destruct</title><link>https://news.ycombinator.com/item?id=42037386</link><description>
&lt;![CDATA[
&lt;p&gt;625 points points by Jerry2 on 2024-11-04T00:42:58 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;There's a decent amount of cynicism in the comments, which I understand. I think this is a really cool and novel study, though.Historically, cancer was treated with therapies that are toxic to all cells, relying on the fact that cancer cells divide quickly and are unable to handle stress as well as normal cells (chemotherapy, radiation).The last couple of decades we've seen many targeted cancer therapies. These drugs generally inhibit the activity of a specific protein that lets the cancer cells grow (e.g. EGFR inhibitors) or prevents the immune system from killing the cancer cells (e.g. PDL1 inhibitors).This mechanism is way more interesting. The gene BCL6 is usually turned on in immune cells when they are mutating to recognize foreign invaders. This process involves lots of DNA damage and stress, but BCL6 stops the cells from dying and is therefore important for normal immune function. Unfortunately, this makes BCL6 a gene that is often co-opted in cancer cells to help them survive.The method cleverly exploits the oncogenic function of BCL6 not by inhibiting it, but by turning it into a guide, enabling the delivery of activating machinery to the targets of BCL6 and reversing the inhibitory effects on cell death.The whole field of targeted degraders, molecular glues, and heterobifunctional molecules is a growing area of interest in cancer research.&lt;/li&gt;&lt;li&gt;All of this stuff is promising, and I hope the diagnostic side catches up as well.Just went to a funeral this weekend for a 40 year old who died of breast cancer 4 weeks after diagnosis at her first annual mammogram.A lot of skeptical people under 30 here haven't lived through regularly various cancer diagnoses in their friends &amp; family group that your late 30s/early 40s starts to bring.I don't have the data on it, but anecdotally I notice that women's cancers seem to strike 5-10 years earlier than mens even if they can be caught early &amp; treated well.. Though apparently men have overall worse cancer survival rates.&lt;/li&gt;&lt;li&gt;Same as mountainriver's comment. I really find strange how I've been reading news lines over the past years about great advancements in many incurable and chronic diseases (like Alzheimer's, diabetes, and cancers) yet after all that time people's treatment is not going any better. I'm not sure whether scientific journalism somehow delivered some unintended messages to me, or we're just supposed to experience these great advancements after couple of decades from the announcement.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:55:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42037386</guid></item><item><title>2. New York Times Tech Guild goes on strike</title><link>https://news.ycombinator.com/item?id=42040795</link><description>
&lt;![CDATA[
&lt;p&gt;683 points points by ChrisArchitect on 2024-11-04T12:08:30 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Here is context on the strike, how long it's been brewing, and more that I happened to read yesterday:https://www.thenation.com/article/archive/the-new-york-times...&lt;/li&gt;&lt;li&gt;&gt; The two sides negotiated until late Sunday. The sticking points in recent days were over whether they could get a “just cause” provision in their contract, which means workers can be terminated only for misconduct or another such reason; pay increases and pay equity; and return-to-office policies.This seems like a LOT of issues that still need to be hammered out. It would be one thing if they were disagreeing about a number, but it sounds like the terms keep changing and nobody agrees on the nature of the work itself. It's not even clear that there's a preliminary contract ready for the NYTimes to sign.Striking during election week is kind of a crappy move to pull. But if this is just attention seeking without a serious contract, it seems egregiously risky on behalf of the union members too: there's not a clear button the Times can push on behalf of the union to end the strike immediately. The Times would either have to sign a blank check to the union now, or the union would have to agree to an IOU in exchange for a bunch of temporary concessions.&lt;/li&gt;&lt;li&gt;Gift link: https://www.nytimes.com/2024/11/04/business/media/new-york-t...https://archive.ph/f9gP0&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42040795</guid></item><item><title>3. A change of heart regarding employee metrics</title><link>https://news.ycombinator.com/item?id=42038653</link><description>
&lt;![CDATA[
&lt;p&gt;570 points points by zdw on 2024-11-04T05:06:42 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This week's prompt is a change of heart on employee metrics. Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com. Today's prompt: Share your thoughts on a story you saw in CNN. com's newsquiz.  The weekly News Quiz will be held on November 3, 2024 at 11:30 a.m. ET (13:30 p.m., November 4, 2014 at 9:30 A.M. ET)&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;&gt;&gt; [Why not build programmer performance measurement tooling?] It's the job of a manager to know what their reports are up to, and whether they're doing a good job of it, and are generally effective. If they can't do that, then they themselves are ineffective, and that is the sort of thing that is the responsibility of THEIR manager, and so on up the line.Agreed wholeheartedly, but for slightly different reasons. To wit, laziness and Goodhart's law. [0]In the absence of infinite time, automation will excuse a lack of manager curiosity, as other competing tasks absorb the freed time.Consequently, most managers with automated dashboards showing performance metrics won't use those dashboards... plus all the person-to-person work they were previously doing. They'll only use those dashboards.Which then slowly but inexorably turns your employees into dashboard-optimization drones via operant conditioning.Helping a colleague doesn't show up on the dashboards? Fuck that. Digging into what looks like a security vulnerability isn't on the sprint board? Fuck that.Which is incredibly corrosive to quality, creative system design.And then, because this is the work reality you've created, the creative folks you really want working there bail for greener pastures, and you're left with bottom of the barrel talent and retention problems.[0] https://en.m.wikipedia.org/wiki/Goodhart's_law&lt;/li&gt;&lt;li&gt;I worked on an internal platform for a large engineering org and was responsible for choosing what features we put in.We had the technical means to track everything from commits to reviews, jiras, deploys, etc. Some of our most celebrated and impactful features were reporting on Accelerate metrics and related. E.g. deploy frequency, size of changes, duration of stages in the dev cycle and such.I set a very inflexible red line: we don’t expose data more granular than at team level. Ever. No excuse.Quite a few line managers would come to me asking for “personal metrics”, and even engineers in the team were super interested in building that (“with all this data we could…”).My argument was that these metrics are toxic and invite misuse. A second factor was that this misuse would generate mistrust from engs against the platform and damage adoption.Instrumenting an organization thought of as a system is fine. You want to see where are bottlenecks, you want to have measurable targets for how technical work is done and how it correlates to business goals/KPIs.You want to offer teams metrics of their delivery my process so they can take the info and implement improvements whenever they see fit, and have a data driven conversation with the business (e.g. about the right setting for the carefulness knob)But teams are the minimum unit of ownership, we stop the instrumentation there. Sure, a team’s performance ultimately links to individuals, but that is the manager’s job to figure out.Interestingly:* only line managers asked for this info, nobody in a director/vp/cxo role
* the most annoyed by me saying no were engineers in the team who wanted to do these features&lt;/li&gt;&lt;li&gt;there's a scene from the tv show "suits" that has always stuck with me:the show is set in a law firm, and in this particular episode they needed to lay off some of their associates. a young, newly-promoted lawyer was tasked with drawing up a list of the associates and marking the ones who she felt should get the axe, based on their performance. so she comes up with some metrics, goes through the associates' work, and ranks them based on the resultant numbers, saying that the bottom few could be let go.there is one employee, brian, who ends up near the bottom of the list. a more senior person takes her aside and asks why she recommended brian be laid off, so she brings out the metrics and rankings and points to him near the bottom. the senior person asks "okay, so who are the top associates in your list? can you point them out on the seating chart?". turns out, the top five associates were all brian's neighbours, and the reason was that he was really good at helping people when they were stuck with something. but of course that affected his own individual contributor numbers, and there were no metrics for "helped someone else out but didn't get credit for it".&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42038653</guid></item><item><title>4. Hertz-dev, the first open-source base model for conversational audio</title><link>https://news.ycombinator.com/item?id=42036995</link><description>
&lt;![CDATA[
&lt;p&gt;280 points points by mnk47 on 2024-11-03T23:30:48 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Introducing hertz-dev, the first open-source base model for conversational audio generation. A convolutional audio autoencoder that takes mono, 16kHz speech and transforms it into a 8 Hz latent representation at about 1kbps bitrate. The model has a context of 8192 sampled latent representations (17 minutes) and predicts the next encoded audio frame. We're excited to announce that we're open-sourcing current checkpoints of our full-duplex, audio-only transformer base model.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;This is really cool. FWIW, existing open-source TTS engines are really bad in comparison to what you have here: I know this is voice-to-voice, but I think there'd be a lot of appetite to get this to also be multimodal and accept text (essentially making it a really good TTS model, in addition to a great voice-to-voice model).I suppose someone could hack their way around the problem by finetuning it to essentially replay Piper (or whatever) output, only with more natural prosody and intonation. And then have the text LLM pipe to Piper, and Piper pipe to Hertz-dev. But it would be pretty useful to have it accept text natively!&lt;/li&gt;&lt;li&gt;They say Hertz is first of its kind but Moshi is another duplex audio model from earlier this year that seems to perform similarly (and it runs on a MacBook):
https://github.com/kyutai-labs/moshi&lt;/li&gt;&lt;li&gt;Tesla’s approach to pure vision-based autonomous driving—temporarily setting aside lidar and other sensors—seems designed to make this technology more accessible and scalable. By focusing on a vision-only model, they can accelerate adoption and gather large datasets for quicker iterations. Once the vision-based system reaches a mature stage, I imagine Tesla might reintegrate additional sensor data, like lidar or radar, to refine their autonomous driving suite, making it even more robust and closer to perfection.Additionally, I’ve been exploring an idea about voice interaction systems. Currently, most voice interactions are processed by converting voice input into text, generating a text-based response, and then turning this text back into audio. But what if we could train the system to respond directly in voice, without involving text at all? If developed to maturity, this model could produce responses that feel more natural and spontaneous, possibly diverging from traditional text-to-speech outputs. Natural speech has unique syntax and rhythm, not to mention dialect and tone variations, which could make a purely voice-trained system fascinating and more human-like.Could you let me know if your current voice interaction model follows the standard speech-to-text-to-speech process, or if there is exploration in voice-to-voice processing?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42036995</guid></item><item><title>5. Alonzo Church: Architect of computer intelligence</title><link>https://news.ycombinator.com/item?id=42042025</link><description>
&lt;![CDATA[
&lt;p&gt;274 points points by drcwpl on 2024-11-04T14:51:10 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;A historical tidbit which I loved in Paradigms of Artificial Intelligence Programming (available in PDF and EPUB here - https://github.com/norvig/paip-lisp):&gt; The name lambda comes from the mathematician Alonzo Church's notation for functions (Church 1941). Lisp usually prefers expressive names over terse Greek letters, but lambda is an exception. A better name would be make-function. Lambda derives from the notation in Russell and Whitehead's Principia Mathematica, which used a caret over bound variables: x̂(x + x). Church wanted a one-dimensional string, so he moved the caret in front: ^x(x + x). The caret looked funny with nothing below it, so Church switched to the closest thing, an uppercase lambda, Λx(x + x) . The Λ was easily confused with other symbols, so eventually the lowercase lambda was substituted: λx(x + x). John McCarthy was a student of Church's at Princeton, so when McCarthy invented Lisp in 1958, he adopted the lambda notation. There were no Greek letters on the keypunches of that era, so McCarthy used (lambda (x) (+ x x)), and it has survived to this day.So, yes, on the topic of this post - Church pops up in loads of Lisp retrospectives. Maybe he's "forgotten" by people with very little engagement in the history of computing.&lt;/li&gt;&lt;li&gt;"Church’s lambda calculus and the Turing machine are equally powerful but differ in the fact that Turing machines use mutable state. To this day, there is a rift between functional and imperative programming languages, because of the separation of Church and state."[I have known the above quote forever, but I can't find an original source]edit: might be from Guy Steele: "And some people prefer not to commingle the functional, lambda-calculus part of a
language with the parts that do side effects. It seems they believe in the separation of Church and state"&lt;/li&gt;&lt;li&gt;If you want to read something incredible about Church, read Rota's reminiscence. It's the first section of https://www34.homepage.villanova.edu/robert.jantzen/princeto....Related:Alonzo Church, 92, Theorist of the Limits of Mathematics(1995) - https://news.ycombinator.com/item?id=12240815 - Aug 2016 (1 comment)Gian-Carlo Rota on Alonzo Church (2008) - https://news.ycombinator.com/item?id=9073466 - Feb 2015 (2 comments)&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042025</guid></item><item><title>6. What should a logo for NeXT look like? (1986)</title><link>https://news.ycombinator.com/item?id=42042382</link><description>
&lt;![CDATA[
&lt;p&gt;222 points points by themantra514 on 2024-11-04T15:26:32 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The logo got a second lease of life after NeXT was acquired by Apple. A bit of British political trivia: Dominic Cummings, the campaign director of the Vote Leave organisation in the 2016 Brexit referendum, nicked the NeXT logo and made a few tweaks for Vote Leave:&gt; The logo was stolen from Steve Jobs. We couldn’t afford to hire a top agency and they wouldn’t have worked with us anyway. So I thought about Jobs’ advice on simplicity and ‘the best artists steal’ (see above!) and did some google searches. Surely there’s something he did with manic determination I could steal? After he left Apple in the 1980s, for his new company he got one of the top designers in the world to do a logo. I looked at it and thought, ‘good enough for Steve good enough for us, we can put a hole in the top so it looks like a ballot box’. Total cost: almost nothing. I made a lot of decisions like this because the savings in time and money were far greater than the marginal improvements of spending more time and money on them (if this would even bring an improvement).https://dominiccummings.substack.com/i/117842715/where-did-t...&lt;/li&gt;&lt;li&gt;I always go back to the Saul Bass presentation to AT&amp;T over their 1970 logo redesign. He takes 30 minutes to explain the thought process and sell this design hard. By the end you're convinced it's the natural thing to do. I'm sure every executive in the room felt the same way.https://www.youtube.com/watch?v=xKu2de0yCJI(Bass would return a mere 13 years later to do the AT&amp;T "Death Star" logo after the breakup)&lt;/li&gt;&lt;li&gt;&gt; Set in all capitals, the word NEXT is sometimes confused with EXIT possibly because the EXT grouping is so dominant. A combination of capitals and lower case letters alleviates this problem.Huh. Never knew why the 'e' was lowercased until now. I thought it was just "style".&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042382</guid></item><item><title>7. An embarrassingly simple approach to recover unlearned knowledge for LLMs</title><link>https://news.ycombinator.com/item?id=42037982</link><description>
&lt;![CDATA[
&lt;p&gt;248 points points by PaulHoule on 2024-11-04T02:52:14 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21\% of the intended forgotten knowledge in full precision, which significantly increases to 83\% after 4-bit quantization.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;In short: their finding is that quantizing a model undoes various “unlearning” methods. An unlearning method is a specific update to model weights that make it forget specific facts. These are often meant to satisfy copyright claims, although I don’t know if these are ever used in practice.I feel that this needs a good threat model analysis. Like, you possess an fp32 model, which someone has fine-tuned to forget some facts, which you can then quantize to recover those facts. When would this lead to a dangerous situation?&lt;/li&gt;&lt;li&gt;I think quantization is a red herring. If there's any way to undo the unlearning, this means that the knowledge is still in the weights -- that's basic information theory. I'm sure there are a million other ways to recover the lost knowledge that don't involve quantization.&lt;/li&gt;&lt;li&gt;It's like asking baby to unlearn something "bad" it learned. Pretty much guaranteed the knowledge will be reinforced rather than forgotten.Whenever I hear about AI craze, I remind myself of the 3D printers craze from 10-15 years ago. "Death blow to factories", "We will print our own cars", "We will print our own food". I imagine LLM AI will follow the same fate - yes, but not really.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42037982</guid></item><item><title>8. Show HN: Tinder, but to decide what to eat</title><link>https://news.ycombinator.com/item?id=42036041</link><description>
&lt;![CDATA[
&lt;p&gt;242 points points by kiru_io on 2024-11-03T20:56:05 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I work for a startup that provides meal plans. This and competing apps let you set requirements (kcal, intolerances, etc), also includes breakfast, etc. These apps are aimed at people that want to eat healthy and are looking for some inspiration.You seem to go with user generated content, so the inspiration part is out, the health part is out, but you focus very much on the problem of forming a choice just for diner.I do think this way your audience is huge, but the added value is a bit limited.So you can decide to slowly move towards those other apps. Or, perhaps move away from it somehow. Maybe it's a generic tool to help you grow and maitain your relationship with your partner by providing tools that deal with each other preferences and choices within that relationship. Both practical and more emotional. But I guess I'm now more brainstorming :).You can also just keep it small and have fun tinkering in a way that works for you. I read a comment:&gt; There are servers needed for the app to work, right? So I guess subscription makes sense?Perhaps you don't really need servers. Keep the data just local on the app. Let people use regular chat for getting to a compromise. That way you could ask a one time fee of $5. It could be a (very) small passive income that doesn't require you much work, no moderation, no security risks.Either way, good luck!&lt;/li&gt;&lt;li&gt;I like the idea and face the same challenge. I’ve just installed it and, from my first impressions, it seemed a bit basic. Here’s what I expected:Hundreds of recipes that I could swipe left and right through, allowing me to build up a typical selection of what I would usually eat. Instead, I was presented with only three choices, none of which I would generally consider.A simple way to send the code to my wife — via imessage, Telegram, etc. Instead, I had to tell her in person! :)This presents the perfect opportunity to delve into shopping lists where the wife wants something healthy, and the I crave a burger. I can think of quite a few features you could add if the app develops further.Also, like the comment below about having a stranger over for dinner (not for dating purposes), it could involve a couple or someone visiting a new country who would appreciate a local showing them around and perhaps covering the dinner cost. Once the app learns your food preferences and interests, that could be quite exciting! There might already be an app that does this; I’m not sure.  Swiping left and right on both food likes / dislikes and also general interests.&lt;/li&gt;&lt;li&gt;Why not both? See what others around you want to eat, swipe together, meet up with a stranger in a restaurant and eat together. Maybe get to know them, maybe not.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42036041</guid></item><item><title>9. Writing secure Go code</title><link>https://news.ycombinator.com/item?id=42043939</link><description>
&lt;![CDATA[
&lt;p&gt;274 points points by gus_leonel on 2024-11-04T17:34:28 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Security in Go code can be achieved by following a few specific practices. These practices will lead to writing robust, secure and performant code. The best way to stay informed about Go security announcements is to subscribe to the [email protected] list. The go vet command without arguments runs the tool with all options allowed by default. The tool scans the source code and reports potential issues. It also enforces Go language styling and suggests corrections with running staticcheck in the CI pipeline, we can install the code locally as a standalone binary.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;As the article also mentions: instead of checking if your program has a dependency on something that contains vulnerabilities, govulncheck checks if vulnerable code is actually reached. I find that so awesome. (And I know, someone is going to point out that hipster language foo does this too and better — it’s not the norm).&lt;/li&gt;&lt;li&gt;Don’t forget about capslock: https://github.com/google/capslockAssess your 3P modules for dangerous capabilities&lt;/li&gt;&lt;li&gt;Great tips in here - I was not aware of `go vet` nor `go test -race`.FWIW, while go is not memory safe, I do find that it's much easier to be safe in go than it is in other languages. Its verboseness lends to a very clear understanding of what's happening in any given function. I absolutely hated this at the start, but now ~3 years into maintaining a go codebase, I find it quite nice both for debugging as well as editing old code. I know exactly what each function does, and what the structure of data is in any given context.Another interesting side effect is that AI tools seem to work amazingly well with golang, given how context is often local to the function.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043939</guid></item><item><title>10. Quincy Jones has died</title><link>https://news.ycombinator.com/item?id=42039569</link><description>
&lt;![CDATA[
&lt;p&gt;362 points points by gfortaine on 2024-11-04T08:13:45 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;As a jazz aficionado, I am very familiar with Quincy Jones’ immense contributions to music.  I am a very big fan of the albums he produced, such as “The Dude” and “Back on the Block.”What is less well known is Quincy Jones’ involvement with computing.  At one point he was on the advisory committee for the ACM Computers in Entertainment Magazine (https://dl.acm.org/doi/10.1145/973801.973803), and if I remember correctly, he was on the board of former Xerox PARC researcher Alan Kay’s Viewpoints Research Institute.  I’ve been wanting to know more about Quincy Jones’ involvement with computing since I first learned about this a few years ago.Rest in peace.  Quincy Jones is a legendary figure.&lt;/li&gt;&lt;li&gt;When I was four, I got a record player for Christmas. This one:https://djcj.website/wp-content/uploads/2019/12/denim_turnta...My mom had a copy of Ray Charles' greatest hits. My favorite song was One Mint Julep. Quincy Jones did the arrangement. You can see by the wear on this record how much I listened to that song, as well as "Unchain My Heart" and "Hit the Road Jack."https://djcj.website/wp-content/uploads/2020/05/one-mint-jul...So much great music. And when you watch interviews with other musicians with whom he crossed paths, they all talk about what an uplifting and positive influence he had on their lives.Here's a interview with his longtime collaborator Tom Bähler. He has some really beautiful stories about his experiences with Quincy.https://youtu.be/yIkP_XuIDeY?t=5197And when he got together with Rod Temperton, the magic was next-level.https://www.facebook.com/QuincyJones/posts/ill-never-forget-...&lt;/li&gt;&lt;li&gt;*From a strictly musical perspective, what have you done that you’re most proud of?*That anything I can feel, I can notate musically. Not many people can do that. I can make a band play like a singer sings. That’s what arranging is, and it’s a great gift. I wouldn’t trade it for shit.https://www.vulture.com/article/quincy-jones-in-conversation...&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039569</guid></item><item><title>11. Diagram as Code</title><link>https://news.ycombinator.com/item?id=42044771</link><description>
&lt;![CDATA[
&lt;p&gt;339 points points by ulrischa on 2024-11-04T18:46:42 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Diagrams lets you draw the cloud system architecture in Python code. It was born for prototyping a new system architecture without any design tools. Diagram as Code allows you to track the architecture diagram changes in any version control system. It currently supports main major providers including: AWS, Azure, GCP, Kubernetes, Alibaba Cloud, Oracle Cloud etc... It also supports On-Premise nodes, SaaS and major Programming frameworks and languages.NOTE: It does not control any actual cloud resources nor does it generate cloud formation or terraform code.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I quite like PlantUML, even for add a simple diagram to an email discussion which has become to long.My colleagues however like the idea but don't want to learn the syntax.So I build a simple add-on to our internal mail system that, when invoked, scrapes the email and runs it against a fine tuned Llama 3.1 8b model which then generates a PlantUML diagram from natural language.If the input isn't of an appropriate nature to be converted to a diagram or vague it will not do this.What I have found is that now at least 50% of the team have used this feature once since go-live.In many cases not all though, the immediately returned image is not 100% correct but there is a nice integrated way to edit and render which is now causing many to get familiar with the syntax whereas before they couldn't be bothered.Overall it's been a nice, relatively cheap way to get GenAI to actually help us at work.&lt;/li&gt;&lt;li&gt;This project (and others like it) are graphviz wrappers - they do some really cool stuff to emit styled .dot files that look better than writing and rendering raw gv.#Allowing specification in Python offers very little advantage - in theory you think, hey, I've got hi-lighting, autocompletion, and so on from an IDE. It'll play nice in VCS. Maybe I can interrogate orchestration layers and so on to produce dynamic views.In practice diagrams are produced by folks who might not want to use or learn python [or golang, their other implementation]. Instead a lean purpose-build DSL, maybe even an extension of graphviz dot, is easier and more portable for some audiences to pick up.
Secondly, we can't JUST graft a DSL front-end onto these tools because the styled components are baked into the project.My personal experience with layout engines is that they work OK for very small architecture diagrams, but become ugly or inelegant at useful scales.I (and the teams I've worked with) settle on draw.io, either the desktop app, or committed as part of confluence, as the best way to describe intent/design - and rendering graphviz with a style up top for anything dynamic.Would welcome seeing a true extension to the dot language that can unlock reasoning engines (like to do threat modeling) and render-time styling.&lt;/li&gt;&lt;li&gt;I personally have been using mermaid for sequence diagrams and flow charts: https://mermaid.js.org/DaC seems nicer for infra&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42044771</guid></item><item><title>12. DB48X: High Performance Scientific Calculator, Reinvented</title><link>https://news.ycombinator.com/item?id=42043747</link><description>
&lt;![CDATA[
&lt;p&gt;153 points points by qwezxcrty on 2024-11-04T17:19:34 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The 48G was a really good calculator, but only after loading additional software. The HP50g that came much later is better in every respect, except possibly for the smaller "ENTER" key (and people used to 48G will have to change some habits and possibly redefine some keys…).Incidentally, many young people (yes, I know how that sounds) do not know how useful a good engineering calculator can be and do not want to learn how to use one. They are missing out. Yes, there is a steep learning curve, but the rewards are significant if you do any amount of calculation in your hobby or work. No, this is not replaced by typing "python" (or "bc", or anything else, really) at your command prompt.Also incidentally, the development of good engineering calculators pretty much died. HP Prime is largely a school-pleasing toy, HP would down their calculator division a long time ago, and nobody else produces anything good. It's kind of like with gyms: what you get is what the market wants, and since the market doesn't know much, you get gyms full of useless exercise machines, because that's what people think a good gym should have. Similarly with calculators: you get stupid "modern" graphing calculators which are useless for actual work (it takes forever to use them to calculate useful things, and graphing is much better done on a computer), but they look great and sell well.I admire the project, although I would probably have taken a different path (emulation) to get the biggest effect with the smallest possible effort :-)I wish there was a good HP50G emulator for iOS — there used to be one, but it was abandoned (contact me if you want to develop it and would like to get the source code, it was under the GPL and I got it from the author).&lt;/li&gt;&lt;li&gt;I am a fan of the HP Primehttps://hpcalcs.com/product/hp-prime-graphing-calculator/But I use it in algebraic instead of RPN mode.  I’ve got a 49g and a 50-something too.People say it is pricey but I managed to get one discounted that was intended for the Latin American market.  So is the thing that software is supposed to run on.&lt;/li&gt;&lt;li&gt;I still have a HP48GX in perfect condition and love it. One of my first programs was to calculate how much „slower“ my time is running when I drive a car or fly in a plane compared to someone standing still on the sidewalk.I still find it much more comfortable having a real calculator… call me old fashioned.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043747</guid></item><item><title>13. A Hamiltonian Circuit for Rubik's Cube</title><link>https://news.ycombinator.com/item?id=42011976</link><description>
&lt;![CDATA[
&lt;p&gt;101 points points by jcalx on 2024-10-31T21:56:35 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;You can solve a (legally scrambled) Rubik's Cube with no knowledge of its initial state, as long as someone stops you when you've done it.You also need several billion years to do this, so it's not recommended for beginner solvers.&lt;/li&gt;&lt;li&gt;This is neat, though it's from 2012 or maybe earlier.I wonder if there is a single not-too-long rotation sequence that generates the whole cube group.  That is, a sequence XYZ that you can perform repeatedly and have that bring you through every cube state.  If not, maybe there is some other very simple algorithm that traverses all the states, instead of a zip file that uncompresses to 200MB.&lt;/li&gt;&lt;li&gt;Bit of a meta note: grown adult here who never got into cubing earlier in life. Recently picked one up as some non-screen entertainment for some long haul flights and train travel. Highly recommend.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42011976</guid></item><item><title>14. Is the Q source the origin of the Gospels?</title><link>https://news.ycombinator.com/item?id=42040706</link><description>
&lt;![CDATA[
&lt;p&gt;155 points points by Tomte on 2024-11-04T11:55:30 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The Q hypothesis has issues. For such an important document or source, nothing is known about it. Its existence is not mentioned or hinted at in external sources. No trace of it has been found.In addition, the synoptic puzzle can be laid in a self-consistent and "path-of-least-resistance way" by looking at e.g. author motives: Matthew writing for the Jewish community in Jerusalem; Mark describing Peter's preaching in Rome; Luke writing as a Greek doctor for a gentile audience (and John writing much later, clarifying and responding to the first heresies that had popped up).So the Q hypothesis, aside from being a purely theoretical construction based on internal evidence, is not necessary either.See e.g. "Case Against Q: Studies in Markan Priority and the Synoptic Problem" by Goodacre.&lt;/li&gt;&lt;li&gt;Kind of odd to see this turning up here:  this theory isn't new and in fact is one of the couple most accepted theories about the origin of the gospels.  It was proposed more than a century ago, and this article doesn't say anything particularly new or interesting about it.  Honestly, the Wikipedia page is probably better:https://en.wikipedia.org/wiki/Q_source&lt;/li&gt;&lt;li&gt;&gt; The Farrer hypothesis proposes that Matthew used Mark as a source, but Luke used both Mark and Matthew as a source. This approach is simple and negates the need for a Q source altogether.&gt; A weakness of the Q source hypothesis is the absence of any textual evidence despite extensive scholarly efforts to find it. The entire hypothesis is based on statistical and literary analysis and inference. It adds complexity to the synoptic problem by introducing an additional layer of tradition, transmission, and composition, which may not be warranted given the available evidence (or rather lack thereof).Wouldn't Occam's Razor suggest that the Farrer hypothesis is most likely true?Edit: Or, maybe I should just continue reading to the end first:&gt; On the other hand, it would also make for a more complex explanation than other scholars have proposed, violating the principle of Occam’s Razor. Alternatively, Mark could have been the source for Matthew, and Matthew for Luke, which is a much simpler explanation than the Q hypothesis.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42040706</guid></item><item><title>15. PacCam: Pac-Man controlled with your face</title><link>https://news.ycombinator.com/item?id=42018740</link><description>
&lt;![CDATA[
&lt;p&gt;59 points points by bblcla on 2024-11-01T16:37:16 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Hello again Nolen, fun game! Tried the single player mode on mobile, works well and fast :)1. Why is there no "map"? I was confused as I expected a fixed grid for pacman to be able to navigate in2. Why are the bots so much faster? It is difficult enough to track my own character to ensure its moving in the right direction, so the fast bots really sneak up on me and there's no way to avoid them&lt;/li&gt;&lt;li&gt;Love it! I think we'd get along - https://github.com/everythingishacked/CheekyKeys&lt;/li&gt;&lt;li&gt;I wish there was some way to calibrate this.My webcam sits low on my desk (it's built into a laptop screen that is one of many) so it was almost impossible to look up without it saying "too far" and I had to curl around myself and hunch to get it to maybe register as looking down.I tried moving the display between monitors and that didn't help much.If I could calibrate what "straight ahead" is then I could maybe play the game.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42018740</guid></item><item><title>16. USFS Decision to Halt Prescribed Burns in California is History Repeating</title><link>https://news.ycombinator.com/item?id=42046596</link><description>
&lt;![CDATA[
&lt;p&gt;274 points points by danboarder on 2024-11-04T22:19:49 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;&gt; This week, the U.S. Forest Service directed its employees in California to stop prescribed burning “for the foreseeable future,” a directive that officials said is meant to preserve staff and equipment to fight wildfires if needed.It sounds like it's a resourcing issue, not a change in philosophy.  It doesn't change the fact that it won't be happening though.&lt;/li&gt;&lt;li&gt;California is in the middle of a huge fire insurance crisis. It started with the intentional housing supply restrictions that drove up property prices and rents. In suburban areas, rebuilding costs were mostly increased indirectly through higher wages (as tradespeople and laborers have to make rent.) This sent insurance rates through the roof and caused a wave of policy cancellations. Many insurance companies exited the market altogether [1].Climate change is also to blame. The firestorms of 2017, 2018 and 2020 broke all records, and were insanely expensive to rebuild after. The typical trigger is a katabatic wind event [2] after a long dry spell. This massively reduces relative humidity (often to 5-10%,) making ignition much easier. Once a fire starts, the wind spreads it extremely quickly. Sustained wind speeds of 50-60mph are not uncommon near mountain peaks.In 2017/2018/2020, the precipitating events were so intense that the initial responses focused exclusively on helping the residents out. By the time the actual firefighting began, the fires were already enormous.It's surprising to me that we haven't seriously looked into large-scale sprinkler systems, such as this one deployed in Spain [3]. These could take a major bite out of the initial uncontrolled stage. They could either be deployed in the wild along naturally defensible lines, or at the perimeters of inhabited areas.They're expensive upfront, but not as expensive as the alternative. They might also reduce the need for prescribed burns.[1] https://www.theguardian.com/us-news/article/2024/aug/10/home...[2] https://en.wikipedia.org/wiki/Katabatic_wind[3] https://www.wired.com/story/spanish-wildfire-defenses/&lt;/li&gt;&lt;li&gt;Slight tangent, USFS has been using outdated models for their prescribed burns, and burned as late as July in my area, right at the beginning of fire season and months away from any expected precipitation. This turned into a big wildfire in my area and they spent ~$100m putting it out. You may have been able to get away with burning during the summer in the 90's here, but not anymore.I'm not opposed to prescribed burns, either, I think they are totally necessary. But do them in the fall, when you've got nothing but rain and cool temperatures for the next 6 months, instead of weeks before the hottest and driest stretch of the year.As to why they burn in early summer, they said at a community meeting it's because it requires fewer people to manage the fire.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42046596</guid></item><item><title>17. Top discoveries about ancient people from DNA in 2023</title><link>https://news.ycombinator.com/item?id=42033913</link><description>
&lt;![CDATA[
&lt;p&gt;89 points points by softwaredoug on 2024-11-03T16:21:03 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This year saw a lot of research consolidation, with continued progress along well-established lines. New techniques have opened up avenues of understanding kinship from ancient populations and the links between people and artifacts. Balancing selection can be a result of overdominance, where the relative fitness of an allele declines when the allele becomes very common, or balancing selection can happen when an allele has varied fitnesses in different times and places. Many fascinating questions about ancient people involve their social dynamics and their interaction with other ancient groups.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;&gt; [On a sense of smell:] Denisovan missense variants had a stronger response than their human orthologs, which de March and coworkers narrowed down to “odors contemporary humans perceive as spicy, balsamic, and unpleasant”. Neandertals, on the other hand, had a much lower response for the missense variants which were found in these genes.I struggle to interpret this (not least because of the mis- prefix: does this mean incorrectly sensing? Does spicy in scent mean something that would map to food spices?) But does it mean that Denisovans would have disliked things we think of as smelling bad, far more than Neanderthals would? Would a Denisovan have bathed more for personal hygiene, or have avoided spicy food, or...? Would a Denisovan today have a strong aversion to some perfumes or colognes (the ones with woody, tobacco, musk scents)?There is this vague sense of wonder that there were human populations with preferences that were _different_ to our own.&lt;/li&gt;&lt;li&gt;It’s impressive how ancient DNA maps our origins though it feels like piecing together a story with missing chapters&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42033913</guid></item><item><title>18. We're Leaving Kubernetes</title><link>https://news.ycombinator.com/item?id=42041917</link><description>
&lt;![CDATA[
&lt;p&gt;384 points points by filiptronicek on 2024-11-04T14:41:28 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Kubernetes seems like the obvious choice for building out remote, standardized and automated development environments. But Gitpod has found that Kubernetes is not the right choice. This is the story of how (not) to build development environments in the cloud. The many gigabytes of source code, build caches, Docker container and test data are subject to a high change rate and costly to migrate. Unlike many production services, there’s a 1-to-1 interaction between the developer and their environment. We found that many teams underestimate the complexity of operating a CDE.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Personally - just let the developer own the machine they use for development.If you really need consistency for the environment - Let them own the machine, and then give them a stable base VM image, and pay for decent virtualization tooling that they run... on their own machine.I have seen several attempts to move dev environments to a remote host.  They invariably suck.Yes - that means you need to pay for decent hardware for your devs, it's usually cheaper than remote resources (for a lot of reasons).Yes - that means you need to support running your stack locally.  This is a good constraint (and a place where containers are your friend for consistency).Yes - that means you need data generation tooling to populate a local env.  This can be automated relatively well, and it's something you need with a remote env anyways.---The only real downside is data control (ie - the company has less control over how a developer manages assets like source code).  I'm my experience, the vast majority of companies should worry less about this - your value as a company isn't your source code in 99.5% of cases, it's the team that executes that source code in production.If you're in the 0.5% of other cases... you know it and you should be in an air-gapped closed room anyways (and I've worked in those too...)&lt;/li&gt;&lt;li&gt;&gt; This is not a story of whether or not to use Kubernetes for production workloads that’s a whole separate conversation. As is the topic of how to build a comprehensive soup-to-nuts developer experience for shipping applications on Kubernetes.&gt; This is the story of how (not) to build development environments in the cloud.I'd like to request that the comment thread not turn into a bunch of generic k8s complaints. This is a legitimately interesting article about complicated engineering trade-offs faced by an organization with a very unique workload. Let's talk about that instead of talking about the title!&lt;/li&gt;&lt;li&gt;  &gt;Kubernetes seems like the obvious choice for building out remote, standardized and automated development environments

- Is it really Obvious Choice™ though Fred?- Hmm, let's consult the graphs.  &gt;Kubernetes is a container orchestration system for automating software deployment.

- It's about automating deployment Carl, not development environments!  &gt;Kubernetes is not the right choice for building development environments, as we’ve found.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42041917</guid></item><item><title>19. Unfortunate things about performance reviews (2021)</title><link>https://news.ycombinator.com/item?id=42039053</link><description>
&lt;![CDATA[
&lt;p&gt;205 points points by zargon on 2024-11-04T06:30:00 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I learned this in my very first corporate job at Factset and it made me sick of them; it's the main reason why I've worked at a bunch of startups.If the manager likes you, they will see the things you do in a positive light.If the manager doesn't like you, they will see the things you do in a negative light.So obviously, the solution is to optimize for always keeping the manager happy... except that that is a little dehumanizing.It's basically like any relationship coupled with confirmation bias. Basically, if you get onto the shit-list of your partner or friend or manager, it is difficult to get off it. People seem to automatically polarize their opinions about other people (probably due to confirmation bias) and then just apply post-hoc justification.If nothing else, I have gotten very good at noticing the change of tone when the point-of-no-return is reached (perhaps because I feel like I am terrible at avoiding it). You'll feel some queasiness/nausea after a conversation that went from friendly to critical based on something you perhaps flubbed... you'll start blaming yourself (even though you probably didn't actually have a ton of control over the outcome). Something will feel "off." Things won't feel as harmonious anymore. Details will be off- you didn't get invited to an important meeting that you are pretty sure you would have been invited to months prior. A new hire will get approved, but without anyone checking in with you first. You will feel like you are on the defensive and are working "defensively"- you're struggling to complete work or put presentations together or whatever- you're not sleeping well- those are all the feel of the ring ropes against your back, because you're actually on them, and you're in denial. It's hard not to take personally; has anyone actually ever been put on a PIP that made it back to "stellar performer", or are PIPs purely just lip-service to a CYA for the inevitable layoff?&lt;/li&gt;&lt;li&gt;&gt;&gt; If you take nothing else away from this post, take this: a sufficiently skilled manager can take the same body of work and make it work for you OR against you.This is pretty much the only thing that matters (unless you are really at one of the far extremes of the ability bell curve).&gt;&gt;About a year ago, I finally came to the conclusion that I would not put anything on a performance review writeup for a coworker that could ever be used against them.When I was a contractor, I was occasionally asked for feedback from permanent employee managers. As if I would say anything bad, even if I hated them.&lt;/li&gt;&lt;li&gt;Perf reviews are a terrible abstraction. The ranking and self-scoring and meetings and goal setting and stomach aching could be boiled down to a 5 item list:1. We want this person to leave. They probably should have been let go already.2. We wouldn't mind if this person left, but we aren't going to go out of our way until there are layoffs.3. This person provides adequate value, loyalty, and flexibility for their salary.4. This person is a key contributor and should be advanced if possible.5. We don't know why this person is still here, and we are terrified they might leave us when they realize how undercompensated they are.That's it. That's all perf reviews are for. No one needs to be stack ranked or anything silly like that. HR is an abomination.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039053</guid></item><item><title>20. Designing a Home Radio Telescope for 21 Cm Emission</title><link>https://news.ycombinator.com/item?id=42044494</link><description>
&lt;![CDATA[
&lt;p&gt;89 points points by antognini on 2024-11-04T18:21:59 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This study presents the methodology for creating a cost-efficient radio astronomy telescope that can be used to detect 21 cm emissions. By measuring the Doppler shifts of the 21 cm emission, the velocities of hydrogen clouds relative to Earth can be determined. This enables the identification of these clouds' movements, their positions within the galaxy's spiral arms, and their roles in the overall rotational dynamics of the Milky Way. The setup is designed to be accessible to amateurs, enabling others to conduct similar projects.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I had a dish set up in London, 20 years ago (before I came out to the USA). Looked like #1. The dish splits into segments, and I recall driving down the M1 from Birmingham in my battered old Ford Escort, with the (razor-sharp) mesh segments squeezed in and wobbling right next to my jugular... Those dishes were getting vanishingly hard to find in the UK, so it was worth the trip, and I kept my neck intact with only minimal damage...I had it all packed up when moving out to the US (because my imagination told me that houses in the US were far larger than in the UK). The house I ended up buying (despite having a much larger back garden) didn't have the space to set it up again and remain married, so two decades later, it's still in that wooden case... I do, however, have an optical telescope set up (#2)Back then, we didn't have easy access to SDR's, so there's a feed horn, a down-converter, and I had an external (standalone) WinRadio receiver to  actually listen to the feed. That went into an audio card on a linux box, and the waterfall display was beautiful :)#1: https://imgur.com/a/CDrEeII#2: https://imgur.com/a/askar-130phq-scope-sb-myt-mount-26mp-cam...&lt;/li&gt;&lt;li&gt;Some pics of the OG detector from the 50s https://www.radio-astronomy.org/node/368The Purcell mentioned is the same one of NMR Nobel and E&amp;M textbook fame.&lt;/li&gt;&lt;li&gt;Page three of the paper shows an enviable rooftop antenna farm. Drool.I have an ignorant question ... can home/amateur radio astronomy ever produce layperson-appreciated "imagery"? Something easily understood like optical astronomy can produce? e.g. stitching together a sky scan for a particular emission or something?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42044494</guid></item><item><title>21. Limitations of frame pointer unwinding</title><link>https://news.ycombinator.com/item?id=42040549</link><description>
&lt;![CDATA[
&lt;p&gt;117 points points by rwmj on 2024-11-04T11:25:25 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Didn’t really get the point of the post as it just presents something without a conclusion.9X% of users do not care about a &lt;1% drop in performance. I suspect we get the same variability just by going from one kernel version to another. The impact from all the Intel mitigations that are now enabled by default is much worse.However I do care about nice  profiles and stack traces without having to jump through hoops.Asking people to recompile an _entire_ distribution just to get sane defaults is wrong. Those who care about the last drop should build their custom systems as they see fit, and they probably already do.&lt;/li&gt;&lt;li&gt;I added support to Sysprof this weekend for unwinding using libdwfl and DWARF/CFI/eh_frame/etc techniques that Serhei did in eu-stacktrace.The overhead is about 10% of samples. But at least you can unwind on systems without frame-pointers. Personally I'll take the statistical anomalies of frame-pointers which still allow you to know what PID/TID are your cost center even if you don't get perfect unwinds. Everyone seems motivated towards SFrame going forward, which is good.https://blogs.gnome.org/chergert/2024/11/03/profiling-w-o-fr...&lt;/li&gt;&lt;li&gt;I broadly agree with the thesis of the post, which if I understand correctly is that frame pointers are a temporary compromise until the whole ecosystem gets its act together and manages to agree on some form of out-of-band tracking of frame pointers, and it seems that we'll eventually get there.Some of the statements in the post seem odd to me though.- 5% of system-wide cycles spent in function prologues/epilogues? That is wild, it can't be right.- Is using the whole 8 bytes right for the estimate? Pushing the stack pointer is the first instruction in the prologue and it's literally 1 byte. Epilogue is symmetrical.- Even if we're in the prologue, we know that we're in a leaf call, we can still resolve the instruction pointer to the function, and we can read the return address to find the parent, so what information is lost?When it comes to future alternatives, while frame pointers have their own problems, I think that there are still a few open questions:- Shadow stacks are cool but aren't they limited to a fixed number of entries? What if you have a deeper stack?- Is the memory overhead of lookup tables for very large programs acceptable?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42040549</guid></item><item><title>22. Cheap Thrills, an album cover by Robert Crumb (2020)</title><link>https://news.ycombinator.com/item?id=42039935</link><description>
&lt;![CDATA[
&lt;p&gt;172 points points by stareatgoats on 2024-11-04T09:35:19 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Robert Crumb was interviewed for a BBC Radio 3 program where he played some records from his collection and talked about them.One song was particularly fascinating: a primitive attempt at the new fangled sound called 'jazz' by a French country musette band from the early 20th C.Crumb explained that when early American jazz bands went to Paris in the 1910s, the new sounds caused a sensation when they performed in the up-market venues. So the country bands were aware of the new style of jazz but most people had never actually heard any and had to play what they imagined jazz to be, mostly based off verbal descriptions. I remember this record as a crazy sound, but brilliantly entertaining.Unfortunately I can't point you to the song or the interview, but if anyone else can please reply :-0&lt;/li&gt;&lt;li&gt;Crumb has been living in a small village in the south of France since the 90's.In the "Crumb" doc he says something along "They're all wearing baseball hats. I'm getting out of here.", speaking about the US.He also laments having taken too much LSD.&lt;/li&gt;&lt;li&gt;The intro about him not liking the music reminded me of the Letter of Note entry when Crumb is sent an experimental jazz album and replies to the musician:https://lettersofnote.com/2015/12/17/torturing-the-saxophone...&gt; I gotta tell you, on the cover of the CD of your sax playing, which is black and has no text on it, I wrote in large block letters, in silver ink, “Torturing The saxophone—Mats Gustafsson.” I just totally fail to find anything enjoyable about this, or to see what this has to do with music as I understand it, or what in God´s name is going on in your head that you want to make such noises on a musical instrument. Quite frankly, I was kind of shocked at what a negative, unpleasant experience it was, listening to it.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039935</guid></item><item><title>23. The history of Unix's ioctl and signal about window sizes</title><link>https://news.ycombinator.com/item?id=42039401</link><description>
&lt;![CDATA[
&lt;p&gt;109 points points by ingve on 2024-11-04T07:39:27 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I submitted the proposal for `tcgetwinsize` to POSIX a few years ago.  I originally wrote it because I was sick of having to turn off _POSIX_C_SOURCE for just a single file to get glibc to expose TIOCGWINSZ.SIGWINCH and the TIOCGWINSZ ioctl() were originally omitted from POSIX as they were considered relevant for windowing systems only and GUI-stuff was considered out of scope for POSIX.  Furthermore, POSIX only specifies ioctl() for STREAMS; other interfaces that traditionally use ioctl() calls are specified in POSIX using wrapper functions (which is what the new interface is; it is specified such that you can implement it just by wrapping the traditional TIOCGWINSZ/TIOCSWINSZ ioctl calls).My original proposal had functions tcgetsize() and tcsetsize(), but it turns out that QNX already uses these identifiers with an incompatible signature, so a last minute change was made to name these tcgetwinsize() and tcsetwinsize().Furthermore, the winsize structure traditionally also has ws_xpixel and ws_ypixel members indicating the resolution of the terminal.  This existed primarily becaus on some historical virtual terminals, a client could change the video mode by calling the TIOCSWINSZ ioctl, providing resolution and row/column count for the desired video mode.  While no current virtual terminal known to me supports this, the POSIX spec mandates that if a slave PTY calls tcsetwinsize(), the window size update is propagated to the master, allowing terminal emulators to implement this feature if desired.  Another objection raised was that the traditional unsigned short type may be insufficient for future high-definition screens and a resolution may not be well defined for some types of terminals like hardcopy or braille terminals.I maintain that submitting a feature to POSIX and waiting for a new version of the standard to be released is probably the easiest way to get glibc to implement a feature you want.&lt;/li&gt;&lt;li&gt;For anybody wondering "why couldn't they just...", there is a lot of complexity in TTYs and PTYs. The kernel is even involved in line discipline and job control. Those Ctrl+Z or Ctrl+C keys you press? The kernel gets involved.It may seem strange that there's a process signal for window-size changes, but that's what was needed back in 1985. There's a similar dance with the Amiga's console.device, but both Unix and Amiga TTYs are better than Windows' terminals where there was no such thing as a PTY until Windows 10, you had to make direct API calls, and even now it's still pretty slow: https://devblogs.microsoft.com/commandline/windows-command-l...This page is a great overview pf the Unix TTY/PTY subsystem: https://www.linusakesson.net/programming/tty/&lt;/li&gt;&lt;li&gt;Terminals, ttys, etc. have some of the most arcane and outdated APIs I am aware of. It's like a window back into the 1970s&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42039401</guid></item><item><title>24. Show HN: Convert any website into a React component</title><link>https://news.ycombinator.com/item?id=42043552</link><description>
&lt;![CDATA[
&lt;p&gt;214 points points by alexdanilowicz on 2024-11-04T17:03:00 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Your actual product is really slick.  Even just with some basic tests I can see that it produces designs with a much higher degree of polish than regular LLM models, and with much more of a design bent.  I'll definitely use this for some prototyping this week!I wonder what changes you've made from standard LLMS to get here?  I could imagine trying to put things on guard rails, giving it some components to build off, or just fine tuning based on a really nice corpus of good websites (maybe generated with this tool).&lt;/li&gt;&lt;li&gt;This is a very useful browser extension. Really love the fact that you are even able to convert the styles to TailwindCSS. Very clever.&lt;/li&gt;&lt;li&gt;I am going to be that person, but how is the copyright for the output of tools like this? Since not all websites include license on their site, yet their looks are replicated, this might be even less clear than with LLMs in general.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043552</guid></item><item><title>25. DataChain: DBT for Unstructured Data</title><link>https://news.ycombinator.com/item?id=42043948</link><description>
&lt;![CDATA[
&lt;p&gt;121 points points by shcheklein on 2024-11-04T17:34:57 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Yay! Excited to see DataChain on the front page :)Maintainer and author here. Happy to answer any questions.We built DataChain because our DVC couldn't fully handle data transformations and versioning directly in S3/GCS/Azure without data copying.Analogy with "DBT for unstractured data" applies very well to DataChain since it transforms data (using Python, not SQL) inside in storages (S3, not DB). Happy to talk more!&lt;/li&gt;&lt;li&gt;Cool!  Does this assume the unstructured data already has a corresponding metadata file?My most common use cases involve getting PDFs or HTML files and I have to parse the metadata to store along with the embedding.Would I have to run a process to extract file metadata into JSONs for every embedding/chunk? Would keys created based off document be title+chunk_no?Very interested in this because documents from clients are subject to random changes and I don’t have very robust systems in place.&lt;/li&gt;&lt;li&gt;It took me a minute to grok what this was for, but I think I like itIt doesn't really replace any of the tooling we use to wrangle data at scale (like prefect or dagster or temporal) but as a local library it seems to be excellent, I think what confused me most was the comparison to dbt.I like the from_* utils and the magic of the Column class operator overloading and how chains can be used as datasets. Love how easy checkpointing is too. Will give it a go&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043948</guid></item><item><title>26. Interview gone wrong</title><link>https://news.ycombinator.com/item?id=42020103</link><description>
&lt;![CDATA[
&lt;p&gt;135 points points by ashu1461 on 2024-11-01T18:32:28 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;If you know nothing about Python or coding, and you see a=b=c, you'd think that's true when all three a,b,c are the same. Python does that beautifully here, and that's the intent. It's not Python that's confusing, it's your previous experience with other languages that's confusing you.&lt;/li&gt;&lt;li&gt;I know the point of the piece is the python syntax here, but I got stuck on: "judge things like code quality / speed / conciseness etc."Do people generally write concise code on right off the bat when confronted with a new problem? I've always taken the same approach I would with writing: get something that works; refactor for concision. Maybe everyone else is playing 3D chess and I'm still on Chutes and Ladders?&lt;/li&gt;&lt;li&gt;I'm confused about this blog post. Python is mostly C inspired but actually more pseudocode inspired (which helps its popularity) which is why chained expressions exist.Also, why would you conduct an interview in a language where even if you don't know the syntax (and this is obscure) you could have looked it up or disallowed the interview to be done in Python? I think the due diligence with this issue is more to the interviewer than Python.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42020103</guid></item><item><title>27. Back to the future: Writing 6502 assembler with Amazon Q Developer</title><link>https://news.ycombinator.com/item?id=42043549</link><description>
&lt;![CDATA[
&lt;p&gt;69 points points by ingve on 2024-11-04T17:02:38 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;In this short post I have some fun with Amazon Q Developer and get it to write code that runs on my virtual Commodore 64. Here is the code it produced. It runs.....well almost. I see a square sprite move smoothly across the screen and when it gets to the end it crashes with the following error:Illegal quantity error in 200I turn to Amazon Q to help me fix this issue, asking it to resolve this error. It quickly provides me with updated code and an explanation of why I got the error. This correction ensures that the high bit of the sprite's X coordinate is set correctly when the sprite moves beyond the 255th pixel, allowing it to move across the entire width of the screen. After looking at some Redit groups, it is clear that the way to use the 6502 assembler tool is the way forward.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;This raises the question: what information did Amazon Q ingest to be able to write C64 Basic, and from where – OCR'd books and magazine off Google Books? Online tutorials? That would explain whether it would be possible to adapt this workflow to supporting other relatively obscure platforms, with a limited documentation set that's certainly not available online on the internet in easily parsable HTML: e.g. PDP-11 assembly, Turbo Pascal, classic Macintosh/Macintosh Toolbox, etc.Who knows, it might be a shot in the arm for retrocomputing enthusiasts.&lt;/li&gt;&lt;li&gt;  // Zero page variables
  .const zp_x = $FB
  .const zp_y = $FE
  .const zp_dx = $101
  .const zp_dy = $104

AI extended zero page, I see… (zp_dx and zp_dy are in 6502 hardcoded stack range, not in zero page at all).&lt;/li&gt;&lt;li&gt;Author of the post here. Just reading the comments so apologies for getting some of the terminology wrong. The intention was never to mislead folk , just wanted to share my enthusiasm for emulation and the fact that you could get working code.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42043549</guid></item><item><title>28. Data Commons</title><link>https://news.ycombinator.com/item?id=42005646</link><description>
&lt;![CDATA[
&lt;p&gt;49 points points by zerojames on 2024-10-31T11:18:49 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Used as grounding by Google's DataGemma model https://blog.google/technology/ai/google-datagemma-ai-llm/&lt;/li&gt;&lt;li&gt;How is this built? What'd be the approach if I'd like to achieve similar results against proprietary data.References article speak of RAG and RIG - but I wonder if they factor into fine-tuning the models. AFAIK, RAG doesn't play nicely with structured data.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42005646</guid></item><item><title>29. It's called a dance floor</title><link>https://news.ycombinator.com/item?id=42042810</link><description>
&lt;![CDATA[
&lt;p&gt;131 points points by wmeredith on 2024-11-04T16:04:07 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Vogue is an RIAA-certified triple-platinum hit, selling over six million copies since its 1991 release on the "I'm Breathless" album by pop mega-star Madonna. Vogue topped charts in Australia, Canada, Japan, the United Kingdom, and the United States. It has been sampled by Kylie Minogue, Beyoncé, and Ariana Grande. The track starts with a startling, sweeping vocal line, "What are you looking at?" that pans around our heads like Michael Bay's camera.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;QSound was magic at the time. We had a DSP class in my EE degree where we implemented a very minor transform that would shift position of audio and it was wild.It's impossible to get 3D audio to be absolutely as flawless as the real world because human ears all vary slightly and your 3D spacial perception of sound is literally tuned on your own ears, but QSound's transfer functions come as close as you can get.The algorithm also falls apart a bit outside of the sweet spot, and is really only useful in headphones and specific cases where a human is known to be placed in a certain location relative to speakers.The original model was developed using a simulated human head and lots of hand-tuning. I am curious if we've advanced far enough with tech that a more modern set of transfer function parameters could be developed.Nothing beats N speakers for positional audio, but this is a pretty decent replacement if the conditions are ideal.OpenAL was designed as an open-source library to bring 3D audio to the masses in the same way that OpenGL did (basically exposing QSound/equivalent hardware on sound cards to an API), but I'm not sure what happened to it [1].[1] https://www.openal.org/documentation/openal-1.1-specificatio...&lt;/li&gt;&lt;li&gt;If you like this kind of stereophonic sound, I recommend Art of Noise. Here are some songs from them:Moments in Love: https://www.youtube.com/watch?v=uNkcZ8QoNuIParanoimia: https://www.youtube.com/watch?v=5F8BD6gNOagDragnet '88: https://www.youtube.com/watch?v=f6JQO0KnUZYI recommend to set the videos to the highest quality and to listen using headphones&lt;/li&gt;&lt;li&gt;I remember being shown Virtual Barbershop on 2000s YouTube as a teenager. I was absolutely blown away by the experience, it did for my ears like what 2024 VR does for my eyes. Total magic.https://www.qsound.com/demos/virtualbarbershop_long.htmVery cool to see it’s from the same company!&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042810</guid></item><item><title>30. HardenedBSD Feature Comparison with OpenBSD, FreeBSD, NetBSD</title><link>https://news.ycombinator.com/item?id=42036652</link><description>
&lt;![CDATA[
&lt;p&gt;97 points points by transpute on 2024-11-03T22:35:16 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This page includes a summary of HardenedBSD's features. Use this summary to help you with reading comprehension and vocabulary. At the bottom of the page, please share your feedback about the features you have seen on this page and the other Hardened FreeBSD features. The Hardened BSD Wiki is a free, open-source, community-driven software project that aims to improve the performance of BSD systems. For a more detailed and up-to-date guide to Hardened. BSD features, please visit our wiki.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;It's easy to invent a chart that only you can get a nearly perfect score on.This does nothing to explain what any of these features are, what are "Boot hardening" and "sysctl hardening"?At least OpenBSD's innovations page makes an attempt to explain new concepts and features that have been developed over the years, and people can make any comparisons for themselves.https://www.openbsd.org/innovations.html&lt;/li&gt;&lt;li&gt;Read these claims with a pretty big asterisk.  Implementation quality of HBSD features is often poor or very poor.  https://www.fabiankeil.de/gehacktes/hardenedbsd/ is just one example.  Specifically some of the changes made to "harden" the system are pretty dubious and introduce new bugs, possibly security relevant, that did not previously exist.  No one runs or pen tests HBSD.  It's even more niche than OpenBSD.&lt;/li&gt;&lt;li&gt;&gt; Executable file integrity enforcementI assume but don't know for sure that this refers to Veriexec in NetBSD, and I'm not sure what in HardenedBSD. Anyone know?https://man.netbsd.org/veriexec.8My understanding is that Veriexec isn't enabled by default - the manpage says only that "[s]ome kernels already enable Veriexec by default." If you have this enabled, how do you upgrade binaries? The manpage says that in strict mode 1, write access to monitored binaries is allowed but then access is denied. So I assume that after file modification, root then runs veriexecgen and veriexecctl load as mentioned in the manual to update the signatures list. So it seems that strict level 1 isn't functionally different from a read-only /usr or even just root-owned binaries. In either case, you just need root to update targeted binaries. Surely I'm missing something and would appreciate some insight.At a glance as an outsider, stricter modes appear somewhat functionally similar to "chflags schg" on BSD systems, where more work is needed to get around restrictions. In the case of schg, you have to reboot into single user mode, remove the schg flag, then modify the binary, and continue booting into multi-user mode. You could do this as a remote attacker (as in not having console access) depending on what boot files are or aren't protected with schg, but modifying all the necessary files can be a source of new problems.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42036652</guid></item><item><title>1. Hacking 700M Electronic Arts accounts</title><link>https://news.ycombinator.com/item?id=42052143</link><description>
&lt;![CDATA[
&lt;p&gt;856 points points by mooreds on 2024-11-05T15:18:34 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website article discusses the issue of EA (Electronic Arts) account takeover and provides tips on how users can protect their accounts from being compromised. It explains the methods used by cybercriminals to gain unauthorized access to accounts and suggests security measures such as enabling two-factor authentication, using unique and strong passwords, and staying vigilant against phishing attempts. The article aims to educate and raise awareness about account security to help users safeguard their accounts from potential breaches.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Ea loves using generic systems across all their games. When poking around at Madden I found they have a common backend called blaze that has generic web and tcp endpoints. We built out a tool to call these endpoints (having to upload xml) and only later found out that every time we made the call it was crashing their servers but since we were grabbing a new server each request we were crashing all of their madden servers one by one. They ended up building an API to discourage people poking around&lt;/li&gt;&lt;li&gt;    So, like any sane person would, I overnighted an Xbox, installed Battlefield 2042, and waited for the moment of truth...
     
    I was in!

I love hackers &lt;3&lt;/li&gt;&lt;li&gt;I enjoyed the detailed explanation of how he moved from point to point. I imagine it wasn't as straightforward as is laid out in a blog postIt would be interesting to see what I imagine to be the reams of notes from one of these to show how much time and effort it takes to perform this kind of attack.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:55:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42052143</guid></item><item><title>2. Hacker Fab</title><link>https://news.ycombinator.com/item?id=42051968</link><description>
&lt;![CDATA[
&lt;p&gt;426 points points by ipnon on 2024-11-05T14:59:15 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website provides information about Hacker-Fab Space, a collaborative workspace aimed at fostering creativity, learning, and innovation within the hacker community. It offers tools, resources, and opportunities for individuals to experiment, share knowledge, and engage in hands-on projects. The space encourages networking and skill development through workshops, events, and open project nights, creating a supportive environment for makers and hackers to collaborate and grow.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;When we saw a rise in 3d printing, I was very hopeful that a hobbyist movement towards fabricating large-feature ICs would soon arise. Nobody's doing 4nm fabrication in their garage, I reasoned, but surely we could get to ~10um.As I read more about the dark art of IC fabrication, though, I realized that even this was a faint dream. I had imagined a world of lasers carving troughs, and print heads carefully placing down the lines and doping the silicon, an elegant symphony of modern technology.But the real world is much messier -- every stage involves dangerous and toxic chemicals, processes that are spoiled by a spec of dust in the wrong place, either causing a cascade of reagent failures or a physical impediment to correctness; distressingly analog and oh so messy and built by trial and error and refined by domain experts in ways that are intensely hard to replicate because all the same lessons need to be learned again each time.I'm glad to see the work being done here for hobbyist fabrication, but barring huge leaps and bounds, the gap between the neat lines in Magic and the shiny silicon discs is a vast chasm owned by the material scientists, not the electrical engineers or the software engineers.&lt;/li&gt;&lt;li&gt;Nobody seems to have mentioned electron beam lithography. Hobbyists have done that.[1]E-beam lithography has been used since the 1970s. It's slow; it might take a day to make a CPU. That's why it's not used as a production process. But as a prototype process, it works fine. There are a few hobbyists doing this.[1]E-beam systems are basically scanning electron microscopes with more power. There's a vacuum chamber, means for focusing and steering an electron beam similar to what's inside a CRT, and control equipment. It's all computer-controlled, of course.This has many advantages. Software can correct for nonlinearities in the scanning. The machine can inspect what it's written by scanning at low power.You still have to coat and etch; it's not a dry process. The beam just exposes photoresist.The equipment is the size of a desk. Here's a machine at CMU.[2] Many universities have such machines.[1] https://hackaday.com/2024/08/06/creating-1%c2%b5m-features-t...[2] https://nanofab.ece.cmu.edu/facilities-equipment/fei-sirion....&lt;/li&gt;&lt;li&gt;While I'm sympathetic to democratizing access to simple fabrication technology, I have serious misgivings about hobbyists getting involved.There's the obvious stuff: you can't avoid HF, and it's nasty stuff. You can die. But that's not what I'm the most worried about; people can make smart decisions to reduce risk, and ultimately people can make their own decisions about their risk tolerance.What I'm worried about is the SF6 for the RIE. Kg for kg, that stuff has a global warming potential of more than 24,000 TIMES the warming potential of CO2. If it's all broken down in the plasma chamber, or there's exhaust scrubbers involved like you'd have at an industrial fab, then it's no issue.But hobbyists are going to be spilling and purging a bunch of unmodified SF6. It's kind of an ecological catastrophe. Some things are better not done at home.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051968</guid></item><item><title>3. Failure analysis of the Arecibo 305 meter telescope collapse</title><link>https://news.ycombinator.com/item?id=42051368</link><description>
&lt;![CDATA[
&lt;p&gt;227 points points by mhb on 2024-11-05T13:37:42 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the health effects of cannabis and cannabinoids, examining the potential therapeutic benefits and risks associated with their use. It explores the role of cannabis-derived compounds in addressing medical conditions such as chronic pain, cancer-related symptoms, and multiple sclerosis. The report addresses various delivery methods and formulations of cannabinoids, highlighting the need for continued research to better understand their effects on health and to inform medical practice and policy decisions.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;In the summary they state:All the reported experimental zinc electroplasticity (EP) data were developed at current densities orders of magnitude higher than those possibly present in the Arecibo Telescope but measured in laboratory experimental periods that were orders of magnitude shorter than the telescope's socket zinc service.There are no reported experimental data concerning low-current, long-term EP, which the committee has lumped together under the term "LEP", affecting zinc's creep mechanisms over decades.The timing and patterns of the Arecibo Telescope's socket failures make the LEP hypothesis the only one that the committee could find that could potentially explain the failure patterns observed.Accelerated aging is, as far as I know, pretty much standard in the industry. Nobody can wait 20 years to find out if a certain material is good enough or not.However, the real failure seems to be the lack of urgency when they signs started to show up:Upon reflection, the unusually large and progressive cable pullouts of key structural cables that could be seen during visual inspection several months and years before the M4N failure should have raised the highest alarm level, requiring urgent action. The lack of documented concern from the contracted engineers about the inconsequentiality of the cable pullouts or the safety factors between Hurricane Maria in 2017 and the failure is alarming.&lt;/li&gt;&lt;li&gt;Even if I am not a radio astronomer, this instrument was unique in nature and still in use for very specific observations and until the very end of its operation was able to deliver data. It is disheartening to learn that it was indeed due to gross maintenance negligence (as assumed originally by many) that the final fatal failure occurred, when potentially the structure could have been salvaged.&lt;/li&gt;&lt;li&gt;Practical Engineering on YouTube has an episode covering the collapse of this structure[1]. It's very good and worth a watch.[1] https://youtu.be/3oBCtTv6yOw&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051368</guid></item><item><title>4. AMD outsells Intel in the datacenter space</title><link>https://news.ycombinator.com/item?id=42054449</link><description>
&lt;![CDATA[
&lt;p&gt;458 points points by baal80spam on 2024-11-05T19:27:15 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The article discusses how AMD has outsold Intel in the data center space for the first time ever, marking a significant milestone in the competitive CPU market. The shift in market share is attributed to AMD's recent success and growing popularity in delivering high-performance processors designed for data center use, challenging Intel's long-standing dominance in the industry.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Oh my, allow me to reminisce.When the Intel 80386-33 came out we thought it was the pinnacle of CPUs, running our Novell servers!   We now had a justification to switch from arcnet to token ring.  Our servers could push things way faster!Then, in the middle 1991, the AMD 80386-40 CPU came out.  Mind completely blown!  We ordered some (I think) Twinhead motherboards. They were so fast we could only use Hercules mono cards in them; all other video cards were fried.  16Mb token ring was out, so some of my clients moved to it with the fantastic CPU.I have seen some closet-servers running Novell NetWare 3.14 (?) with that AMD CPU in the late '90s.  There was a QUIC tape &amp; tape drive in the machine that was never changed for maybe a decade?  The machine never went down (or properly backed up).&lt;/li&gt;&lt;li&gt;Damn, first Intel missed out on Mobile, then it fumbled AI, and now it's being seriously challenged on its home turf. Pat has his work cut out for him.&lt;/li&gt;&lt;li&gt;Surprising it took so long given how dominant the EPYC CPUs were for years.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054449</guid></item><item><title>5. Machines of Loving Grace</title><link>https://news.ycombinator.com/item?id=42045509</link><description>
&lt;![CDATA[
&lt;p&gt;230 points points by greenie_beans on 2024-11-04T20:05:19 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the rise of artificial intelligence and its impact on the future of work, exploring the concept of 'machines of loving grace' - a term that refers to the possibility of advanced technology enhancing human potential and well-being. It delves into the potential benefits and challenges that AI and automation may bring to society, offering thought-provoking insights on how we can navigate this transformative technological landscape.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;&gt; Yet, I am shocked when AI does not stop Outlook Messenger from bursting confetti across my desktop in response to the Congratulations reply I receive when HR misreads my email about both adding and removing our late son from my health insurance.Echoes of Facebook showing people “memories” (photos) of their deceased children on their bday. This is one of the saddest stories I’ve read in a bit.&lt;/li&gt;&lt;li&gt;Adam Curtis made a fantastic documentary on the darker side of our relationship with technology. I don't agree with all of his points, but it's still a great watch.From Wikipedia: Curtis argues that computers have failed to liberate humanity, and instead have "distorted and simplified our view of the world around us".https://en.wikipedia.org/wiki/All_Watched_Over_by_Machines_o...&lt;/li&gt;&lt;li&gt;brutal story. for those who were equally confused this post seems to have the same title as but is unrelated to Dario Amodei's recent https://darioamodei.com/machines-of-loving-grace - is perhaps a nice/bittersweet reality check on how our designs often fall short of our ambitions.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42045509</guid></item><item><title>6. Show HN: rallyup – Lightweight Wake-on-LAN Scheduler</title><link>https://news.ycombinator.com/item?id=42050862</link><description>
&lt;![CDATA[
&lt;p&gt;136 points points by darwindarak on 2024-11-05T12:04:14 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This page provides information about a tool called RallyUp developed by Darwin Darak, designed for performance measurement and data recording in the context of rally racing. It outlines the features of the tool, such as real-time speed and distance tracking, as well as elevation profiles and split times, to assist rally drivers in analyzing and improving their performance. Users can find the code, contributing guidelines, and project updates on this GitHub page.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Very nice, just FYI for home assistant fans: WoL is also supported in there :)&lt;/li&gt;&lt;li&gt;Isn't it bad design in the first place if you require "right order" of boot up? What if some, but not all, servers crash and reboot? How do you ensure the correct order in that case?&lt;/li&gt;&lt;li&gt;One thing that might be useful is to allow a given server in the chain to fail. For example, if you had a Proxmox (or other hypervisor) cluster, in the event that a single node fails to come up, you'd probably want everything else to still boot. Or maybe it would be easier if there was a separate category for VM vs. hypervisor?Either way, neat project, and thank you for sharing.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42050862</guid></item><item><title>7. Facebook building subsea cable that will encompass the world</title><link>https://news.ycombinator.com/item?id=42041581</link><description>
&lt;![CDATA[
&lt;p&gt;269 points points by giuliomagnifico on 2024-11-04T14:00:59 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses Facebook's plans to construct a new subsea cable project called "Bifrost" that will connect the United States, Europe, Africa, and the Middle East, enhancing global internet connectivity. The construction of this cable aims to address the increasing demand for data transmission capacity and speed, with Facebook collaborating with various partners to ensure successful deployment and operation of the infrastructure.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;FYI, this is NOT the cable Facebook is planning to build, this is the dream cable of a submarine cable… enthusiast? From LinkedIn: “To be clear, this is not Meta's plan or map. This is Ver "T" and T stands for Tagare. It's what I think is going to happen to this cable if I was designing it. This is my wish list.”https://www.linkedin.com/pulse/map-metas-w-cable-sunil-tagar...&lt;/li&gt;&lt;li&gt;Highly recommend an article by The Verge on how these things are repaired and maintained.https://www.theverge.com/c/24070570/internet-cables-undersea...&lt;/li&gt;&lt;li&gt;So do we sometimes lay cables on top of other cables down there?What governments do you have to go to to get approval to do this? Could I just run a string across the Atlantic Ocean?If we do lay cables on top of other cables how high do they get stacked? Are there challenges to bring the lower cables back up? Does that happen? Or do we just keep them down there forever basically and upgrade the hardware at the terminal?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42041581</guid></item><item><title>8. Blog Writing for Developers (2023)</title><link>https://news.ycombinator.com/item?id=42045477</link><description>
&lt;![CDATA[
&lt;p&gt;243 points points by mooreds on 2024-11-04T20:01:57 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website article provides guidance and tips on blog writing specifically tailored for developers. It covers topics such as finding inspiration for blog content, structuring posts effectively, balancing technical details with engaging writing, and promoting blog posts to reach a wider audience. Overall, it aims to help developers enhance their writing skills and create compelling and useful content for their audience.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I’ve been writing a technical blog for over 20 years, and I believe that each blog post helps me think more deeply, examining every source and related code carefully. This process has been incredibly valuable to me, and even in the LLM era of 2024, I still enjoy blogging. Often, the primary user of my blog is myself; I go back to my past entries to help guide further research and exploration.I once heard a senior developer say, 'I’m not shy to admit that after I finish a blog post, I’m at ease to forget about it—because I know I can always look it up again.&lt;/li&gt;&lt;li&gt;The author suggests everyone should watch the Larry McEnerney lecture but he seems to have missed a pretty important point from that lecture.A really big point Larry tries to make during his lecture is that there are 2 types of writing. One you do for yourself (to help clear your ideas) and the other and the other one is designed to valuable to the reader.And he is pretty obsessed with the idea of writing valuable text. He even says that if your text isn't valuable there is no point in making it persuasive, organized or clear.For me this was a pretty interesting revelation. For most of my life I had this idea that the quality of the content and the quality of the writing were tightly related. And this idea made me believe that if you have good content, good writing should follow naturally.After watching this lecture I realized that content and writing are separated axis, and you can definitely have one without the other. LLMs are pretty good at writing without content, for example.&lt;/li&gt;&lt;li&gt;My biggest challenge with writing blogs/newsletters is the fear of publishing, not getting it "perfect", or being horribly wrong about whatever I'm writing about.To get over this I just made simple personal blog/site using GH pages/jekyll/markup that doesn't have 1. A marketing version of a "publish" function and 2. the posts are perpetually in DRAFT.Basically there is no 'done' which leaves me more comfortable in putting my thoughts on the internet instead of leaving them in my head. I can keep going back to the ideas and refining them.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42045477</guid></item><item><title>9. Every boring problem found in eBPF (2022)</title><link>https://news.ycombinator.com/item?id=42018195</link><description>
&lt;![CDATA[
&lt;p&gt;158 points points by udev4096 on 2024-11-01T15:50:56 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website showcases a series of photographs with captions that humorously depict common workplace frustrations and scenarios, such as dealing with difficult colleagues, technology malfunctions, and mundane tasks. The images aim to provide a lighthearted perspective on office life and evoke solidarity among individuals who can relate to these humorous situations.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;BPF recently got published as an RFC[1], posted here[2] today and earlier here[3][4].[1]: https://datatracker.ietf.org/doc/html/rfc9669[2]: https://news.ycombinator.com/item?id=42051950[3]: https://news.ycombinator.com/item?id=42024377[4]: https://news.ycombinator.com/item?id=42038371&lt;/li&gt;&lt;li&gt;By the way, this article is published as part of the tmp.0ut zine, and the CFP for the next issue is currently open: https://tmpout.sh/blog/vol4-cfp.html&lt;/li&gt;&lt;li&gt;I'm usually against separate "mobile versions" of websites but wow, this needs one.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42018195</guid></item><item><title>10. Show HN: I wrote an open-source browser alternative for Computer Use for any LLM</title><link>https://news.ycombinator.com/item?id=42052432</link><description>
&lt;![CDATA[
&lt;p&gt;169 points points by gregpr07 on 2024-11-05T15:51:43 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The GitHub repository contains code for a web browser usage analysis project. It includes tools for collecting and analyzing data on browser usage, focusing on tracking the popularity of different web browsers over time. The project aims to provide insights into trends and patterns related to browser usage on the internet.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Is it decided then that screenshots are better input for LLMs than HTML, or is that still an active area of investigation? I see that y'all elected for a mostly screenshot-based approach here, wondering if that was based on evidence or just a working theory.&lt;/li&gt;&lt;li&gt;Awesome project, starred! Here are some other projects for agentic browser interactions:* Cerebellum (Typescript): https://github.com/theredsix/cerebellum* Skyvern: https://github.com/Skyvern-AI/skyvernDisclaimer: I am the author of Cerebellum&lt;/li&gt;&lt;li&gt;It's impressive, but to me it seems like the saddest development experience...    agent = Agent(
        task='Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour.',
        llm=ChatOpenAI(model='gpt-4o'),
    )
    
    await agent.run()

Passing prompts to a LLM agent... waiting for the black box to run and do something...&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42052432</guid></item><item><title>11. Show HN: Whirlwind – Async concurrent hashmap for Rust</title><link>https://news.ycombinator.com/item?id=42053747</link><description>
&lt;![CDATA[
&lt;p&gt;135 points points by willothy on 2024-11-05T18:02:18 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website contains a project called "Whirlwind," created by the Fortress Build team. It focuses on providing developers with a framework for building fast and scalable API-driven web applications using Python. The project includes features such as database integration, seamless API development, and performance optimization. Additionally, it offers documentation and guidance for developers interested in using Whirlwind for their projects.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I don't think I'd recommend using this in production. The benchmarks look good, but by immediately waking the waker[0], you've effectively created a spin-lock. They may work in some very specific circumstances, but they will most likely in practice be more costly to your scheduler (which likely uses locks btw) than just using locks[0]: https://github.com/fortress-build/whirlwind/blob/0e4ae5a2aba...&lt;/li&gt;&lt;li&gt;One thing which wasn’t obvious to me from the benchmark: What’s the key distribution? A sharded map will probably have great performance on uniform keys, but in my experience it’s far more common to have power law distribution in real life scenarios.It would be good to see a benchmark where it only touches a _single_ key. If Whirlwind is still fast than the others I would be far more convinced to use it unconditionally.EDIT: I also see that you're benchmarking on a M3 Max. Note that this has 6 performance cores and 6 efficiency cores. This means that if you're running at &lt;6 cores it will most likely start out running it at the efficiency core. From my experience it's quite important to do warmup phases in order to get stable results at low thread count. And even then I find it hard to reason about the results since you're running in mixed set of cores…&lt;/li&gt;&lt;li&gt;&gt; Just as dashmap is a replacement for std::sync::RwLock&lt;HashMap&gt;, whirlwind aims to be a replacement for tokio::sync::RwLock&lt;HashMap&gt;.I'm curious about the practical benefits of handling a HashMap with an async interface. My long-standing understanding is that `tokio::sync::RwLock&lt;HashMap&gt;` is only useful when you'd want to hold the lock guard across another `await` operation; but when the lock guard is not held across an await, it is always preferable to use the synchronous version.This would lead me to assume that same applies for dashmap--it should be sufficient for async use cases and doesn't need an async API unless we expect to be blocked, but the benchmarks indicate that whirlwind outperforms dashmap in various situations. Do you have a sense of where this blocking occurs in dashmap?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42053747</guid></item><item><title>12. Pagination widows, or, why I'm embarrassed about my eBook (2023)</title><link>https://news.ycombinator.com/item?id=42047677</link><description>
&lt;![CDATA[
&lt;p&gt;217 points points by OuterVale on 2024-11-05T00:58:11 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This blog discusses the concept of responsive web design, emphasizing the importance of designing websites that adapt to different screen sizes and devices. The author highlights the significance of creating flexible layouts and using media queries to enhance user experience across various platforms. The blog provides examples and practical tips for implementing responsive design in web development projects.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;While everyone here seems to talk about the epub angle to the story, there's also simply the deeper story here, that "the web's" handling of paged media and the CSS paged media specs (to which his epub problem is related) is a never ending shitshow. Not only for epubs, for everybody who actually wants to print to real paper, too, ideally with a working cross browser solution.Mistake is largely not in the specs, but in the lack of support for them. Page breaking controls, weirdly breaking tables, lack of access to area outside the page box to influence headers/footers without weird hacks etc. etc. For printing, the 1990ies never ended.This leads to the bizarre situation where basically everyone who has semi complex printing needs in web applications will create PDF and then print that - and for creating those PDFs, often HTML to PDF conversion is used, just with actually implemented CSS for paged media. Which again proves that the spec is at least 99% there, if somebody would just kindly implement it in a browser, too.Won't be more complex than having the latest WebGL whatever thing in your browser engine ;-)&lt;/li&gt;&lt;li&gt;Another frustrating thing with ebooks is that you can't get them in PDF format any more. So much time is spent making a nicely fomatted hardcopy edition, then the ebook is only available as a terribly auto-converted epub that throws away all the layout and style. Particularly cookbooks, as well as anything technical, I just can't stand how lazy, ugly, and difficult to read the epubs are. All the tooling already exists to produce PDFs identical to the print version, but no, we can't have those.&lt;/li&gt;&lt;li&gt;Not to mention the ugly/unusable rendering of mathematical formulate in ebooks on my Kindle, which is gatherig dust.Layouting is an art and a craft, and the fact that it's automated by people who
lack the specialized knowledge, or for whom it is not a priority (quarter century old bug reports, really?) suggests that in 2025, you should still avoid ebooks if you care about quality and aesthetics.This is a shame because e-ink is just becoming usable. Anyhow, long live the paper book!&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42047677</guid></item><item><title>13. What Every Developer Should Know About GPU Computing (2023)</title><link>https://news.ycombinator.com/item?id=42042016</link><description>
&lt;![CDATA[
&lt;p&gt;175 points points by mooreds on 2024-11-04T14:49:44 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses how Graphical Processing Units (GPUs) play a crucial role in accelerating computations for various tasks like machine learning, simulations, and data processing. It explains the benefits of using GPUs, such as parallel processing power, over traditional Central Processing Units (CPUs). The article highlights how GPUs are optimized for handling multiple tasks simultaneously, making them efficient for handling complex computations and improving overall system performance in applications requiring high computational power.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Unrelated but I absolutely love this reply from the previous time this was posted and someone complained about the line "most programmmers ...":&gt; Try this on: "A non-trivial number of Computer Scientists, Computer Engineers, Electrical Engineers, and hobbyists have ..."&gt; Took some philosophy courses for fun in college. I developed a reading skill there that lets me forgive certain statements by improving them instead of dismissing them. My brain now automatically translates over-generalizations and even outright falsehoods into rationally-nearby true statements. As the argument unfolds, those ideas are reconfigured until the entire piece can be evaluated as logically coherent.&gt; The upshot is that any time I read a crappy article, I'm left with a new batch of true and false premises or claims about topics I'm interested in. And thus my mental world expands.https://news.ycombinator.com/item?id=37969305&lt;/li&gt;&lt;li&gt;This video is a great explainer too:How do Graphics Cards Work? Exploring GPU Architecture (https://youtu.be/h9Z4oGN89MU?si=EPPO0kny-gN0zLeC)&lt;/li&gt;&lt;li&gt;Makes me consider writing a post on misconceptions of GPU computing, such as requiring the problem to be fully data-parallel.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042016</guid></item><item><title>14. The Roots of Fear: Understanding the Amygdala</title><link>https://news.ycombinator.com/item?id=42042417</link><description>
&lt;![CDATA[
&lt;p&gt;146 points points by birriel on 2024-11-04T15:29:07 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Dreams and fear have an odd and slightly unintuitive relationship. When we are anxious and awake the amygdala is active and norepinephrine (the “fight or flight” neurotransmitter) is high.During REM sleep, surprisingly the amygdala is inactive and norepinephrine is 85% lower than base waking levels (not high anxious levels). So the brain is in a super relaxed state!I wrote a paper on the implications for dream content and interpretation (I’m a psychotherapist in training).If you’re interested you can find the paper here:https://osf.io/preprints/psyarxiv/k6trzAnd it was discussed on HN here:https://news.ycombinator.com/item?id=19143590&lt;/li&gt;&lt;li&gt;I think there are two types of fear mostly, the innate survival animalistic fear and the self-perpetuating fear caused due to misunderstanding. The animalistic fear is present in all and it's not possible to get rid of. When you see a snake or a tiger in front of you, that fear is natural. The response is to jump or run and is so spontaneous, you can't really control it. It's necessary for survival. But I think we are interested in the other fear, the one that is bound to attachment. You see a tiger, you panic, turns out to be a cat, you laugh it off, go away, that fear is not an issue. But if you go about your day thinking, what if that was a tiger? What if I get jumped by tiger this time? Then, you are creating the fear. The fear has no basis, except for it was implanted to you awhile ago. And now you are attaching yourself to it. You are extending it which is the actual problem. Most of us have fears that go back to childhood. If you think back far enough(like the tiger example), question yourself why you are afraid, you know the answers.One more example, I used to be afraid of getting heart-attacks in the past. Even gas passing would make me panic. Have I ever had a heart-attack before? No. How am I so damn sure that I have a heart-attack if I don't even know what it's supposed to feel like? Heart-attack is a bad thing and it shouldn't be happening to me. How is every acid reflux a heart-attack to me now. I have created my own bubble of fear. When though? I sure as hell didn't know what heartattack is when I was born. So it happened when I was able to comprehend what a heart-attack is right? For me, it's due to people around me passing, it's due to reading on Internet about young celebrities dying to strokes, watching movies, etc. It got implanted in me. I don't know a heartattack I just have an idea of it which is not the same thing. Not even remotely related.Fear arises due to misunderstanding. If you trace it far back enough, fear was implanted mostly in the childhood.&lt;/li&gt;&lt;li&gt;https://gwern.net/backstop#hui-nengs-flag -- Evolution as Backstop for Reinforcement Learning -- Hui Neng’s Flag -- the mathematics of positive and negative reinforcementhttps://gwern.net/fiction/batman -- The Gift of the Amygdali -- Sci-Fi, anxiety, pain&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42042417</guid></item><item><title>15. Lisp Query Notation (LQN)</title><link>https://news.ycombinator.com/item?id=42007462</link><description>
&lt;![CDATA[
&lt;p&gt;132 points points by surprisetalk on 2024-10-31T14:46:59 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses a new query notation inspired by Lisp for structuring and querying data, aiming to provide a clearer and more expressive alternative to standard query languages. By utilizing nested lists resembling Lisp code, the query notation enables a versatile approach to defining and querying data relationships, offering increased flexibility in data manipulation and retrieval.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I don't quite understand the images that are included here...Though they're interesting and eye-catching.I feel like they've got something related to the tool... but are they simply for decoration?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42007462</guid></item><item><title>16. State of Python 3.13 performance: Free-threading</title><link>https://news.ycombinator.com/item?id=42051197</link><description>
&lt;![CDATA[
&lt;p&gt;180 points points by art049 on 2024-11-05T13:06:57 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the performance improvements in Python 3.13 and focuses on the benefits of free threading in Python. It highlights how Python's GIL (Global Interpreter Lock) is being addressed in the latest version and how it affects multi-threading. The article explores how these improvements can enhance Python's performance and facilitate better concurrency in Python applications.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I don't really have a dog in this race as I don't use Python much, but this sort of thing always seemed to be of questionable utility to me.Python is never really going to be 'fast' no matter what is done to it because its semantics make most important optimizations impossible, so high performance "python" is actually going to always rely on restricted subsets of the language that don't actually match language's "real" semantics.On the other hand, a lot of these changes to try and speed up the base language are going to be highly disruptive. E.g. disabling the GIL will break tonnes of code, lots of compilation projects involve changes to the ABI, etc.I guess getting loops in Python to run 5-10x faster will still save some people time, but it's also never going to be a replacement for the zoo of specialized python-like compilers because it'll never get to actual high performance territory, and it's not clear that it's worth all the ecosystem churn it might cause.&lt;/li&gt;&lt;li&gt;I'm glad the Python community is focusing more on CPython's performance. Getting speed ups on existing code for free feels great. As much as I hate how slow Python is, I do think its popularity indicates it made the correct tradeoffs in regards to developer ease vs being fast enough.Learning it has only continued to be a huge benefit to my career, as it's used everywhere which underlies how important popularity of a language can be for developers when evaluating languages for career choices&lt;/li&gt;&lt;li&gt;Performance for python3.14t alpha 1 is more like 3.11 in what I've tested. Not good enough if Python doesn't meet your needs, but this comes after 3.12 and 3.13 have both performed worse for me.3.13t doesn't seem to have been meant for any serious use. Bugs in gc and so on are reported, and not all fixes will be backported apparently. And 3.14t still has unavoidable crashes. Just too early.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051197</guid></item><item><title>17. Aldebaran 1959 Spacecraft Concept (2010)</title><link>https://news.ycombinator.com/item?id=42047243</link><description>
&lt;![CDATA[
&lt;p&gt;62 points points by LorenDB on 2024-11-04T23:39:15 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The long Discovery space craft depicted in the latter half of "2001: A Space Odyssey" was derived from the nuclear rocket. It was suggested that the radioactive part of an Orion-style space craft be put far away from the crew compartment.We can probably can thank Fred Ordway (Marshall Spaceflight Center engineer) who Kubrick brought on board as technical consultant back then. (And of course for the look of the ships that are still so iconic over 50 years later I shouldn't leave off Harry Lange.)&lt;/li&gt;&lt;li&gt;Pictures of Orion concepts have been widely distributed for decades, but not this one. Going into space with an air-breathing nuclear bomb powered jet engine. That is truly weird. How fast was it supposed to be going in atmosphere, I wonder. Did it carry reaction mass for vacuum so it could keep going out of the atmosphere?The trouble with nuclear rockets is that although you have plenty of energy, you still need to carry reaction mass - air, or water, or something - and a lot of it. That becomes the limit on delta-V.(The great frustration of rockets: not only do rockets need something to push against, they have to carry it with them.)&lt;/li&gt;&lt;li&gt;Seems small. The proposed Super Orion would lift 8 million tons to orbit. From wikipedia:&gt; The biggest design above is the "super" Orion design; at 8 million tons, it could easily be a city. [...] This extreme design could be built with materials and techniques that could be obtained in 1958 or were anticipated to be available shortly after.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42047243</guid></item><item><title>18. DeepMind debuts watermarks for AI-generated text</title><link>https://news.ycombinator.com/item?id=42051098</link><description>
&lt;![CDATA[
&lt;p&gt;117 points points by ambigious7777 on 2024-11-05T12:50:16 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;These watermarks are not robust to paraphrasing attacks: AUC ROC falls from 0.95 to 0.55 (barely better than guessing) for a 100 token passage.The existing impossibility results imply that these attacks are essentially unavoidable (https://arxiv.org/abs/2311.04378) and not very costly, so this line of inquiry into LLM watermarking seems like a dead end.&lt;/li&gt;&lt;li&gt;This article goes into it a little bit, but an interview with Scott Aaronson goes into some detail about how watermarking works[0].He's a theoretical computer scientist but he was recruited by OpenAI to work on AI safety. He has a very practical view on the matter and is focusing his efforts on leveraging the probabilistic nature of LLMs to provide a digital undetectable watermark. So it nudges certain words to be paired together slightly more than random and you can mathematically derive with some level of certainty whether an output or even a section of an output was generated by the LLM. It's really clever and apparently he has a working prototype in development.Some work arounds he hasn't figured out yet is asking for an output in language X and then translating it into language Y. But those may still be eventually figured out.I think watermarking would be a big step forward to practical AI safety and ideally this method would be adopted by all major LLMs.That part starts around 1 hour 25 min in.&gt; Scott Aaronson: Exactly. In fact, we have a pseudorandom function that maps the N-gram to, let’s say, a real number from zero to one. Let’s say we call that real number ri for each possible choice i of the next token. And then let’s say that GPT has told us that the ith token should be chosen with probability pi.https://axrp.net/episode/2023/04/11/episode-20-reform-ai-ali...&lt;/li&gt;&lt;li&gt;Some comments here point at impossibility results, but after screening hundreds of job applications at work, it's not hard to pick out the LLM writing, even without watermark. My internal LLM detector is now so sensitive that I can tell when my confirmed-human colleagues used an LLM to rephrase something when it's longer than just one sentence. The writing style is just so different.Maybe if you prompt it right, it can do a better job of masking itself, but people don't seem to do that.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051098</guid></item><item><title>19. Netflix Europe offices raided in tax fraud probe</title><link>https://news.ycombinator.com/item?id=42051643</link><description>
&lt;![CDATA[
&lt;p&gt;333 points points by user20180120 on 2024-11-05T14:20:49 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the global initiative by the United Nations to save biodiversity, aiming to halt the extinction crisis and restore ecosystems. The article emphasizes the urgency of action needed to protect the planet's biodiversity and highlights the importance of conserving nature to ensure a sustainable future for all life on Earth.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I wonder how these "office raids" would work for remote first companies that don't have much of an office presence and with little or no physical documents and everything being stored in the cloud somewhere.&lt;/li&gt;&lt;li&gt;Wel,But things are changing. It seems... These are the developments in The Netherlands. Most of it somewhere over the horizon. Interested to know if other countries with similar tax evasion rules change their rules?It's in dutch so use your popular translation tool for these links:- https://www.rijksoverheid.nl/documenten/brochures/2023/10/11...
- https://theses.ubn.ru.nl/server/api/core/bitstreams/a384a151...
- https://open.overheid.nl/documenten/44e45809-c66e-4378-9fc8-...
- https://www.nu.nl/economie/6286473/nederland-nummer-een-bij-...&lt;/li&gt;&lt;li&gt;Sounds like the tech companies won't be expanding outside of Ireland for a while ....&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051643</guid></item><item><title>20. Nvidia and its partners built a system to bypass U.S. export restrictions</title><link>https://news.ycombinator.com/item?id=42048065</link><description>
&lt;![CDATA[
&lt;p&gt;324 points points by mgh2 on 2024-11-05T02:20:46 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The tweet posted by user @kakashiii111 discusses the importance of self-assessment and personal growth. It emphasizes the need to reflect on our actions, behaviors, and thoughts in order to become better individuals. The tweet encourages self-improvement and underscores the significance of learning from past experiences to evolve and make positive changes in our lives.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Nvidia is obviously a US company, but the chips themselves are manufactured in Taiwan.And of course China sees Taiwan as a rogue province, at at least treats invasion there as "on the table". While the US may decide to actively support Taiwan, at the very least a war over that will disrupt production.Should Taiwan fall, and China choose to ban exports from there to the US, then the fun and games would really start.As long as back-channels exist to supply the chips to China, then there's less incentive for China to control Taiwan. The ban exists as good politics (we don't ship to our adversaries) while the back-channels ensure they aren't forced into a position no-one wants them to be in.&lt;/li&gt;&lt;li&gt;Article: https://news.ycombinator.com/item?id=42048033&lt;/li&gt;&lt;li&gt;We will see what happens - but given nvidias growth and how heavy they are now weighted I’m skeptical there will be any enforcement until well after the elections.Neither party wants to look “bad for the economy”, even if the people harmed isn’t of significant size.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42048065</guid></item><item><title>21. Low-poly image generation using evolutionary algorithms in Ruby (2023)</title><link>https://news.ycombinator.com/item?id=42047320</link><description>
&lt;![CDATA[
&lt;p&gt;113 points points by thomascountz on 2024-11-04T23:50:49 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses creating low-poly images using Delaunay triangulation and the Voronoi diagram algorithms. It provides an in-depth tutorial on generating these geometric artworks with Python, manipulating colors, and incorporating noise for a unique effect. The article offers step-by-step instructions and code examples to help readers understand and implement the process of low-poly image generation.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Great write-up, I like the fitness graphs a lot.I did something similar in Julia a while ago in an attempt to learn the language: https://www.basjacobs.com/post/2020-11-18-image-triangulatio...&lt;/li&gt;&lt;li&gt;Camme for the evolutionary stuff (wrote mh PhD on it).Left having leaned that you can switch Tail Call Optimisation on or off in Ruby code.&lt;/li&gt;&lt;li&gt;I made some image generation with CLIP and Evolutionary algorithms not so long ago[1] and the results had a bit more life than I was expecting. It is still a contested area of research and you have some cool stuff like CLIPDraw[2] where they use gradient decent to approximate a vector to the embeddings of CLIP.[1] https://snats.xyz/pages/articles/optimizing_images.html
[2] https://arxiv.org/pdf/2106.14843&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42047320</guid></item><item><title>22. World’s oldest tree? Genetic analysis traces evolution of iconic Pando forest</title><link>https://news.ycombinator.com/item?id=42046953</link><description>
&lt;![CDATA[
&lt;p&gt;116 points points by pseudolus on 2024-11-04T22:58:50 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website provides information on the challenges facing global aquaculture due to climate change, including impacts on fish health and production. It discusses how rising water temperatures can lead to disease outbreaks and stresses the need for innovative solutions to ensure sustainable aquaculture practices in the face of climate-related challenges.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;If you're ever in central Utah you should make the trip to see Pando, it grows beside Fish Lake which is teeming with life, and surrounded by beautiful hills and mountains that make for great campsite views. The lake is full of landlocked kokanee salmon that never see an ocean in their lifetime.&lt;/li&gt;&lt;li&gt;TIL Pando is not just an especially large quaking aspen, but rather a triploid mutant that can reproduce only asexually.&lt;/li&gt;&lt;li&gt;The fact that Pando is a single organism is so confusing to me. I’m guessing there are more forests like Pando that are also a single organism? Is this something unique to this particular species?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42046953</guid></item><item><title>23. Netnews: The Origin Story [pdf]</title><link>https://news.ycombinator.com/item?id=42048021</link><description>
&lt;![CDATA[
&lt;p&gt;60 points points by tkhattra on 2024-11-05T02:09:16 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The document provides a historical overview of Usenet, a popular early online discussion system that emerged in the 1980s. It discusses the growth of Usenet from a small community of users to a global network of servers exchanging messages and files. The paper highlights key milestones in Usenet's development and the challenges it faced as it grew in popularity, such as spam and scalability issues. Additionally, it delves into the social aspects of Usenet, including its impact on online culture and communication.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;There is a probably-'80s document that I would like to find again, written I think by some university as an ‘introduction to Usenet’ for students. It had a section I particularly remember about focusing discussions on the topic of a newsgroup rather than on the newsgroup. Anyone recognize this?(Today is Tuesday the 11389th of September 1993.)&lt;/li&gt;&lt;li&gt;the section "conclusion" is a good summary of the article, of major usenet design decisions and also of it's shortcomings.It seems it has ~~degenerated~~ evolved to a niche file sharing platform for obscure contents?I remember the days when comp.os.linux.announce was a good place to keep a pulse on what's cooking in terms of fun FOSS software.&lt;/li&gt;&lt;li&gt;"Personally owned computers—microcomputers, in the terminology of the day—were rare and were the domain of a few
hobbyists. Most were very small and generally lacked hard drives;
bulk storage was via audio cassette tape or (for the lucky few) on
floppy disks with a capacity of about 1.5 megabytes."1.5 megabytes?  Um, no.  3.5" floppies weren't out yet in 1979, and they were 1.44MB.  5.25" double-sided high-density floppies were 1.2MB, and I'm not sure they were were out yet either.  I was using 8" floppies in 1979, and IIRC they were about 250KB&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42048021</guid></item><item><title>24. Why Companies Are Ditching the Cloud: The Rise of Cloud Repatriation</title><link>https://news.ycombinator.com/item?id=42054813</link><description>
&lt;![CDATA[
&lt;p&gt;203 points points by panrobo on 2024-11-05T20:19:13 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The article explores the trend of companies moving away from the cloud and opting for cloud repatriation, where they bring data and applications back in-house due to cost savings, security concerns, and performance issues. It discusses the factors driving this shift and presents various scenarios where companies are reconsidering their cloud strategies to better align with their specific business needs.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I don't know that 37Signals counts as a "major enterprise". Their Cloud exodus can't have been more than a few dozen servers, right?Meanwhile AWS is growing at 20%/year, Azure at 33% and GCP at 35%. That doesn't seem compatible with any kind of major cloud repatriation trend.&lt;/li&gt;&lt;li&gt;GEICO is moving away from the cloud because their IT is a joke. They had a horrible on-prem infrastructure, so they moved to the cloud not knowing how, and they made the same mistakes in the cloud as on-prem, plus the usual mistakes every cloud migration runs into. They are moving away from the cloud because their new VP's entire career is focused on running her own hardware. What we know about their new setup is absolutely bonkers (like, K8s-on-OpenStack-on-K8s bonkers). Look to them for what not to do.37signals is like the poster child for NIH syndrome. They keep touting cost savings as the reason for the move, but from what I have gathered, they basically did nothing to save cost in the cloud. It is trivial to save 75% off AWS's list price. They will even walk you through it, they literally want you to save money. That, plus using specific tech in specific ways, allows you to reap major benefits of modern designs while reducing cost more. 37signals didn't seem to want to go that route. But they do love to build their own things, so servers would be a natural thing for them to DIY.Almost every argument against the cloud - cost inefficiency, fear of vendor lock-in, etc - has easy solutions that make the whole thing extremely cost competitive, if not a way better value, than trying to become your own cloud hosting provider. It's very hard to estimate the real world costs, both known and unknown, of DIY hosting (specifically the expertise, or lack of it, and the impacts from doing it wrong, which is very likely to happen if cloud hosting isn't your core business). But it's a 100% guarantee that you will never do it better than AWS.AI is the only place I could reasonably imagine somebody having an on-prem advantage. At the moment, we still live in a world where that hardware isn't a commodity in the way every other server is. So you might just be faster to deploy, or cheaper to buy, with AI gear. Storage is similar but not nearly as tight a market. But that will change eventually once either the hype bubble bursts, or there's more gear for cheaper for the cloud providers to sell.&lt;/li&gt;&lt;li&gt;It's a short simple post that comes down to this:&gt; Weekly explains that “just running legacy applications in the cloud is prohibitively expensive,” highlighting how lift-and-shift approaches often fail to deliver expected benefits.Yes, if you have a mature business without active development at a scale where compute/storage costs is a substantial accounting line item, then it makes sense to run on hardware that doesn't have the flexibility and cost of the cloud.There is an in-between that makes much more sense for most though. Running on provisioned bare metal. Lots of providers offer this as a better performance/price option where you don't have to deal with provisioning hardware but do everything else from the OS+maintenance and up.At one company we used large bare-metal machine instances provisioned for stable parts of the application architecture (e.g. database and webapp instances) and the cloud for new development where it made sense to leverage capabilities, e.g. DynamoDB with cross-region replication.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054813</guid></item><item><title>25. Wooden satellite heads to space in Mars exploration test</title><link>https://news.ycombinator.com/item?id=42051687</link><description>
&lt;![CDATA[
&lt;p&gt;97 points points by austinallegro on 2024-11-05T14:26:42 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The world's first wooden satellite designed to test the durability of wood in space is scheduled to be launched as part of a Mars exploration project. The satellite, named WISA Woodsat, aims to assess the potential for sustainable materials in space missions. This innovative approach could provide valuable data on how wood behaves in the harsh conditions of space and its viability for future space exploration missions.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I wasn’t sure what the article meant by “no screws or glue”, when the photograph appears to have visible screws. But closer images show that these are apparently some sort of rivet?I found a (Japanese-language-only) news piece that shows some of the crafting and assembly of the satellite, and the box body certainly holds together by itself, via some beautifully intricate joinery:https://www.youtube.com/watch?v=A_F-NzzC7RA&lt;/li&gt;&lt;li&gt;I'm confused by this statement in the article:&lt;&lt; LignoSat is made of honoki, a kind of magnolia tree native to Japan, and has been made using a traditional Japanese technique without screws or glue. &gt;&gt;From photos I've seen while searching for more information, it does appear that there's a wooden core structure that is joined without fasteners. But it's then given a metal exoskeleton and what certainly appears to be metal fasteners.I'd like to understand whether the goal is to create satellites without metal, as the article seemed to imply.&lt;/li&gt;&lt;li&gt;I accidentally visited this from a browser with no adblocker and outbrain clickbait has become comically weird. I was shown what appears to be AI generated video clips of a bear walking through a children's hospital ward, presented as a story about something that happened in my area (Ireland has no bears). I refreshed and was shown the same story but this time it was a wolf. This was side by side with the usual midjourney images as dating site profiles, and weird fabricated medical stuff. They really have gone off the deep end.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051687</guid></item><item><title>26. The Eternal Mainframe (2013)</title><link>https://news.ycombinator.com/item?id=42055556</link><description>
&lt;![CDATA[
&lt;p&gt;72 points points by w3ll_w3ll_w3ll on 2024-11-05T22:00:05 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website explores the concept of a hypothetical eternal mainframe computer, discussing its potential implications on society and the limitations of current technology. It delves into the idea of a computer system continuously evolving and improving itself, leading to ethical considerations, philosophical questions, and speculations about the future of artificial intelligence and human-computer interaction.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;At least in my experience, when I've heard that the "mainframe is going to die", it's specifically referencing the IBM ecosystem - COBOL and friends.To me it looks like the author is grasping for straws when saying "well, a server rack is just like a mainframe, so the mainframe is not dying!".To me it's the opposite: yes, a server rack is just like a mainframe. That's why the mainframe is dying - a bunch of servers can do the same work much more cheaply.&lt;/li&gt;&lt;li&gt;Great article reflecting on who controls computational resources - the user or the company.I want to respond to one point mentioned:&gt; Those who continue to do significant work offline will become the exception; meaning they will be an electoral minority. With so much effort being put into web apps, they may even be seen as eccentrics; meaning there may not be much sympathy for their needs in the halls of power.What I find scary is that developers see web apps (and hence the open web platform) as no longer fashionable, and instead focus on developing mobile apps (iOS and Android).There are various services that are only available to mobile users, not PC / web browser users. One I can recall off the top of my head is Snapchat a decade ago. Other examples today include various bike sharing apps, and possibly some banking apps too. Often, the web app and mobile app don't reach feature parity. Often, the company pushes people to download the mobile app and discourages visiting the website (e.g. Reddit).&lt;/li&gt;&lt;li&gt;I think "looks like" is very ephemeral to what being a mainframe IS. it's true that MP systems can look like a single entity, but they are highly asynchronous. The prism architecture meant a single clock state propagating cleanly across the CPU(s) provided a consistent, time managed framework to be all things to all people. (thats how I understand it)A Sun E10000 is to my mind, as close as a mainframe gets in the post-sparc era. The Tandem non-stops had some of it, the final Dec cluster model was getting there but in a distributed async clocked manner.In the end the point of the mainframe was the TPC. The sustained rate it could process edge device request-response sequences inside the bounds of your choices in the CAP theorem. Distributed systems solve the same problem, but with other consequences. It still freaks me out that IBM had so many irons in the fire they had room to do this, AND to make unix work inside this, and manage legacy, and scale out to whole-of-government or SAGE or SABRE or you-name-it.I hated using AIX as a sysadmin from Dec world view btw. I'm not an IBM fanboi. I lived in the competition.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055556</guid></item><item><title>27. Vega's Puzzling Disk</title><link>https://news.ycombinator.com/item?id=42054569</link><description>
&lt;![CDATA[
&lt;p&gt;55 points points by JPLeRouzic on 2024-11-05T19:43:34 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The article notes Vega’s presence in lots of sci-fi. To add one more: Karl Schroeder’s Virga series is placed within the Vega system (not a spoiler, so far as I know.) I’m still reading through the series, but I came across them through a recommendation from Cory Doctorow — which is high praise. What appear to be fun light adventure novels (and they’re very good at that) hide stronger insight and criticism, political especially.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054569</guid></item><item><title>28. Tencent Hunyuan-Large</title><link>https://news.ycombinator.com/item?id=42054186</link><description>
&lt;![CDATA[
&lt;p&gt;142 points points by helloericsf on 2024-11-05T18:52:09 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The Tencent Hunyuan Large-Scale Chinese Word Embedding Dataset is a resource aimed at providing researchers with pre-trained word embeddings for the Chinese language. The dataset includes word embeddings trained on a large corpus of Chinese text to support various natural language processing tasks. Users can access and utilize these word embeddings in their research or applications related to Chinese language processing.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Not open source. Even if we accept model weights as source code, which is highly dubious, this clearly violates clauses 5 and 6 of the Open Source Definition. It discriminates between users (clause 5) by refusing to grant any rights to users in the European Union, and it discriminates between uses (clause 6) by requiring agreement to an Acceptable Use Policy.EDIT: The HN title was changed, which previously made the claim. But as HN user swyx pointed out, Tencent is also claiming this is open source, e.g.: "The currently unveiled Hunyuan-Large (Hunyuan-MoE-A52B) model is the largest open-source Transformer-based MoE model in the industry".&lt;/li&gt;&lt;li&gt;The model meets/beats Llama despite having an order-of-magnitude fewer active parameters (52B vs 405B). Absolutely bonkers. AI is moving so fast with these breakthroughs -- synthetic data, distillation, alt. architectures (e.g. MoE/SSM), LoRA, RAG, curriculum learning, etc.We've come so astonishingly far in like two years. I have no idea what AI will do in another year, and it's thrilling.&lt;/li&gt;&lt;li&gt;&gt; Territory” shall mean the worldwide territory, excluding the territory of the European Union.Anyone have some background on this?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054186</guid></item><item><title>29. Mozilla is eliminating its advocacy division</title><link>https://news.ycombinator.com/item?id=42055979</link><description>
&lt;![CDATA[
&lt;p&gt;219 points points by doener on 2024-11-05T23:04:45 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The Mozilla Foundation has laid off a significant portion of its staff focused on advocacy and global programs, citing budget constraints and the need to refocus on technical development. The organization, known for its Firefox web browser, faces criticism for the decision as it impacts key aspects of its mission to promote an open and accessible internet. Mozilla plans to transition some programs to community-led initiatives and is prioritizing investments in products and technologies rather than non-profit initiatives.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;A lot of people here will react to the advocacy cuts, and the idea that advocacy make up such a large portion of the workforce.30 percent seemed like a lot, but I think it's just 30 percent of the foundation's direct staff. I suspect the corporation employs more people than the foundation? So stuff like development is not included in that count.I do wonder if the cuts are because of anticipation of lower search revenue from Google with tech restricting legislation on the horizon and google's focus pivoting to AI.&lt;/li&gt;&lt;li&gt;A job for advocacy division is to, uhm, advocate for the product and mission.We all know how that has worked out in the last decade or so (down to &lt;3% market share from 14% in 2014 and 31% in 2009, though I wonder about absolute numbers as number of Internet users has gone up).It's fine for Mozilla to recognize this as a failed approach (or team), without dropping their mission altogether.&lt;/li&gt;&lt;li&gt;dupe: https://news.ycombinator.com/item?id=42054867&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055979</guid></item><item><title>30. What if they are all wrong? (2020)</title><link>https://news.ycombinator.com/item?id=42051231</link><description>
&lt;![CDATA[
&lt;p&gt;74 points points by macleginn on 2024-11-05T13:13:17 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website explores the idea of considering different perspectives and possibilities, challenging conventional wisdom or established beliefs. It raises questions about the validity of popular opinions and encourages readers to think critically, fostering curiosity and open-mindedness towards alternative viewpoints.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;As someone not in the field of mathematics, I actually didn't realize there was such an emphasis on attempting to prove famous conjectures correct. I thought the famous conjectures were famous precisely because knowing the veracity of the conjecture (or independence with respect to some formal system) would be a monumental event in any case.I also assumed many mathematicians utilized the strategy of attempting to disprove something as a way to reveal the proof. Sort of like how the best chess players tend to spend most of their thinking time mentally challenging their planned move as opposed to novice chess players who tend to look for reasons confirming why their move will be a good one. Is this not the case?&lt;/li&gt;&lt;li&gt;Any theorem was a conjecture before its formal proof was accepted by the community. Thus the importance of conjectures is a proxy to the importance of theorems: they are proto-theorems.The fact that the human mind is capable of searching for new mathematical theorems specifically here instead of there, is quite interesting. It's as if a skilled mathematician has knowledge that is bigger than math itself.Penrose used this as argument for the special nature of consciousness, wrongly - it probably makes more sense to remember how the way the human mind is not exact and produces errors all the time plays a huge role in a creative process. And luckily we can amend the human mind by social processes that help eliminating errors again.This way, a conjecture can be thought of as a claim to truth in a competitive environment and that would explain why proving the truth is regarded so much higher.&lt;/li&gt;&lt;li&gt;I think this sentiment is coming from the same place as that of people who oppose more "pure" scientific pursuits in general. You can ask "what good does it do me that some guy was able to go to the moon?" or "who cares about theorizing about black holes, they're really far away", but ultimately pursuing these goals is what got us such crucial everyday stuff like GPS. Sure, you may not care about the goal (even though I think they're worthy goals), but you sure as heck benefit from the journey that got us there. Similarly, chasing mathematical conjectures, even the ones that turn out false, sets us off on journeys on which we discover/invent ever more sophisticated and powerful mathematical tools. And these tools have an amazing tendency to give us insight into broader problems, and help us prove other theorems, even if the conjecture we were originally chasing turns out to be false. It is in this way that chasing conjectures gets us closer to the truth, regardless of their own truthiness.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42051231</guid></item><item><title>1. Title drops in movies</title><link>https://news.ycombinator.com/item?id=42056923</link><description>
&lt;![CDATA[
&lt;p&gt;496 points points by gaws on 2024-11-06T02:48:06 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website features a searchable database of movie title drops, where characters say the title of the film within the movie itself. Users can browse through various movies to find instances of title drops, offering a fun and unique way to explore and revisit films.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;While the 1995 Japanese anime series, Neon Genesis Evangelion revolves around human-shaped weapons called "Evangelions", the "Neon Genesis" part of the title is neither part of the original Japanese name, nor its direct translation. The Japanese name is 新世紀エヴァンゲリオン / Shin-seiki evangerion, "Evangelion of a new era/century". The series has other non-direct translations too, and apparently this style was approved of the original creators, but it was always a bit of a mystery whether the gap in the interpretation was intentional or not.However, over two decades later, with the re-boot movie series Rebuild of Evangelion, in the final scenes of the final movie, the protagonist name-drops the words "neon genesis" in appropriate context. I've never grinned as hard in movie theater.&lt;/li&gt;&lt;li&gt;Intentionality matters. "It" should not count as a title drop.  Nor Barbie (or any movie where the title is the characters name). But I understand it would be way more difficult to run the numbers with such a  constraint.  But this is a case where, to me, the results are very much tainted and thus I had to stop reading.  To me this is like when developers run into a hard issue and somehow play a game of semantics with the wording of a ticket to avoid putting together something useful for the user&lt;/li&gt;&lt;li&gt;Including films where the title is a character name makes the data set less interesting. “Barbie title-drops a ton!” yeah ok.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:55:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056923</guid></item><item><title>2. Useful built-in macOS command-line utilities</title><link>https://news.ycombinator.com/item?id=42057431</link><description>
&lt;![CDATA[
&lt;p&gt;733 points points by yen223 on 2024-11-06T05:51:40 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This website provides a comprehensive overview of useful macOS command line utilities for various tasks, including managing processes, networking, file manipulation, and system monitoring. The article covers essential commands and their functionalities, providing insights into how these utilities can enhance productivity and efficiency for users navigating the macOS command line interface.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;A couple more:    afconvert(1) - an audio file format converter, which includes Apple's superior AAC codec from the Core Audio framework

    diskutil(8) - tons of tools for fixed and removable storage

Examples:    afconvert in.wav -o out.m4a -q 127 -s 2 -b 160000 -f m4af -d 'aac '

    mb=300; diskutil eraseVolume APFS myramdisk `hdiutil attach -nomount ram://$((mb*2048))`&lt;/li&gt;&lt;li&gt;I would like to also recommend the app:   hear (macOS speech recognition and dictation via the command line)

See: https://sveinbjorn.org/hear(Uses built-in macOS capabilities for transcription from audio to text.)&lt;/li&gt;&lt;li&gt;Few additions.open -n file.pdf : opens new instance of Preview application which is useful if you want to open the same file twice (for example to look at different pages at once).caffeinate -d : prevents display turning off, useful if you want to look at display without moving mouse.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057431</guid></item><item><title>3. New images of Jupiter</title><link>https://news.ycombinator.com/item?id=42057851</link><description>
&lt;![CDATA[
&lt;p&gt;441 points points by 0xFACEFEED on 2024-11-06T07:30:37 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website provides a platform for processing images captured by the JunoCam instrument aboard NASA's Juno spacecraft on its mission to Jupiter. Users can access and analyze images taken during specific timeframes and mission phases, such as Perijove 66, which occurred between October 1 and November 1, 2024. The site allows for detailed examination and enhancement of these images for scientific research and public engagement.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;These come from Juno, a mission sent in 2011 and orbiting Jupiter since 2016. Must say it wasn't really on my radar anymore, but looking at the timeline on Wikipedia, it's still going around and getting close ("perijove") every month and a week or so, at an ever-increasing longitude https://en.wikipedia.org/wiki/Juno_(spacecraft)#Timeline The planned end of the mission is in about a year. The camera was "included in the payload to facilitate education and public outreach [but] later re-purposed to study the dynamics of Jupiter's clouds"&lt;/li&gt;&lt;li&gt;Juno was something about radar - penetrating the cloud layers to see what was below.In college my son worked on the FFT engine that processed the radar data. He has code circling Jupiter!&lt;/li&gt;&lt;li&gt;Alien feel (and even unsettling at times).I guess we have grown used to this by now, but from the Moon landing pictures, to the Mars rovers and the various asteroid and planetary missions the objects of the Solar system are now vivid, complex and above all, "real" places.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057851</guid></item><item><title>4. Passport Photos</title><link>https://news.ycombinator.com/item?id=42069646</link><description>
&lt;![CDATA[
&lt;p&gt;913 points points by gaws on 2024-11-06T21:23:50 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Max Siedentopf has created a playful and imaginative project that showcases unusual and creative passport photo concepts. The series features a variety of quirky and humorous portraits that defy traditional passport photo norms. Using props, costumes, and unconventional backgrounds, the project aims to transform the mundane task of taking passport photos into a fun and artistic experience. The images serve as a refreshing and entertaining twist on a typically tedious process, encouraging viewers to see passport photos in a new light.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Looking at other art by him, his latest piece Democracy features three figures in voting booths, one with their pants pulled down. Sure feels timely. He wrote a nice blurb with it too, I love it when artists include some of their thoughts in portfolios rather than just the photos alone (though this piece was a sculpture).https://maxsiedentopf.com/democracy/&lt;/li&gt;&lt;li&gt;Oh! Something I took a part in on HN. That's a first. Almost everything there was practical. Highly recommend checking out all of Max's work, beaming with creativity.&lt;/li&gt;&lt;li&gt;It's a lot of "fun" trying to get acceptable photos. Last week I went to my local American Automobile Association (AAA) office to get an International Driver's Permit (IDP). It's just a translation of your license, which is valid for 1 year. I had to take 2 passport-sized photos with me, which I did.But I was told they wouldn't be accepted because I had long hair and a beard in them, but short hair and no beard now. That's absurd, because it's the same photo used in both of my passports, and there's no requirement that you don't alter your appearance from your passport photo. Somehow border guards can crack the code.Amusingly, my California driver's license shows short hair and no beard, but the AAA person wasn't even looking at my CA license at the time. What happens if I grow long hair and a beard before I travel? Was he just trying to upsell me on a $9.99 photo?We had a hell of a time getting the UK passport authorities to accept the photos we sent in for her passport; they recommend getting your photos taken at an "official" UK location where the digital photos are identified by a code you send in. Well, we happened to be traveling through Australia during this timeframe, so we were able to stop at an Australian Post Office, which supposedly had the same "digital" system, but instead of a code to send to the UK authorities, they handed us printed photos and a web link. Thankfully I was able to use the web link to download the photo and upload it to the UK site, where it was approved almost immediately, and the new passport arrived back at our home before we returned from our trip. But there's no user-obvious criteria that was being used to reject the SEVERAL rounds of photos we had sent to the UK earlier.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42069646</guid></item><item><title>5. Trump wins presidency for second time</title><link>https://news.ycombinator.com/item?id=42057647</link><description>
&lt;![CDATA[
&lt;p&gt;1693 points points by koolba on 2024-11-06T06:49:49 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;All: please make sure you're up on the site guidelines before commenting: https://news.ycombinator.com/newsguidelines.html. That means editing out snark, swipes, and flamebait. Or you can simply follow this metarule, which is also in there: "Comments should get more thoughtful and substantive, not less, as a topic gets more divisive."This thread could be worse (ok, it could be a lot worse) but I'm still noticing people breaking the rules. Please follow them instead—it will be a better experience for all of us, including yourself.&lt;/li&gt;&lt;li&gt;It's the economy, stupid:-Inflation is not prices; it is the rate of change in prices.  Low inflation doesn't imply low prices.
-Aggregate statistics don't necessarily explain individual outcomes.The Dems failed on this count massively, and have, for maybe the last 40 years, which is about the amount of time it took for my state to go from national bellwether (As goes Ohio, so goes the nation) to a reliably red state.  This cost one of the most pro-union Senators (Sherrod Brown) his job.&lt;/li&gt;&lt;li&gt;About 20 million votes less than the 2020 election, with about 15 million less for the democrats, and a measely 4 million less for the republicans. Thought that was interesting.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057647</guid></item><item><title>6. Private Cloud Compute Security Guide</title><link>https://news.ycombinator.com/item?id=42062230</link><description>
&lt;![CDATA[
&lt;p&gt;350 points points by djoldman on 2024-11-06T13:48:55 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website provides documentation on Apple's private cloud compute service, detailing the technical aspects and best practices for setting up and maintaining secure private cloud deployments. It offers guidance on securely developing and deploying applications within a private cloud environment, emphasizing protection of data and ensuring compliance with security standards and protocols.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;There's something missing from this discussion.What really matters isn't how secure this is on an absolute scale, or how much one can trust Apple.Rather, we should weigh this against what other cloud providers offer.The status quo for every other provider is: "this data is just lying around on our servers. The only thing preventing a employee from accessing it is that it would be a violation of policy (and might be caught in an internal audit.)" Most providers also carve out several cases where they can look at your data, for support, debugging, or analytics purposes.So even though the punchline of "you still need to trust Apple" is technically true, this is qualitatively different because what would need to occur for Apple to break their promises here is so much more drastic. For other services to leak their data, all it takes is for one employee to do something they shouldn't. For Apple, it would require a deliberate compromise of the entire stack at the hardware level.This is very much harder to pull off, and more difficult to hide, and therefore Apple's security posture is qualitatively better than Google, Meta or Microsoft.If you want to keep your data local and trust no-one, sure, fine, then you don't need to trust anyone else at all. But presuming you (a) are going to use cloud services and (b) you care about privacy, Apple has a compelling value proposition.&lt;/li&gt;&lt;li&gt;Sibling comments point out (and I believe, corrections are welcome) that all that theater is still no protection against Apple themselves, should they want to subvert the system in an organized way. They’re still fully in control. There is, for example, as far as I understand it, still plenty of attack surface for them to run different software than they say they do.What they are doing by this is of course to make any kind of subversion a hell of a lot harder and I welcome that. It serves as a strong signal that they want to protect my data and I welcome that. To me this definitely makes them the most trusted AI vendor at the moment by far.&lt;/li&gt;&lt;li&gt;This is probably the best way to do cloud computation offoading, if one chooses to do it at all.What's desperately missing on the client side is a switch to turn this off. It's really intransparent which Apple Intelligence requests are locally processed and which are sent to the cloud, at the moment.The only sure way to know/prevent it a priori is to... enter flight mode, as far as I can tell?Retroactively, there's a request log in the privacy section of System Preferences, but that's really convoluted to read (due to all of the cryptographic proofs that I have absolutely no tools to verify at the moment, and honestly have no interest in).&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42062230</guid></item><item><title>7. Show HN: SuperSplat – open-source 3D Gaussian Splat Editor</title><link>https://news.ycombinator.com/item?id=42060856</link><description>
&lt;![CDATA[
&lt;p&gt;229 points points by ovenchips on 2024-11-06T12:07:06 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website allows users to access a 3D editor where they can interact with and customize a 3D model of a toy cat. Users can manipulate the model using different tools and features available in the editor, enabling them to experiment with various modifications and view the cat from multiple angles.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;This is neat but Splats are not really mean to be edited in this way.Splats are sort of like byte code, they are the compiled and optimized representation of reflected light as semi-transparent guassians.Or you can think of them as the PDF equivalent of a Google or Word Doc.  All the logic is gone, and you just have final optimized results.Generally when you edit PDFs, the results are not great and you cannot make major edits because the layout won't reflow, etc.So while this is cool, I don't think it will take off unless there is another innovation in terms of either using AI to "reflow" the lighting and surfaces after an edit, or inferring more directly the underlying representations (true surface properties and the light sources.)&lt;/li&gt;&lt;li&gt;I could imagine this as a clean-up tool for splats.  In any case, beautiful interface and the sample model made me smile.  Thanks for sharing.&lt;/li&gt;&lt;li&gt;There's an app for Quest 3 called Gracia, which allows you to see these in 3D space:- https://www.meta.com/en-gb/experiences/gracia/25784099001234...- https://www.gracia.ai&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:56:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42060856</guid></item><item><title>8. 98.css – A design system for building faithful recreations of old UIs</title><link>https://news.ycombinator.com/item?id=42056918</link><description>
&lt;![CDATA[
&lt;p&gt;408 points points by OuterVale on 2024-11-06T02:46:58 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This website seems to offer a minimalist stylesheet called 98.css that emulates Windows 98. It provides a nostalgic design reminiscent of the classic operating system, allowing users to incorporate the look and feel of Windows 98 into their web projects through a simple and lightweight CSS file.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I made something similar as well (that includes both 3.11, 95, 2000, XP, CDE and Mac OS 9, and also all the default color schemes of those): https://nielssp.github.io/classic-stylesheets/?theme=win9x&amp;s...My focus was not so much on pixel perfect, but instead on creating something that would also work and look aesthetically pleasing on modern systems, like with higher DPI monitors and such. So one of the the things I did was to recreate all the icons and symbols in SVG.I tried posting it as a Show HN when I added XP and Mac OS 9, but it didn't get much attention. Maybe the title of the project isn't as catchy.&lt;/li&gt;&lt;li&gt;Author here – happy to see this posted again!This was my burnout recovery project and I wrote some thoughts on it recently https://notes.jordanscales.com/98-css-reflections&lt;/li&gt;&lt;li&gt;My collection:The Sims https://thesimscss.inbn.dev/Windows 98 https://jdan.github.io/98.css/Windows XP https://botoxparty.github.io/XP.css/Windows 7 https://khang-nd.github.io/7.css/Edward Tufte https://edwardtufte.github.io/tufte-css/&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056918</guid></item><item><title>9. The deep learning boom caught almost everyone by surprise</title><link>https://news.ycombinator.com/item?id=42057139</link><description>
&lt;![CDATA[
&lt;p&gt;276 points points by slyall on 2024-11-06T04:05:01 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the reasons behind the rapid growth of deep learning in the field of artificial intelligence. It highlights key factors such as increased computation power, the availability of large datasets for training, algorithmic innovations, and the parallel development of hardware specifically designed for deep learning tasks. The article emphasizes how these factors have collectively contributed to the proliferation of deep learning applications across various industries.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The article credits two academics (Hinton, Fei Fei Li) and a CEO (Jensen Huang).  But really it was three academics.Jensen Huang, reasonably, was desperate for any market that could suck up more compute, which he could pivot to from GPUs for gaming when gaming saturated its ability to use compute.  Screen resolutions and visible polygons and texture maps only demand so much compute; it's an S-curve like everything else.  So from a marketing/market-development and capital investment perspective I do think he deserves credit.  Certainly the Intel guys struggled to similarly recognize it (and to execute even on plain GPUs.)But... the technical/academic insight of the CUDA/GPU vision in my view came from Ian Buck's "Brook" PhD thesis at Stanford under Pat Hanrahan (Pixar+Tableau co-founder, Turing Award Winner) and Ian promptly took it to Nvidia where it was commercialized under Jensen.For a good telling of this under-told story, see one of Hanrahan's lectures at MIT: https://www.youtube.com/watch?v=Dk4fvqaOqv4Corrections welcome.&lt;/li&gt;&lt;li&gt;I think there is a slight disconnect here between making AI systems which are smart and AI systems which are useful. It’s a very old fallacy in AI: pretending tools which assist human intelligence by solving human problems must themselves be intelligent.The utility of big datasets was indeed surprising, but that skepticism came about from recognizing the scaling paradigm must be a dead end: vertebrates across the board require less data to learn new things, by several orders of magnitude. Methods to give ANNs “common sense” are essentially identical to the old LISP expert systems: hard-wiring the answers to specific common-sense questions in either code or training data, even though fish and lizards can rapidly make common-sense deductions about manmade objects they couldn’t have possibly seen in their evolutionary histories. Even spiders have generalization abilities seemingly absent in transformers: they spin webs inside human homes with unnatural geometry.Again it is surprising that the ImageNet stuff worked as well as it did. Deep learning is undoubtedly a useful way to build applications, just like Lisp was. But I think we are about as close to AGI as we were in the 80s, since we have made zero progress on common sense: in the 80s we knew Big Data can poorly emulate common sense, and that’s where we’re at today.&lt;/li&gt;&lt;li&gt;I think neural nets are just a subset of machine learning techniques.I wonder what would have happened if we poured the same amount of money, talent and hardware into SVMs, random forests, KNN, etc.I don't say that transformers, LLMs, deep learning and other great things that happened in the neural network space aren't very valuable, because they are.But I think in the future we should also study other options which might be better suited than neural networks for some classes of problems.Can a very large and expensive LLM do sentiment analysis or classification? Yes, it can. But so can simple SVMs and KNN and sometimes even better.I saw some YouTube coders doing calls to OpenAI's o1 model for some very simple classification tasks. That isn't the best tool for the job.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057139</guid></item><item><title>10. Show HN: Hacker News frontpage as a print newspaper that you can personalize</title><link>https://news.ycombinator.com/item?id=42063709</link><description>
&lt;![CDATA[
&lt;p&gt;369 points points by nimbusega on 2024-11-06T15:23:42 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website covers various topics related to cybersecurity, hacking, technology, and internet news. It provides updates on the latest incidents, trends, and developments in the world of hacking and cybersecurity. The content includes articles, tutorials, discussions, and resources aimed at informing and educating readers about these subjects.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;But that just redirects. It would be nicer to also fetch the text and media when you click on a title.&lt;/li&gt;&lt;li&gt;This doesn't look like a print newspaper. Print newspapers are much denser (in general) and have different headline sizes to emphasize the editor's choice of stories. This looks like a corporate blog home page or something. Some people will like this presentation; I'm pretty happy with HN as it is. But congratulations on shipping!&lt;/li&gt;&lt;li&gt;Looks super neat! I've had a longtime dream of working on a similar project, but I want to make it "Daily Prophet" styled, inspired by the Harry Potter series - https://harrypotter.fandom.com/wiki/Daily_Prophet?file=Daily.... With gifs and effects :)A few years ago, a similar project was posted on HN that I thought was really cool too - E Ink smart screen puts a newspaper on your wall (https://news.ycombinator.com/item?id=22831323).&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42063709</guid></item><item><title>11. Trudeau government bans TikTok from operating in Canada</title><link>https://news.ycombinator.com/item?id=42070946</link><description>
&lt;![CDATA[
&lt;p&gt;609 points points by empressplay on 2024-11-06T23:04:39 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Instead of the laser focus on TikTok as a threat, it would be better for the US and Canada to have real data protection laws that would apply equally to TikTok, Meta, Google, Apple, and X. What the EU has done is far from perfect but it bans the worst practices. The Chinese can buy all of the information they want on Americans and Canadians from ad brokers, who will happily sell them everything they need to track individuals' locations.Perhaps the way to get anti-regulation politicians on board with this is for someone to do what was done to Robert Bork and legally disclose lots of personal info on members of Congress/Parliament, obtained from data brokers and de-anonymized.&lt;/li&gt;&lt;li&gt;&gt; "Most people can say, 'Why is it a big deal for a teenager now to have their data [on TikTok]?' Well in five years, in 10 years, that teenager will be a young adult, will be engaged in different activities around the world,"I’m technically Gen-Z (but just barely) and this is something that really worries me. It’s become increasingly normal in recent times to share absolutely everything online but I’ve got a pretty grim feeling that this isn’t  gonna end well. People don’t realize that the AI’s being trained on your data today will act as an internet history that you can never delete.&lt;/li&gt;&lt;li&gt;To be clear, they're not banning the app, they're banning ByteDance from having offices in Canada&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42070946</guid></item><item><title>12. Kernel optimization with BOLT (binary optimization and layout tool)</title><link>https://news.ycombinator.com/item?id=42005429</link><description>
&lt;![CDATA[
&lt;p&gt;165 points points by chmaynard on 2024-10-31T10:45:19 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website article discusses the process of creating custom Linux kernels and details the steps involved in selecting, configuring, and building a kernel tailored to specific requirements. It explores the benefits of custom kernels, including improved performance and stability, as well as potential challenges such as compatibility issues. The article provides insights into kernel configuration options, addressing common pitfalls, and optimizing the kernel build process to ensure a successful outcome.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Here is another interesting BOLT article, this one on PostgreSQL optimization:https://vondra.me/posts/playing-with-bolt-and-postgres/"results are unexpectedly good, in some cases up to 40%"&lt;/li&gt;&lt;li&gt;Instruction Cache and TLB trashing is an often overlooked consequence of code bloat and sometimes of overly aggressive micro-benchmark driven optimization.Reorganizing the binary is an interesting approach to minimize the cost, but I think that any performance oriented developer should keep in mind that most projects are rarely dependent on a single hot loop but on many systems working together and competing for space in the cache(s).I generally use -Os instead of -O2 and -O3 in my projects, while trying to reduce code bloat to a minimum for that reason.&lt;/li&gt;&lt;li&gt;One can try it out with CachyOS/Arch:https://cachyos.org/blog/2411-kernel-autofdo/&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42005429</guid></item><item><title>13. Model Predictive Control in the Browser with WebAssembly</title><link>https://news.ycombinator.com/item?id=41992851</link><description>
&lt;![CDATA[
&lt;p&gt;112 points points by thunderbong on 2024-10-30T08:15:37 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses implementing Model Predictive Control (MPC) to stabilize a cart-pole system. It explores how to model the dynamics of the system and optimize control inputs to keep the pole upright. The article explains the concept of MPC, the objectives of the control algorithm, and provides code snippets to implement MPC for controlling the cart-pole system efficiently.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I am delighted to see a renewed interest in the field of systems control! This is awesome work!&lt;/li&gt;&lt;li&gt;I'd be interested, if any one had suggestions, on MPC applied to ML/AI systems -- it seems this is an underserved technique/concern in MLEng, and I'd expect to see more on it.&lt;/li&gt;&lt;li&gt;Author of the post here - happy to answer any questions.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:57:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=41992851</guid></item><item><title>14. Only 5.3% of US welders are women. After years as a professor, I became one</title><link>https://news.ycombinator.com/item?id=42056420</link><description>
&lt;![CDATA[
&lt;p&gt;259 points points by Michelangelo11 on 2024-11-06T00:24:48 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The article discusses the author's transition from being a writing professor to becoming a welder. It highlights the lack of gender diversity in the field of welding, with only 5.3% of welders in the U.S. being women. The author shares her personal experiences and challenges in entering a male-dominated profession, emphasizing the importance of breaking stereotypes and encouraging more women to pursue careers in welding.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;What comes across from the article to me is the class barrier more than the gender one - basically it's a posh person finding out what the "real world" looks like.Shop talk and banter are fairly universal. Any difference is going to be a target. Thin bloke who doesn't look strong enough? Ginger hair? Tall guy, short guy? Weird tattoo, etc. Definitely the one black guy or the one white guy is going to get shit. But is it malicious? Almost certainly not.The other thing, which in my experience is relatively common worldwide, is that working class communities are more accepting of male-female dynamics. In academia and in highbrow society the tendency is to basically sanitise every social interaction. When you're in an environment where that isn't happening then you can't suddenly ignore it any more.&lt;/li&gt;&lt;li&gt;&gt; “You’re better looking than the guy I talked to before.” Such harassment remains common for tradeswomenIf people think this is harassment, no wonder people experience a lot of harassment.Unless there was more to it the correct answer is along the lines of "yes thankfully" and then a laugh.I'd recommend a good look in the mirror when looking for the problem in such situations.Same goes for the thing about trying to discreetly notifying that someone has dirty hands:Yes, I don't know what is up with Americans and demanding everyone has clean hands at all times, but as long as that is a thing this probably is meant as a favor. Maybe clumsily, but still.More generally the saying: "when you hear hooves, think horses, not zebras" comes to mind:If you expect things to be meant funny or helpful (and give people some slack) maybe life becomes a lot less stressful than if everything has to be seen through a lens of gender dynamics.And if one is known as a reasonable person, I guess people will also take your side if you have to be loud and clear about something, e.g. if it turns out someone wasn't just clumsily trying to be nice or funny.&lt;/li&gt;&lt;li&gt;&gt; I laid down the welds and put my hood up and the guy goes, ‘Well, goddamn, bitch can weld,’ and I was like, ‘Oh my god, thank god.’”The article refers to various forms of sexism and harassment, including the passage above. I’m absolutely not denying that these things happen in the workplace. That would be insane.But it is also true that the exact exchange above could completely have happened between two guys. Anyone who knows tradesmen understands that there’s a fair amount of good natured hassling of coworkers that has nothing to do with sexism.A lot of this work is dangerous and has to happen quickly and on schedule. You’re not really given serious responsibilities until you can demonstrate you’re not going to get someone crushed under a heavy weight or burned.It might be that she is misinterpreting some of this, but I must concede that she’s kind of a badass because she completed all three years of training and actually does work as a welder.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056420</guid></item><item><title>15. Switch 2 will be backwards compatible with Switch</title><link>https://news.ycombinator.com/item?id=42062841</link><description>
&lt;![CDATA[
&lt;p&gt;318 points points by ashitlerferad on 2024-11-06T14:32:32 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The article states that a successor to the Nintendo Switch will be backwards compatible with the existing Switch console, as confirmed by Nintendo. This means that the new console will be able to play the games from its predecessor. This move by Nintendo aims to ensure that players can continue enjoying their existing game libraries on the new system, providing a smooth transition for consumers and possibly boosting the appeal of the upcoming console.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;This shouldn't come as a surprise to anyone. Nintendo has had a trend for the past couple decades of releasing "sequel" consoles that are essentially a modernized version of the old one with extra features, compatible with everything that released on the predecessor.With all three major console manufacturers prioritizing backwards compatibility, and the rise in PC gaming (universally backwards compatible), people are starting to catch on to the fact that old games don't "expire" after 10 years. I wouldn't be surprised if backwards compatibility just becomes the standard for all gaming consoles going forward.Tangential, but I'm also interested in seeing how games that released on old consoles and are continued to be played, like Fortnite, will support aging hardware. I don't like that Epic can one day announce the game just no longer works on that console, rendering your purchases null and void until you upgrade your hardware, but I can't expect them to update that version of the game forever.&lt;/li&gt;&lt;li&gt;And this reveals the real reason Nintendo came after Switch emulators - to buy some extra time before Switch 2 gets properly emulated.&lt;/li&gt;&lt;li&gt;They're being purposely coy though on what this actually means. Backwards compatibility with digital/e-games, or backwards compatible with the physical carts?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42062841</guid></item><item><title>16. U.S. chip revival plan chooses sites</title><link>https://news.ycombinator.com/item?id=42054779</link><description>
&lt;![CDATA[
&lt;p&gt;172 points points by pseudolus on 2024-11-05T20:14:02 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Wolfspeed is building a fab in North Carolina that will make SiC based chips. They are receiving $750 million from the CHIPS and Science Act and will likely receive another $1 billion in tax credits.https://en.wikipedia.org/wiki/CHIPS_and_Science_ActSiC transistors and diodes are used in high power applications like locomotives, EV chargers and industrial motor controls. In their catalog they have a half-bridge power module rated for 1200V and 760A, which to me is amazing that a semiconductor can handle that much.https://www.wolfspeed.com/products/power/sic-power-modules/h...&lt;/li&gt;&lt;li&gt;It seems that the world is dividing into two camps- the ones who want to hunker down and bunker down into mini-empires, shunning globalisation. Expecting great rewards, by turning economics into trapdoor functions with loads of export and zero imports and tarifs as shield.And the others, who don't want - because they can't. For some globalisation is a navel, a lifeline without which there countries economies would wither and die. The exact same layout pre-WW2.&lt;/li&gt;&lt;li&gt;Well the revival may be halted depending on the election:&gt; The US CHIPS and Science Act's future may depend on the outcome of Tuesday's Presidential Election after House Speaker Mike Johnson suggested the GOP would likely move to repeal the $280 billion funding bill if the party wins a majority in Congress.* https://www.theregister.com/2024/11/04/chips_act_repeal/but a little while later:&gt; Johnson, who voted against the legislation, later said in a statement that the CHIPS Act, which poured $54 billion into the semiconductor manufacturing industry, “is not on the agenda for repeal.”* https://apnews.com/article/mike-johnson-chips-act-d5504f76d3...so ¯\_(ツ)_/¯&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42054779</guid></item><item><title>17. Unix Programmer's Manual Third Edition [pdf] (1973)</title><link>https://news.ycombinator.com/item?id=42055644</link><description>
&lt;![CDATA[
&lt;p&gt;183 points points by rbanffy on 2024-11-05T22:12:02 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The provided link leads to a PDF document that contains the Unix V3 manual. This manual provides comprehensive documentation on the Unix Version 3 operating system, detailing commands, syntax, and usage instructions for various functions within the Unix environment. It serves as a valuable resource for users looking to understand and effectively utilize Unix V3.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;&gt; the number of UNIX installations has grown to 16, with more expected.What a time.&lt;/li&gt;&lt;li&gt;My favorite (and also surprising) old Unix document is an USENIX paper from 1984, describing the /proc filesystem:https://news.ycombinator.com/item?id=26298564&lt;/li&gt;&lt;li&gt;I hadn't realized there was a built in "interactively delete files asking the user" command, "dsw" this far back. I wonder when and why it got dropped?&gt; For each file in the given directory ("." if not
specified) d_s_w_ types its name. If "y" is typed,
the file is deleted; if "x", d_s_w_ exits; if anything else, the file is not removed.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055644</guid></item><item><title>18. Monorepo – Our Experience</title><link>https://news.ycombinator.com/item?id=42062074</link><description>
&lt;![CDATA[
&lt;p&gt;178 points points by vishnumohandas on 2024-11-06T13:37:03 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The article discusses the advantages and challenges of using a monorepo (a version control system where all code is stored in a single repository) in software development. It shares insights and lessons learned from transitioning to a monorepo structure, highlighting benefits such as improved code sharing and easier dependency management, while also addressing issues like build and deployment complexities. The retrospective provides valuable reflection on the impact and outcomes of implementing a monorepo approach in a development workflow.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;    &gt; Moving to a monorepo didn't change much, and what minor changes it made have been positive.

I'm not sure that this statement in the summary jives with this statement from the next section:    &gt; In the previous, separate repository world, this would've been four separate pull requests in four separate repositories, and with comments linking them together for posterity.
    &gt; 
    &gt; Now, it is a single one. Easy to review, easy to merge, easy to revert.

IMO, this is a huge quality of life improvement and prevents a lot of mistakes from not having the right revision synced down across different repos.  This alone is a HUGE improvement where a dev doesn't accidentally end up with one repo in this branch and forgot to pull this other repo at the same branch and get weird issues due to this basic hassle.When I've encountered this, we've had to use another repo to keep scripts that managed this.  But this was also sometimes problematic because each developer's setup had to be identical on their local file system (for the script to work) or we had to each create a config file pointing to where each repo lived.This also impacts tracking down bugs and regression analysis; this is much easier to manage in a mono-repo setup because you can get everything at the same revision instead of managing synchronization of multiple repos to figure out where something broke.&lt;/li&gt;&lt;li&gt;Every monorepo I've ever met (n=3) has some kind of radioactive DMZ that everybody is afraid to touch because it's not clear who owns it but it is clear from its quality that you don't want to be the last person who touched it because then maybe somebody will think that you own it.  It's usually called "core" or somesuch.Separate repos for each team means that when two teams own components that need to interact, they have to expose a "public" interface to the other team--which is the kind of disciplined engineering work that we should be striving for.  The monorepo-alternative is that you solve it in the DMZ where it feels less like engineering and more like some kind of multiparty political endeavor where PR reviewers of dubious stakeholder status are using the exercise to further agendas which are unrelated to the feature except that it somehow proves them right about whatever architectural point is recently contentious.Plus, it's always harder to remove something from the DMZ than to add it, so it's always growing and there's this sort of gravitational attractor which, eventually starts warping time such that PR's take longer to merge the closer they are to it.Better to just do the "hard" work of maintaining versioned interfaces with documented compatibility (backed by tests).  You can always decide to collapse your codebase into a black hole later--but once you start on that path you may never escape.&lt;/li&gt;&lt;li&gt;The #1 benefit for me regarding the monorepo strategy is that when someone on the team refers to a commit hash, there is exactly one place to go and it provides a consistent point-in-time snapshot of everything. Ideally, all of the commits on master are ~good, so you have approximately a perfect time machine to work with.I have solved more bugs looking at diffs in GitHub than I have in my debugger simply by having everything in one happy scrolly view. Being able to flick my mouse wheel a few clicks and confirm that the schema does indeed align with the new DTO model props has saved me countless hours. Confirming stuff like this across multiple repos &amp; commits can encourage a more lackadaisical approach. This also dramatically simplifies things like ORM migrations, especially if you require that all branches rebase &amp; pass tests before merging.I agree with most of the hypothetical caveats, but if you can overcome them even with some mild degree of suffering, I don't see why you wouldn't fight for it.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42062074</guid></item><item><title>19. Superstreamer – OSS streaming toolkit from video source to player</title><link>https://news.ycombinator.com/item?id=42025619</link><description>
&lt;![CDATA[
&lt;p&gt;151 points points by thunderbong on 2024-11-02T11:09:41 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website provides a tool called SuperStreamer that allows users to easily stream video content from popular platforms like Amazon Prime, Netflix, and more, through a single interface. SuperStreamer aims to simplify the streaming experience by aggregating content from various services into one place, making it convenient for users to access and watch their favorite shows and movies without having to switch between multiple streaming platforms.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I skimmed the Readme, the What is Superstreamer? page, and features list. I still don't understand when I would use this, or when I would recommend it to someone. I'm an engineer somewhat familiar with the space.You may consider starting with a simple unique value proposition and reworking presentation from there.Take the first sentence of the Readme as example: "Superstreamer is a self hostable platform that aims to simplify the complexities of video delivery" - and answer questions:1. Who is benefiting?2. How is this better?3. What complexity is being solved?4. What's the tangible outcome, or CTA?5. What well-known alternative is this related to?ChatGPT took a stab at it. Not amazing, but something to start with:"Superstreamer is a self-hosted platform that simplifies video delivery, giving you full control over your content without third-party dependencies. Reduce costs, customize your setup, and deliver high-quality streams with ease. Drop &lt;competitor&gt; today and get started in minutes."Also simple things like defining an acronym before it's used goes a long way.Overall presentation, UX, design, code quality, and detail is a homerun IMO. Nice work, I can tell you put a heap of passion into it.&lt;/li&gt;&lt;li&gt;Author here, this is a fun surprise to wake up to! I was doubting whether my project was "ready to post on HN" but someone beat me to it.With Superstreamer, I'd like to create building blocks that simplify video end-to-end. While I initially wrote it as an "all-in-one" toolkit, I'm more leaning towards an open architecture. Like, you could use Stitcher to insert HLS interstitials (like ads, or bumpers) but have your original playlists come from Mux, Cloudflare Stream, etc... The transcode and package infrastructure is there for you to use it if you'd like to stick to a fully self hostable solution.As for player, it's a neat facade around HLS.js (kudos to the maintainers, their project is great), while initially a streaming library, the facade exposes an interface that makes sense for UI developers.Happy to answer any questions you have.&lt;/li&gt;&lt;li&gt;Something wrong with ffmpeg -&gt; icecast?  Those have been around forever.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:58:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42025619</guid></item><item><title>20. Tracker Beeper (2022)</title><link>https://news.ycombinator.com/item?id=42057036</link><description>
&lt;![CDATA[
&lt;p&gt;375 points points by gaws on 2024-11-06T03:21:09 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the creation of a device called the Tracker Beeper, designed to locate lost items using radio waves and a portable locator. The author details the technical aspects of the project, including the hardware used, software development, and the challenges faced during the design process. The Tracker Beeper is intended to aid in finding misplaced or hidden items by emitting beeps, helping users locate their belongings efficiently.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;It would be mostly quiet (remember that humans only hear up to ~20 kHz).Sure, this is a joke today, but if we continue down our current path, we would probably hit ultrasonic rates in the not too distant future.The video was fun and insightful to watch.  Big fan of sonification of computer processes.  We can hear such a large and important range of frequencies (more than the 'audible range' because we hear impulses in the subsonic range as events) and it works as a nice complementary in real time for an experience that charts can't convey.&lt;/li&gt;&lt;li&gt;Chrome's combined search + address bar seems like a fantastic data source for reverse search warrants: https://en.wikipedia.org/wiki/Reverse_search_warrantImagine a reverse warrant for any person who has searched “torproject.or” in the process of navigating to torproject.org&lt;/li&gt;&lt;li&gt;This would be like the old school computing environment where you get an audible beep every time something is written to your hard disk. People noticed abusive code much more easily then.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42057036</guid></item><item><title>21. 3D Rotation Design</title><link>https://news.ycombinator.com/item?id=42058355</link><description>
&lt;![CDATA[
&lt;p&gt;133 points points by fisian on 2024-11-06T09:07:17 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website describes a project by Matt Keeter, showcasing a tool for interactive three-dimensional modeling and 3D printing. It introduces the concept of rotational extrusion, which creates objects by revolving a 2D shape around an axis, allowing users to design custom shapes easily. The website provides an interactive demonstration of this process and offers the tool for users to experiment with their own designs, promoting creativity and exploration in 3D modeling.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Interesting but lacking some information. First up, of course, most people are familiar with rotating the camera rather than a single object. This is how most 3d viewers work, even if the orbit point is locked to the center of an object (e.g. in a 3d product display). So it's important to specific which we're talking about in an introductory article on 3d rotation methods.But, ok. We're talking about schemes to rotate a single object rather than the camera.The turntable controls they talk about are a special case of gimbal controls where we lock rotation to one or two axes. But in my personal experience, when it's two or three axes people still call it gimbal controls whereas turntable controls is rotation in a single axis (as if on a turntable, hence the name). But then again, 3d terminology is so mixed up across different fields that maybe some people have only heard the two axes version called a turntable. Not a big deal, but  why no mention at all of gimbal controls?Then, trackballs. In my experience, when it's limited to a single hemisphere of rotation, these are called arcball controls. Trackballs are supposed to emulate a trackball mouse which don't have this limitation.And finally, no mention at all of the dreaded gimbal lock (where two of axes end up overlaid on each other and the controls loses a degree of freedom), which is a major reason for choosing one type over another.Overall, not an amazing article. I checked it again to see if I missed anything and realized it's a blog post for some app - so, basically an ad - which probably explains the lack of effort.&lt;/li&gt;&lt;li&gt;FYI, from 2017.Also, Matt Keeter has some serious skills.I always thought his Antimony CAD program[1] was neat, and sad that it seems to have died.  I've yet to figure out how to get it to run on newer versions of linux (The last time I tried was about 3 years ago, and I was just using a raspberry pi.)[1] https://www.mattkeeter.com/projects/antimony/3/&lt;/li&gt;&lt;li&gt;&gt; There's another, more subtle critique of this system: it lacks path independence. This means that if you start and end a drag with your mouse at a particular location, the rotation will depend on the path that your mouse took.Actually, when I accidentally tumble models with that kind of UI, I just drag it in a circle until it's right side up.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42058355</guid></item><item><title>22. Show HN: Aide, an open-source AI native IDE</title><link>https://news.ycombinator.com/item?id=42063346</link><description>
&lt;![CDATA[
&lt;p&gt;192 points points by skp1995 on 2024-11-06T15:01:00 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website provides tools and resources to help developers create conversational AI applications using natural language processing. It offers a platform for building virtual assistants, chatbots, and voice-enabled applications with pre-built modules and integration capabilities for various platforms. The focus is on simplifying the development process and making it accessible to a wide range of users, including those without extensive coding knowledge.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Been using Cursor since launch. Really frustrating how they charge per message (500/mo) instead of by token usage. Like, why should a one-line code suggestion cost the same as refactoring an entire class? Plus it's been losing context lately and making rookie mistakes.Tried Zed AI but couldn't get into it - just doesn't feel as smooth as Cursor used to. GitHub Copilot is even worse. Feels like they're so obsessed with keeping that $10/month price point that they've gutted everything. Context window is tiny and the responses are barebones.&lt;/li&gt;&lt;li&gt;Links to the project, I'm guessing these :)https://github.com/codestoryai/aidehttps://aide.dev/&lt;/li&gt;&lt;li&gt;If it's a fork of VS code it should be trivial to also support Linux and Windows. Why is it MacOs only?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42063346</guid></item><item><title>23. Defibrillation devices save lives using 1k times less electricity</title><link>https://news.ycombinator.com/item?id=42056954</link><description>
&lt;![CDATA[
&lt;p&gt;109 points points by wglb on 2024-11-06T02:54:44 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;The article is about internal defibrillators. External ones are still the same as (good grief) 35 years ago (well maybe down from 300J to 200J). The only change I've noticed is moving from a gel for the pads to a gel pad (which feel like a frog, chuck one in your partners bed and let them find it!) which reduced the possibility of burning and odd smells in your ambulance. Fortunately my sense of smell wasn't great and often had a partner who smoked (and was allowed to in the olden days) in the ambulance to dull it. You kids don't know how it was having to actually manually read the trace instead of all this new-fangled automation that guides you through it.&lt;/li&gt;&lt;li&gt;This is actually interesting for multiple reasons. One is the technology. The other is the positive outcome rate for cardiac arrest after 30 days is so low.The percentage of cardiac arrest survivors with positive outcomes 30 days after release depends on the type of cardiac arrest, and can range from 40% to 82%:In-hospital cardiac arrest (IHCA)
The 30-day survival rate for IHCA is around 25% in the United States and up to 35% in European countries. *In one study, the 30-day survival rate was 40%, with 34% of survivors having good neurological outcomes*.Out-of-hospital cardiac arrest (OHCA)
The probability of survival after OHCA can be increased by providing immediate cardiopulmonary resuscitation (CPR) and using an automated external defibrillator (AED). In one study, *10% of people who experienced OHCA survived with a favorable neurological outcome*.https://pmc.ncbi.nlm.nih.gov/articles/PMC8359113/&lt;/li&gt;&lt;li&gt;This appears to be a simulation study done in 2d.Similar results have been observed in 2d simulations for more than 20 years, no one had managed to translate them to application.One of the problems is, that 2 d and 3d reaction-diffusion systems are very different when it comes to so-called topological charge conservation. One can show that interactions of the applied electrical field can be described by its influence on the topological charges.In 2d these topological charges are limited to points in 3d they form curves.Points are limited to drifting and colliding, lines can twist, self collide, form rings and so on making translating 1d results to 3d quite difficult.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42056954</guid></item><item><title>24. What Shapes Do Matrix Multiplications Like?</title><link>https://news.ycombinator.com/item?id=42055616</link><description>
&lt;![CDATA[
&lt;p&gt;156 points points by skidrow on 2024-11-05T22:08:24 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website explains the concept of matrix multiplication by visually illustrating how it is performed through a step-by-step process. It breaks down the calculations involved in multiplying two matrices and shows examples of different matrix shapes to demonstrate how they are manipulated in the multiplication process. The resources aim to provide a clear understanding of matrix operations and help users grasp the fundamentals of linear algebra.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I recall some optimization advice to choose a leading dimension that is NOT a power of two, in order to avoid cache set associativity conflicts. Guess it's highly hardware dependent (in particular, that advice was for cpu's not GPU's).&lt;/li&gt;&lt;li&gt;Great post! I appreciate the diagrams.&lt;/li&gt;&lt;li&gt;TL;DR: make sure your matrix dimensions are divisible by 2 often.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42055616</guid></item><item><title>25. Forget CDK and AWS's insane costs. Pulumi and DigitalOcean to the rescue</title><link>https://news.ycombinator.com/item?id=42065561</link><description>
&lt;![CDATA[
&lt;p&gt;136 points points by mavdi on 2024-11-06T17:15:43 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The GitHub repository stoix-cloud-saver is a storage management tool designed to help users save and restore their digital assets efficiently. It includes features such as backups, archives, and retention policies for organizations looking to manage their cloud storage effectively. The tool aims to simplify the process of storing and recovering data on the cloud for users.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Hetzner has been our "expensive AWS cloud costs" saviourWe've also started switching our custom Docker compose + SSL GitHub Action deployments to use Kamal [1] to take advantage of its nicer remote monitoring features[1] https://kamal-deploy.org&lt;/li&gt;&lt;li&gt;For anyone deliberating between Pulumi and CDK let me recommend what I consider the best of both worlds: CDKTF, Hashicorp’s answer to Pulimi (my quote not theirs).It’s got everything you want:- strong type system (TS),- full expressive power of a real programming language (TS),- can use every existing terraform provider directly,- compiles to actual Terraform so you can always use that as an escape hatch to debug any problems or interface with any other tools,- official backing of Hashicorp so it’s a safe betIt’s a super power for infra. If you have strong software dev skills and you want to leverage the entire TF ecosystem without the pain of Terraform the language, CDKTF is for you.(No affiliation)https://developer.hashicorp.com/terraform/cdktf&lt;/li&gt;&lt;li&gt;Pulumi is really a royal piece of shit.  Why the f*ck am I writing code to do "deployment".  In C# --&gt; new Dictionary&lt;string, object&gt; when dealing with a values.yaml for instance.  The whole need to figure out when and when not to use Apply.Give me Terraform (as much as I hate it) any day.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 04:59:57 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42065561</guid></item><item><title>26. WebSockets cost us $1M on our AWS bill</title><link>https://news.ycombinator.com/item?id=42067275</link><description>
&lt;![CDATA[
&lt;p&gt;305 points points by tosh on 2024-11-06T18:50:02 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;This article discusses how the use of WebSockets significantly increased the AWS bill of a company, leading to unexpected high costs. It explains the challenges faced with scaling and managing WebSockets on AWS, highlighting the impact on cost and performance. The author shares valuable insights and recommendations on optimizing WebSocket usage to control expenses and improve system efficiency.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Classic story of a startup taking a "good enough" shortcut and then coming back later to optimize.---I have a similar story: Where I work, we had a cluster of VMs that were always high CPU and a bit of a problem. We had a lot of fire drills where we'd have to bump up the size of the cluster, abort in-progress operations, or some combination of both.Because this cluster of VMs was doing batch processing that the founder believed should be CPU intense, everyone just assumed that increasing load came with increasing customer size; and that this was just an annoyance that we could get to after we made one more feature.But, at one point the bean counters pointed out that we spent disproportionately more on cloud than a normal business did. After one round of combining different VM clusters (that really didn't need to be separate servers), I decided that I could take some time to hook up this very CPU intense cluster up to a profiler.I thought I was going to be in for a 1-2 week project and would follow a few worms. Instead, the CPU load was because we were constantly loading an entire table, that we never deleted from, into the application's process. The table had transient data that should only last a few hours at most.I quickly deleted almost a decade's worth of obsolete data from the table. After about 15 minutes, CPU usage for this cluster dropped to almost nothing. The next day we made the VM cluster a fraction of its size, and in the next release, we got rid of the cluster and merged the functionality into another cluster.I also made a pull request that introduced a simple filter to the query to only load 3 days of data; and then introduced a background operation to clean out the table periodically.&lt;/li&gt;&lt;li&gt;&gt; One complicating factor here is that raw video is surprisingly high bandwidth.It's weird to be living in a world where this is a surprise but here we are.Nice write up though. Web sockets has a number of nonsensical design decisions, but I wouldn't have expected that this is the one that would be chewing up all your cpu.&lt;/li&gt;&lt;li&gt;The problem is not on network level.The problem is that the developers behind this way of streaming video data seem to have no idea of how video codecs work.If they are in control of the headless chromium instances, the video streams, and the receiving backend of that video stream...why not simply use RDP or a similar video streaming protocol that is made exactly for this purpose?This whole post reads like an article from a web dev that is totally over their head, trying to implement something that they didn't take the time to even think about. Arguing with TCP fragmentation when that is not even an issue, and trying to use a TCP stream when that is literally the worst thing you can do in that situation because of roundtrip costs.But I guess that there is no JS API for that, so it's outside the development scope? Can't imagine any reason not to use a much more efficient video codec here other than this running in node.js, potentially missing offscreen canvas/buffer APIs and C encoding libraries that you could use for that.I would not want to work at this company, if this is how they develop software. Must be horribly rushed prototypical code, everywhere.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:07 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42067275</guid></item><item><title>27. Hacking cars in JavaScript (Replay attacks in the browser with the HackRF)</title><link>https://news.ycombinator.com/item?id=42028890</link><description>
&lt;![CDATA[
&lt;p&gt;83 points points by rmason on 2024-11-02T20:05:17 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website discusses the concept of replay attacks in JavaScript, where an attacker intercepts and replicates data packets to impersonate a legitimate user. It explores how the HackRF tool can be used to capture signals for these attacks, demonstrating the potential vulnerabilities in security protocols such as the Key Fob Authentication System. The article delves into the technical aspects of replay attacks, providing insights on how to identify and prevent such malicious activities in various contexts.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Lots of other interesting projects on the author's site, check them out&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:17 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42028890</guid></item><item><title>28. Launch HN: Midship (YC S24) – Turn PDFs, docs, and images into usable data</title><link>https://news.ycombinator.com/item?id=42066500</link><description>
&lt;![CDATA[
&lt;p&gt;86 points points by maxmaio on 2024-11-06T18:05:55 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;None&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;Heres a real world use case, our company has moved our pension provider. This provider like the old one sucks at providing me with a good way to navigate through the 120 funds I can invest in.I want to create something that can paginate through 12 pages of html, perform clicks, download pdf fund factsheet, extract data from this factsheet into excel or CSV. Can this help? What's the best way to deal with the initial task of automating webpage interactions systematically?&lt;/li&gt;&lt;li&gt;Congrats on the launch. I just sent y'all an email – I'm curious with what you can do with airline crew rosters.&lt;/li&gt;&lt;li&gt;Saw your demo video. Are you focusing on the finance sector primarily? It is a challenging industry IMO, requiring high accuracy and has strict privacy/security bar. How do you address these concerns?Curious what are the biggest complain from your users? Are they willing to manually auditing the numbers in the table, make sure the output is 1. accurate. 2. formatted in the table they expected.&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:27 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42066500</guid></item><item><title>29. 131M American Buildings</title><link>https://news.ycombinator.com/item?id=42025037</link><description>
&lt;![CDATA[
&lt;p&gt;159 points points by marklit on 2024-11-02T09:03:28 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;The website details a project where advanced technology was used to scan buildings at Oak Ridge National Laboratory (ORNL) in collaboration with the Federal Emergency Management Agency (FEMA). The project aimed to generate highly detailed 3D models of structures to assist in disaster response planning and other emergency scenarios. High-tech equipment like LiDAR scanners and a cutting-edge imaging technique called structured-light 3D scanning were utilized to capture accurate representations of the buildings. The website provides a detailed account of the technology used, the process involved, and the significance of the project for enhancing emergency preparedness and response efforts.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;About this website: as soon as i scroll downwards, the font-size doubles and page margins increase quite a bit. So I'm reading skinny paragraphs in large-ish type.As soon as i scroll upwards, the font size shrinks back to normal and page margins similarly retreat.No matter where i am in the page, i scroll down it does the one; i scroll up it does the other.FWIW I'm using the DuckDuckGo browser on Android.&lt;/li&gt;&lt;li&gt;I am tempted to import this data into my system and build a pivot table of building type (PRIM_OCC) by state.I could then graph the data (pie chart, bar graph, etc) to show how the building type distribution (e.g. residential ratio per hospital) varies between the states.&lt;/li&gt;&lt;li&gt;any cool ideas I could build with this data?&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:37 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42025037</guid></item><item><title>30. Physicists spot quantum tornadoes twirling in a 'supersolid'</title><link>https://news.ycombinator.com/item?id=42067233</link><description>
&lt;![CDATA[
&lt;p&gt;84 points points by elsewhen on 2024-11-06T18:46:53 &lt;/p&gt;
&lt;h2&gt;Article Summary&lt;/h2&gt;
&lt;p&gt;Physicists have observed quantum tornadoes within a supersolid, a strange state of matter that combines the properties of a solid and a superfluid. The researchers used a novel experimental setup to visualize these tornado-like excitations and gain insights into the behavior of supersolids. The findings offer new understanding of exotic quantum phenomena and potential applications in quantum information processing.&lt;/p&gt;
            &lt;h2&gt;Top Comments&lt;/h2&gt;&lt;p&gt;&lt;ol&gt;&lt;li&gt;I’m way out of my depth in this subject, but I find this incredibly fascinating.I had to read up on supersolids; still not fully understanding.I once had a naïve perspective that we’d figured out all the “big” stuff in science, but I’m now of the perspective that we’re still only scratching the surface.&lt;/li&gt;&lt;li&gt;there were missing waffles, next to the gnocci and spaghetti&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;]]]]</description><pubDate>Thu, 07 Nov 2024 05:00:47 -0000</pubDate><guid isPermaLink="false">https://news.ycombinator.com/item?id=42067233</guid></item></channel></rss>